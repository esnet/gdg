var suggestions=document.getElementById("suggestions"),search=document.getElementById("search");search!==null&&document.addEventListener("keydown",inputFocus);function inputFocus(e){e.ctrlKey&&e.key==="/"&&(e.preventDefault(),search.focus()),e.key==="Escape"&&(search.blur(),suggestions.classList.add("d-none"))}document.addEventListener("click",function(e){var t=suggestions.contains(e.target);t||suggestions.classList.add("d-none")}),document.addEventListener("keydown",suggestionFocus);function suggestionFocus(e){const s=suggestions.classList.contains("d-none");if(s)return;const t=[...suggestions.querySelectorAll("a")];if(t.length===0)return;const n=t.indexOf(document.activeElement);if(e.key==="ArrowUp"){e.preventDefault();const s=n>0?n-1:0;t[s].focus()}else if(e.key==="ArrowDown"){e.preventDefault();const s=n+1<t.length?n+1:n;t[s].focus()}}(function(){var e=new FlexSearch.Document({tokenize:"forward",cache:100,document:{id:"id",store:["href","title","description"],index:["title","description","content"]}});e.add({id:0,href:"/gdg/docs/releases/",title:"Releases",description:"",content:""}),e.add({id:1,href:"/gdg/docs/gdg/installation/",title:"Installation",description:`Installation # The easiest way to install GDG is to get one of the pre-compiled binaries from our release page which can be found here. Packages for a few distributions have been added. The release cycle relies on goreleaser so anything that is well supported can be added it at some point. There is no APT or such you can connect to but the packages are available for download.
The following packages are currently supported:`,content:`Installation # The easiest way to install GDG is to get one of the pre-compiled binaries from our release page which can be found here. Packages for a few distributions have been added. The release cycle relies on goreleaser so anything that is well supported can be added it at some point. There is no APT or such you can connect to but the packages are available for download.
The following packages are currently supported:
RPM APK Docker Brew Package Installation # Install from package involves downloading the appropriate package from the release and installing it as you usually do on your favorite Distro.
rpm -Uvh ./gdg_0.5.3_amd64.rpm dpkg -i ./gdg_0.5.3_amd64.deb Homebrew Installation # brew tap esnet/gdg brew update brew install gdg If there is a conflict you can try to be explicit.
brew install esnet/gdg/gdg Docker usage # The docker tags are released started with 0.3.1. Each release will generate a major version and minor version tag.
You can see the available images here
docker pull ghcr.io/esnet/gdg:0.5.3 NOTE: ghcr.io/esnet/gdg:0.3 will also point to 0.3.1 until 0.3.2 is released after which it&rsquo;ll point to 0.3.2
Example compose.
version: '3.7' services: gdg: image: ghcr.io/esnet/gdg:0.5.3 command: &quot;--help&quot; ## Add additional parameters here # command: &quot;ds export&quot; ## Pass any cmd on here. volumes: - ./config:/app/config ## where the configuration lives - ./exports:/app/exports ## doesn't need to be /app/exports but you should export the destination of where exports are being written out to. From the CLI:
docker run -it --rm -v $(pwd)/config:/app/config -v $(pwd)/exports:/app/exports ghcr.io/esnet/gdg:latest ds --help Installing via Go # If you have go install you may run the following command to install gdg. Keep in mind there are two binaries you may install.
gdg ==&gt; Main binary that manages the various entities supported. gdg-generate =&gt; Helper utility that allows you to generate multiple dashboards given a valid configuration and seed data. gdg
go install github.com/esnet/gdg/cmd/gdg@latest #for latest go install github.com/esnet/gdg/cmd/gdg@v0.5.3 #for a specific version You can verify the version by running gdg version.
gdg-generate
go install github.com/esnet/gdg/cmd/gen@latest #for latest go install github.com/esnet/gdg/cmd/gen@v0.5.3 #for a specific version Configuration # You can then create a simple configuration using gdg tools ctx new which will do a best effort to guide to setup a basic config that will get you up and going or read the more detailed documentation that can be found here
NOTE: wizard doesn&rsquo;t currently support ALL features but it should help you get a head start.
`}),e.add({id:2,href:"/gdg/docs/templating/description/",title:"Templating Tool",description:`GDG has now introduced a new supporting tool that works in conjunction with GDG. It is currently dependent on the GDG configuration since it will operate on the currently selected context. You can confirm what the current context is by running gdg ctx show
For example, my current output is as follows:
context_name: storage: &quot;&quot; enterprise_support: true url: http://localhost:3000 token: &quot;&quot; user_name: admin password: admin organization_id: 0 watched_folders_override: [ ] watched: - General - Other connections: exclude_filters: - { } credential_rules: - rules: - field: name regex: misc - field: url auth: user: user password: password - rules: - field: url regex: .`,content:`GDG has now introduced a new supporting tool that works in conjunction with GDG. It is currently dependent on the GDG configuration since it will operate on the currently selected context. You can confirm what the current context is by running gdg ctx show
For example, my current output is as follows:
context_name: storage: &quot;&quot; enterprise_support: true url: http://localhost:3000 token: &quot;&quot; user_name: admin password: admin organization_id: 0 watched_folders_override: [ ] watched: - General - Other connections: exclude_filters: - { } credential_rules: - rules: - field: name regex: misc - field: url auth: user: user password: password - rules: - field: url regex: .*esproxy2* auth: user: admin password: secret - rules: - field: name regex: .* auth: user: user password: password datasources: { } filter_override: ignore_dashboard_filters: false output_path: test/data Most of the config isn&rsquo;t that interesting, except the output_path will be used to determine where the newly generated dashboards will be. Make sure you have a valid configuration before continuing.
What does gdg-generate do? # There are use cases where an almost identical dashboard is needed except we need to replace certain parts of it.
For example, parts of a query need to be different, a different title, brand it to specific customer with a different logo, or footer. All of these are difficult to control from grafana itself and even in the best case scenario it&rsquo;s not great user experience. This allows you to configure and generate a new dashboard with any set of variables and dictionaries that you will seed to the tool.
The configuration that drives this application is templates.yml. You can see an example below.
entities: dashboards: - template_name: &quot;template_example&quot; ##Matches the name to a file under ouput_path/templates/*.go.tmpl output: ## The section below defines one or multiple destination and the associated configuration ## that goes with it. - folder: &quot;General&quot; ## Name of the new folder where the template will be created org_id: 2 ## Organization ID, will be converted to a name in a future version dashboard_name: &quot;&quot; ## Optional, defaults to template_name.json template_data: ## Template Data the dictionary of datasets that can be used in the template, # it's basically your 'seed data'. Everything is contains is absolutely arbitrary # and can have any structure as long as it's valid yaml Title: &quot;Bob Loves Candy&quot; ## Dashboard Titlte enabledlight: false ## Boolean check to enable/disable behavior lightsources: ## some arbitrary list we get to play with - sun - moon - lightbulb - office lights One caveat. The &ldquo;Keys&rdquo; will all be lowercased due to how the data is being read in. Meaning, even though Title is specified, the template will see the value under &ldquo;title&rdquo; instead.
Available Functions # Additionally, there a few functions exposed and available to you that allows you to modify
| Function Name | Example | Input | Output | |------------------|-----------------------------------------|----------------------|--------------------------| | ToSlug | {{ .title \\| ToSlug }} | Bob Candy | bob-candy | | QuotedStringJoin | {{ .lightsources \\| QuotedStringJoin }} | [sun,moon,lightbulb] | &quot;sun&quot;,&quot;moon&quot;,&quot;lightbulb&quot; | There is also a large collection of functions that have been imported from sprig and are available for use.
Example Templating Snippets # Data Injection
{ &quot;annotations&quot;: { &quot;list&quot;: [ { &quot;$$hashKey&quot;: &quot;{{ .title | lower | ToSlug}}&quot;, // Inserting data and piping it to two different functions. In this case, ToLower is redundant, but it serves as a chained example. &quot;builtIn&quot;: 1, &quot;datasource&quot;: &quot;Grafana&quot;, &quot;enable&quot;: true, &quot;hide&quot;: true, &quot;iconColor&quot;: &quot;rgba(0, 211, 255, 1)&quot;, &quot;name&quot;: &quot;Annotations Alerts&quot;, &quot;type&quot;: &quot;dashboard&quot; } ] } } Iterating and conditionals.
{ &quot;link_text&quot;: [ {{if .enabledlight}} // conditional to check if to insert or not {{ range $v := .lightsources}} // Iterating through list {{ $v }} // Inserting value {{ end }} {{ end }} ] } Inserting a comma delimited list
&quot;link_url&quot;: [ &quot;{{ .lightsources | join &quot;,&quot; }}&quot;, &quot;/grafana/d/000000003/bandwidth-dashboard&quot;, &quot;/grafana/d/xk26IFhmk/flow-data&quot;, ] Usage # As part of the installation you will have access to gdg-generate.
NOTE: -c and -ct are optional parameters as is -t if you&rsquo;re relying on the defaults. -t will filter the config and only process the template you&rsquo;ve specified.
gdg-generate -c config/importer.yml --ct config/template.yaml -t template_example Example output:
2023-11-16 09:49:03 INF gen/main.go:16 Reading GDG configuration 2023-11-16 09:49:03 INF gen/main.go:20 Configuration file is: config=importer.yml 2023-11-16 09:49:03 INF gen/main.go:29 Context is set to: context=testing 2023-11-16 09:49:03 INF templating/templating.go:83 Processing template template=template_example 2023-11-16 09:49:03 INF templating/templating.go:97 Creating a new template folder=General orgId=2 data=&quot;map[enabledlight:false lightsources:[sun moon lightbulb office lights] title:Bob Loves Candy]&quot; 2023-11-16 09:49:03 INF templating/templating.go:100 Writing data to destination output=test/data/org_2/dashboards 2023-11-16 09:49:03 INF templating/templating.go:131 template Path: path=test/data/templates A new file has been created under test/data/org_2/dashboards/General/template_example.json
`}),e.add({id:3,href:"/gdg/docs/gdg/",title:"GDG Docs",description:"",content:""}),e.add({id:4,href:"/gdg/docs/tutorials/library_elements/",title:"Working with Library Panels",description:`Starting with version 0.4, library panels are going to be supported. It&rsquo;s a bit special and the behavior is somewhat unique.
Rules:
Library Panels are immutable. They cannot be moved to a different folder. They are linked to one or multiple dashboards. The only way I can see to move a lib element is to unlink the panel, delete the panel and re-create it in a different folder, then re-link it.`,content:`Starting with version 0.4, library panels are going to be supported. It&rsquo;s a bit special and the behavior is somewhat unique.
Rules:
Library Panels are immutable. They cannot be moved to a different folder. They are linked to one or multiple dashboards. The only way I can see to move a lib element is to unlink the panel, delete the panel and re-create it in a different folder, then re-link it. In theory it&rsquo;s supposed to move with the dashboards but I haven&rsquo;t been able to re-create that behavior. You cannot delete a library element while a dashboard is still using it. Import components # will retrieve all the components from Grafana and save to local file system.
gdg lib download ┌─────────┬───────────────────────────────────────────────────────────────────────────────────────────────────────┐ │ TYPE │ FILENAME │ ├─────────┼───────────────────────────────────────────────────────────────────────────────────────────────────────┤ │ library │ testing_data/libraryelements/General/dashboard-makeover-extra-cleaning-duty-assignment-today.json │ │ library │ testing_data/libraryelements/General/dashboard-makeover-lighting-status.json │ │ library │ testing_data/libraryelements/General/dashboard-makeover-side-dish-prep-times-past-7-days.json │ │ library │ testing_data/libraryelements/General/dashboard-makeover-time-since-we-purchased-these-spices.json │ │ library │ testing_data/libraryelements/General/extreme-dashboard-makeover-grill.json │ │ library │ testing_data/libraryelements/General/extreme-dashboard-makeover-mac-oven.json │ │ library │ testing_data/libraryelements/General/extreme-dashboard-makeover-refrigerator-temperature-f.json │ │ library │ testing_data/libraryelements/General/extreme-dashboard-makeover-room-temperature-f.json │ │ library │ testing_data/libraryelements/General/extreme-dashboard-makeover-salmon-cooking-times-past-7-days.json │ └─────────┴───────────────────────────────────────────────────────────────────────────────────────────────────────┘ Importing Dashboards # Now that we the library components, pulled let&rsquo;s pull the Dashboard.
gdg dash download INFO[0002] Importing dashboards for context: 'local' ┌───────────┬───────────────────────────────────────────────────────────────────┐ │ TYPE │ FILENAME │ ├───────────┼───────────────────────────────────────────────────────────────────┤ │ dashboard │ testing_data/dashboards/General/bandwidth-dashboard.json │ │ dashboard │ testing_data/dashboards/General/bandwidth-patterns.json │ │ dashboard │ testing_data/dashboards/Other/dashboard-makeover-challenge.json │ &lt;== uses library panels │ dashboard │ testing_data/dashboards/Other/flow-analysis.json │ │ dashboard │ testing_data/dashboards/Other/flow-data-for-circuits.json │ │ dashboard │ testing_data/dashboards/Other/flow-data-for-projects.json │ │ dashboard │ testing_data/dashboards/Other/flow-data-per-country.json │ │ dashboard │ testing_data/dashboards/Other/flow-data-per-organization.json │ │ dashboard │ testing_data/dashboards/Other/flow-information.json │ │ dashboard │ testing_data/dashboards/Other/flows-by-science-discipline.json │ │ dashboard │ testing_data/dashboards/General/individual-flows.json │ │ dashboard │ testing_data/dashboards/General/individual-flows-per-country.json │ │ dashboard │ testing_data/dashboards/Ignored/latency-patterns.json │ │ dashboard │ testing_data/dashboards/General/loss-patterns.json │ │ dashboard │ testing_data/dashboards/General/other-flow-stats.json │ │ dashboard │ testing_data/dashboards/General/science-discipline-patterns.json │ │ dashboard │ testing_data/dashboards/General/top-talkers-over-time.json │ └───────────┴───────────────────────────────────────────────────────────────────┘ The dashboards will have a reference to the library panel linked by UID.
Here&rsquo;s the json from the dashboard JSON:
&quot;libraryPanel&quot;: { &quot;description&quot;: &quot;&quot;, &quot;meta&quot;: { &quot;connectedDashboards&quot;: 3, &quot;created&quot;: &quot;2022-05-17T19:35:06Z&quot;, &quot;createdBy&quot;: { &quot;avatarUrl&quot;: &quot;/avatar/579fc54abdc9ab34fb4865322f2870a1&quot;, &quot;id&quot;: 13, &quot;name&quot;: &quot;mike.johnson@grafana.com&quot; }, &quot;folderName&quot;: &quot;mj&quot;, &quot;folderUid&quot;: &quot;R0bMCcW7z&quot;, &quot;updated&quot;: &quot;2022-05-17T19:37:14Z&quot;, &quot;updatedBy&quot;: { &quot;avatarUrl&quot;: &quot;/avatar/579fc54abdc9ab34fb4865322f2870a1&quot;, &quot;id&quot;: 13, &quot;name&quot;: &quot;mike.johnson@grafana.com&quot; } }, &quot;name&quot;: &quot;Extreme Dashboard Makeover - Grill&quot;, &quot;type&quot;: &quot;graph&quot;, &quot;uid&quot;: &quot;y1C0A5unz&quot;, &quot;version&quot;: 2 }, Please note, this is the Grill panel.
{ &quot;name&quot;: &quot;Extreme Dashboard Makeover - Grill&quot;, &quot;orgId&quot;: 1, &quot;type&quot;: &quot;graph&quot;, &quot;uid&quot;: &quot;y1C0A5unz&quot;, &quot;version&quot;: 1 } Deleting Elements # If we try to delete all the Library elements, that won&rsquo;t be allowed.
./bin/gdg lib clear ERRO[0000] Failed to delete library panel titled: Dashboard Makeover - Extra Cleaning Duty Assignment Today ErrorMessage=&quot;the library element has connections&quot; ERRO[0000] Failed to delete library panel titled: Dashboard Makeover - Lighting Status ErrorMessage=&quot;the library element has connections&quot; ERRO[0000] Failed to delete library panel titled: Dashboard Makeover - Side Dish Prep Times, past 7 days ErrorMessage=&quot;the library element has connections&quot; ERRO[0000] Failed to delete library panel titled: Dashboard Makeover - Time since we purchased these spices ErrorMessage=&quot;the library element has connections&quot; ERRO[0000] Failed to delete library panel titled: Extreme Dashboard Makeover - Grill ErrorMessage=&quot;the library element has connections&quot; ERRO[0000] Failed to delete library panel titled: Extreme Dashboard Makeover - Mac Oven ErrorMessage=&quot;the library element has connections&quot; ERRO[0000] Failed to delete library panel titled: Extreme Dashboard Makeover - Refrigerator Temperature (F) ErrorMessage=&quot;the library element has connections&quot; ERRO[0000] Failed to delete library panel titled: Extreme Dashboard Makeover - Room Temperature (F) ErrorMessage=&quot;the library element has connections&quot; ERRO[0000] Failed to delete library panel titled: Extreme Dashboard Makeover - Salmon Cooking Times, past 7 days ErrorMessage=&quot;the library element has connections&quot; INFO[0000] No library were found. 0 librarys removed Deleting related dashboard # (Future version will allow you to inspect which dashboard has a link to which dashboards)
./bin/gdg dash clear -d dashboard-makeover-challenge (gke_esnet-sd-dev_us-central1-c_dev-staging-kafka-3/default) INFO[0000] 1 dashboards were deleted ┌───────────┬──────────────────────────────┐ │ TYPE │ FILENAME │ ├───────────┼──────────────────────────────┤ │ dashboard │ Dashboard Makeover Challenge │ └───────────┴──────────────────────────────┘ Please note the -d, we&rsquo;re explicitly only deleting one dashboard. We can verify the list.
./bin/gdg dash list ┌────┬──────────────────────────────┬──────────────────────────────┬─────────┬───────────┬────────────────────────────────────────────────────────────────┐ │ ID │ TITLE │ SLUG │ FOLDER │ UID │ URL │ ├────┼──────────────────────────────┼──────────────────────────────┼─────────┼───────────┼────────────────────────────────────────────────────────────────┤ │ 80 │ Bandwidth Dashboard │ bandwidth-dashboard │ General │ 000000003 │ http://localhost:3000/d/000000003/bandwidth-dashboard │ │ 81 │ Bandwidth Patterns │ bandwidth-patterns │ General │ 000000004 │ http://localhost:3000/d/000000004/bandwidth-patterns │ │ 90 │ Flow Analysis │ flow-analysis │ Other │ VuuXrnPWz │ http://localhost:3000/d/VuuXrnPWz/flow-analysis │ │ 91 │ Flow Data for Circuits │ flow-data-for-circuits │ Other │ xk26IFhmk │ http://localhost:3000/d/xk26IFhmk/flow-data-for-circuits │ │ 92 │ Flow Data for Projects │ flow-data-for-projects │ Other │ ie7TeomGz │ http://localhost:3000/d/ie7TeomGz/flow-data-for-projects │ │ 93 │ Flow Data per Country │ flow-data-per-country │ Other │ fgrOzz_mk │ http://localhost:3000/d/fgrOzz_mk/flow-data-per-country │ │ 94 │ Flow Data per Organization │ flow-data-per-organization │ Other │ QfzDJKhik │ http://localhost:3000/d/QfzDJKhik/flow-data-per-organization │ │ 95 │ Flow Information │ flow-information │ Other │ nzuMyBcGk │ http://localhost:3000/d/nzuMyBcGk/flow-information │ │ 96 │ Flows by Science Discipline │ flows-by-science-discipline │ Other │ WNn1qyaiz │ http://localhost:3000/d/WNn1qyaiz/flows-by-science-discipline │ │ 83 │ Individual Flows │ individual-flows │ General │ -l3_u8nWk │ http://localhost:3000/d/-l3_u8nWk/individual-flows │ │ 82 │ Individual Flows per Country │ individual-flows-per-country │ General │ 80IVUboZk │ http://localhost:3000/d/80IVUboZk/individual-flows-per-country │ │ 88 │ Latency Patterns │ latency-patterns │ Ignored │ 000000005 │ http://localhost:3000/d/000000005/latency-patterns │ │ 84 │ Loss Patterns │ loss-patterns │ General │ 000000006 │ http://localhost:3000/d/000000006/loss-patterns │ │ 85 │ Other Flow Stats │ other-flow-stats │ General │ CJC1FFhmz │ http://localhost:3000/d/CJC1FFhmz/other-flow-stats │ │ 86 │ Science Discipline Patterns │ science-discipline-patterns │ General │ ufIS9W7Zk │ http://localhost:3000/d/ufIS9W7Zk/science-discipline-patterns │ │ 87 │ Top Talkers Over Time │ top-talkers-over-time │ General │ b35BWxAZz │ http://localhost:3000/d/b35BWxAZz/top-talkers-over-time │ └────┴──────────────────────────────┴──────────────────────────────┴─────────┴───────────┴────────────────────────────────────────────────────────────────┘ Removing related components # ./bin/gdg lib clear (gke_esnet-sd-dev_us-central1-c_dev-staging-kafka-3/default) INFO[0000] 9 library were deleted ┌─────────┬────────────────────────────────────────────────────────────────┐ │ TYPE │ FILENAME │ ├─────────┼────────────────────────────────────────────────────────────────┤ │ library │ Dashboard Makeover - Extra Cleaning Duty Assignment Today │ │ library │ Dashboard Makeover - Lighting Status │ │ library │ Dashboard Makeover - Side Dish Prep Times, past 7 days │ │ library │ Dashboard Makeover - Time since we purchased these spices │ │ library │ Extreme Dashboard Makeover - Grill │ │ library │ Extreme Dashboard Makeover - Mac Oven │ │ library │ Extreme Dashboard Makeover - Refrigerator Temperature (F) │ │ library │ Extreme Dashboard Makeover - Room Temperature (F) │ │ library │ Extreme Dashboard Makeover - Salmon Cooking Times, past 7 days │ └─────────┴────────────────────────────────────────────────────────────────┘ `}),e.add({id:5,href:"/gdg/docs/tutorials/orgs_auth/",title:"Organization and Authentication",description:`Concepts # At it&rsquo;s core an Organization in grafana is an entity that allows you (the user) to organize and structure entities to seperate access for both usability and security. So a Connection under org1 would never be able to be configured to use a dashboard under Org2.
Authentication with GDG and grafana can take a few different patterns.
Grafana Admin - this is your typical admin/admin default user that comes with most installs.`,content:`Concepts # At it&rsquo;s core an Organization in grafana is an entity that allows you (the user) to organize and structure entities to seperate access for both usability and security. So a Connection under org1 would never be able to be configured to use a dashboard under Org2.
Authentication with GDG and grafana can take a few different patterns.
Grafana Admin - this is your typical admin/admin default user that comes with most installs. You have full access to do everything. Org Admin - this is a user that is an admin for one or multiple Orgs and can manage most entities under the given org but not high level entities. Each user can be authenticated with &lsquo;BasicAuth&rsquo; or APIKeys/Service Tokens.
Basic Auth allows a user to change Orgs context if they have access to more than one. Service Token/API Keys are bound to a given org, so if the user tries to change the Org, it won&rsquo;t work. It grants access, viewer, editor, admin for a given Org. If you are working with multiple Orgs, you will have a much easier time if you use basic auth. You can certainly simply rotate the tokens as you like though GDG is a bit better at dealing with basic auth and switching orgs accordingly.
Organization Workflow # List Orgs (Grafana Admin) # will retrieve all the components from Grafana and save to local file system.
gdg backup orgs list ┌────┬───────────┐ │ ID │ ORG │ ├────┼───────────┤ │ 1 │ Main Org. │ │ 2 │ DumbDumb │ │ 3 │ Moo │ └────┴───────────┘ Let&rsquo;s take a look at our context
---local: storage: &quot;&quot; enterprise_support: false url: http://localhost:3000 token: &quot;SomeTokenHere&quot; user_name: admin password: admin organization_id: 1 watched: - General - Other connections: credential_rules: - rules: - field: name regex: .* auth: user: user password: password datasources: {} filter_override: ignore_dashboard_filters: false output_path: test/data The organization_id is set to 1. In the configuration which matches &lsquo;Main Org.&rsquo; and is the default if unspecified.
Inspect Current Auth Org # Let&rsquo;s have a look at our Token.
gdg tools org tokenOrg ┌────┬───────────┐ │ ID │ NAME │ ├────┼───────────┤ │ 1 │ Main Org. │ └────┴───────────┘ This is an immutable value and may cause issues if we switch. Depending on the call the behavior is to give token preference or basic auth. So if the basic auth is succesfully namespace into a given org, the token will still point to the wrong one and cause issues. IF you wish to use Tokens, then avoid using basic auth.
We can also look at what our User Org is set to using:
gdg tools org userOrg ┌────┬───────────┐ │ ID │ NAME │ ├────┼───────────┤ │ 1 │ Main Org. │ └────┴───────────┘ This value though IS changeable.
List Dashboards # Now that we take a look at the dashboards under Org 1.
gdg b dash list INFO[0002] Listing dashboards for context: 'local' ┌─────┬──────────────────────────────┬──────────────────────────────┬─────────┬───────────┬──────────────┬────────────────────────────────────────────────────────────────┐ │ ID │ TITLE │ SLUG │ FOLDER │ UID │ TAGS │ URL │ ├─────┼──────────────────────────────┼──────────────────────────────┼─────────┼───────────┼──────────────┼────────────────────────────────────────────────────────────────┤ │ 166 │ Bandwidth Dashboard │ bandwidth-dashboard │ General │ 000000003 │ netsage │ http://localhost:3000/d/000000003/bandwidth-dashboard │ │ 167 │ Bandwidth Patterns │ bandwidth-patterns │ General │ 000000004 │ netsage │ http://localhost:3000/d/000000004/bandwidth-patterns │ │ 174 │ Dashboard Makeover Challenge │ dashboard-makeover-challenge │ Other │ F3eInwQ7z │ │ http://localhost:3000/d/F3eInwQ7z/dashboard-makeover-challenge │ │ 175 │ Flow Analysis │ flow-analysis │ Other │ VuuXrnPWz │ flow,netsage │ http://localhost:3000/d/VuuXrnPWz/flow-analysis │ │ 176 │ Flow Data for Circuits │ flow-data-for-circuits │ Other │ xk26IFhmk │ flow,netsage │ http://localhost:3000/d/xk26IFhmk/flow-data-for-circuits │ │ 177 │ Flow Data for Projects │ flow-data-for-projects │ Other │ ie7TeomGz │ │ http://localhost:3000/d/ie7TeomGz/flow-data-for-projects │ │ 178 │ Flow Data per Country │ flow-data-per-country │ Other │ fgrOzz_mk │ flow,netsage │ http://localhost:3000/d/fgrOzz_mk/flow-data-per-country │ │ 179 │ Flow Data per Organization │ flow-data-per-organization │ Other │ QfzDJKhik │ flow,netsage │ http://localhost:3000/d/QfzDJKhik/flow-data-per-organization │ │ 180 │ Flow Information │ flow-information │ Other │ nzuMyBcGk │ │ http://localhost:3000/d/nzuMyBcGk/flow-information │ │ 181 │ Flows by Science Discipline │ flows-by-science-discipline │ Other │ WNn1qyaiz │ flow,netsage │ http://localhost:3000/d/WNn1qyaiz/flows-by-science-discipline │ │ 169 │ Individual Flows │ individual-flows │ General │ -l3_u8nWk │ netsage │ http://localhost:3000/d/-l3_u8nWk/individual-flows │ │ 168 │ Individual Flows per Country │ individual-flows-per-country │ General │ 80IVUboZk │ netsage │ http://localhost:3000/d/80IVUboZk/individual-flows-per-country │ │ 170 │ Loss Patterns │ loss-patterns │ General │ 000000006 │ netsage │ http://localhost:3000/d/000000006/loss-patterns │ │ 171 │ Other Flow Stats │ other-flow-stats │ General │ CJC1FFhmz │ flow,netsage │ http://localhost:3000/d/CJC1FFhmz/other-flow-stats │ │ 172 │ Science Discipline Patterns │ science-discipline-patterns │ General │ ufIS9W7Zk │ flow,netsage │ http://localhost:3000/d/ufIS9W7Zk/science-discipline-patterns │ │ 173 │ Top Talkers Over Time │ top-talkers-over-time │ General │ b35BWxAZz │ │ http://localhost:3000/d/b35BWxAZz/top-talkers-over-time │ └─────┴──────────────────────────────┴──────────────────────────────┴─────────┴───────────┴──────────────┴────────────────────────────────────────────────────────────────┘ Switching Organizations # Switching context to Org 2.
gdg tools orgs set 2 INFO[0000] Succesfully set Org ID for context: local Let&rsquo;s confirm that we trully changed contexts.
gdg tools org userOrg ┌────┬───────────┐ │ ID │ NAME │ ├────┼───────────┤ │ 2 │ DumbDumb │ └────┴───────────┘ Listing Orgs Dashboards # Listing dashboards under Org 2 will result in an empty set.
gdg b dash list INFO[0000] Listing dashboards for context: 'local' INFO[0000] No dashboards found Let&rsquo;s switch back to org 1 and donwload our dashboards.
gdg tools orgs set 1 INFO[0000] Succesfully set Org ID for context: local Download Orgs Dashboards # gdg backup dash download INFO[0000] Importing dashboards for context: 'local' ┌───────────┬──────────────────────────────────────────────────────────────────────┐ │ TYPE │ FILENAME │ ├───────────┼──────────────────────────────────────────────────────────────────────┤ │ dashboard │ test/data/org_1/dashboards/General/bandwidth-dashboard.json │ │ dashboard │ test/data/org_1/dashboards/General/bandwidth-patterns.json │ │ dashboard │ test/data/org_1/dashboards/Other/dashboard-makeover-challenge.json │ │ dashboard │ test/data/org_1/dashboards/Other/flow-analysis.json │ │ dashboard │ test/data/org_1/dashboards/Other/flow-data-for-circuits.json │ │ dashboard │ test/data/org_1/dashboards/Other/flow-data-for-projects.json │ │ dashboard │ test/data/org_1/dashboards/Other/flow-data-per-country.json │ │ dashboard │ test/data/org_1/dashboards/Other/flow-data-per-organization.json │ │ dashboard │ test/data/org_1/dashboards/Other/flow-information.json │ │ dashboard │ test/data/org_1/dashboards/Other/flows-by-science-discipline.json │ │ dashboard │ test/data/org_1/dashboards/General/individual-flows.json │ │ dashboard │ test/data/org_1/dashboards/General/individual-flows-per-country.json │ │ dashboard │ test/data/org_1/dashboards/General/loss-patterns.json │ │ dashboard │ test/data/org_1/dashboards/General/other-flow-stats.json │ │ dashboard │ test/data/org_1/dashboards/General/science-discipline-patterns.json │ │ dashboard │ test/data/org_1/dashboards/General/top-talkers-over-time.json │ └───────────┴──────────────────────────────────────────────────────────────────────┘ Please note the path has org_1 in the path. Starting with version 0.5 of GDG we always namespace the entities we back by the org they belong to.
`}),e.add({id:6,href:"/gdg/docs/templating/",title:"Templating Docs",description:"",content:""}),e.add({id:7,href:"/gdg/docs/tutorials/",title:"Tutorials",description:"",content:""}),e.add({id:8,href:"/gdg/docs/gdg/getting_started/",title:"Getting Started",description:`Setup new configuration # You can create new context configuration using an interactive setup.
$ ./bin/gdg tools ctx new mycontext When creating a new context, you will be asked for authorization type, your default datasource and username/password, along with which folders you wish to manage under the context. You have three options:
Default option (&ldquo;General&rdquo;) List of folders you wish to manage Wildcard configuration (all folders) Import / Download Dashboards # Minimal configuration (eg.`,content:"Setup new configuration # You can create new context configuration using an interactive setup.\n$ ./bin/gdg tools ctx new mycontext When creating a new context, you will be asked for authorization type, your default datasource and username/password, along with which folders you wish to manage under the context. You have three options:\nDefault option (&ldquo;General&rdquo;) List of folders you wish to manage Wildcard configuration (all folders) Import / Download Dashboards # Minimal configuration (eg. the importer.yml file) that you need to download your dashboards from your Grafana endpoint:\ncontext_name: all contexts: all: url: https://grafana.example.org token: &quot;&lt;&lt;Grafana API Token&gt;&gt;&quot; # user_name: admin # password: admin output_path: exports watched: - Example - Infrastructure global: debug: true ignore_ssl_errors: false You need to adjust three parts in the configuration in order to function:\nGrafana URL: This is just a URL where your Grafana is available. API Key OR Username / Passoword for Admin user. See authentication section if you need more information. Downloaded Folders: The watched field defines folders which will be considered for manipulation. You can see these folders in your Grafana Web UI, under Dashboards &gt; Management. From there, you can simply define the folders you want to be downloaded in the watched list. The dashboards are downloaded as JSON files in the $OUTPUT_PATH/dashboards/$GRAFANA_FOLDER_NAME directory. Where $OUTPUT_PATH is the path defined in the dashboard_output configuration property and $GRAFANA_FOLDER_NAME the name of the folder from which the dashboards were downloaded After you are done, and you can execute ./bin/gdg dash list successfully, eg.:\n$ ./bin/gdg dash list time=&quot;2021-08-22T11:11:27+02:00&quot; level=warning msg=&quot;Error getting organizations: HTTP error 403: returns {\\&quot;message\\&quot;:\\&quot;Permission denied\\&quot;}&quot; time=&quot;2021-08-22T11:11:28+02:00&quot; level=info msg=&quot;Listing dashboards for context: 'all'&quot; ┌────┬───────────────────────────────────┬───────────────────────────────────┬────────────────┬────────────┬────────────────────────────────────────────────────────────────────────────┐ │ ID │ TITLE │ SLUG │ FOLDER │ UID │ URL │ ├────┼───────────────────────────────────┼───────────────────────────────────┼────────────────┼────────────┼────────────────────────────────────────────────────────────────────────────┤ │ 8 │ AWS CloudWatch Logs │ aws-cloudwatch-logs │ Infrastructure │ AWSLogs00 │ https://grafana.example.org/d/AWSLogs00/aws-cloudwatch-logs │ │ 6 │ AWS ECS │ aws-ecs │ Infrastructure │ ly9Y95XWk │ https://grafana.example.org/d/ly9Y95XWk/aws-ecs │ │ 5 │ AWS ELB Application Load Balancer │ aws-elb-application-load-balancer │ Infrastructure │ bt8qGKJZz │ https://grafana.example.org/d/bt8qGKJZz/aws-elb-application-load-balancer │ │ 4 │ AWS RDS │ aws-rds │ Infrastructure │ kCDpC5uWk │ https://grafana.example.org/d/kCDpC5uWk/aws-rds │ │ 3 │ AWS S3 │ aws-s3 │ Infrastructure │ AWSS31iWk │ https://grafana.example.org/d/AWSS31iWk/aws-s3 │ │ 17 │ Cluster Autoscaling │ cluster-autoscaling │ Example │ iHUYtABMk │ https://grafana.example.org/d/iHUYtABMk/cluster-autoscaling │ └────┴───────────────────────────────────┴───────────────────────────────────┴────────────────┴────────────┴────────────────────────────────────────────────────────────────────────────┘ After executing ./bin/gdg dash import you can find the dashboards of the Infrastructure folder in the local directory dashboards/dashboards/Infrastructure and the dashboards of the Example directory in the local directory dashboards/dashboards/Example.\nExport / Upload Dashboards # Minimal configuration (eg. the importer.yml file) that you need to upload your dashboards from your Grafana endpoint:\ncontext_name: all contexts: all: url: https://grafana.example.org token: &quot;&lt;&lt;Grafana API Token&gt;&gt;&quot; # user_name: admin # password: admin output_path: exports watched: - Example - Infrastructure global: debug: true ignore_ssl_errors: false You need to adjust three parts in the configuration in order to function:\nGrafana URL: This is just a URL where your Grafana is available. API Key OR Username / Passoword for Admin user. See authentication section if you need more information. Uploaded Folders: The watched field defines folders which will be considered for manipulation. The dashboards should be stored as JSON files in the $OUTPUT_PATH/dashboards/$GRAFANA_FOLDER_NAME directory. Where $OUTPUT_PATH is the path defined in the dashboard_output configuration property and $GRAFANA_FOLDER_NAME the name of the folder to which the dashboards will be uploaded. In case of the above configuration file, the dashboards should be stored locally in the dashboards/dashboards/Example and dashboards/dashboards/Infrastructure/ directories. ├── bin | └── gdg └── exports └── dashboards ├── Example | └── cluster-scaling.json └── Infrastructure └── aws-ecs.json You can execute ./bin/gdg dash export to upload the local dashboards to your Grafana. Afterwards, you can try running ./bin/gdg dash list in order to confirm that your dashboards were uploaded successfully.\n"}),e.add({id:9,href:"/gdg/docs/gdg/configuration/",title:"Configuration",description:`Getting started # This project requires Go to be installed. On OS X with Homebrew you can just run brew install go.
make a copy of config/importer-example.yml and name it config/importer.yml You&rsquo;ll need GRAFANA ADMINISTRATIVE privileges to proceed.
Authentication # Authentication Token # You can use an Authentication Token / API Key to authenticate with the Grafana API, which can be generated in your Grafana Web UI =&gt; Configuration =&gt; API Keys.`,content:`Getting started # This project requires Go to be installed. On OS X with Homebrew you can just run brew install go.
make a copy of config/importer-example.yml and name it config/importer.yml You&rsquo;ll need GRAFANA ADMINISTRATIVE privileges to proceed.
Authentication # Authentication Token # You can use an Authentication Token / API Key to authenticate with the Grafana API, which can be generated in your Grafana Web UI =&gt; Configuration =&gt; API Keys. You can then use it in your configuration file (eg. importer.yml).
👉 gdg is currently using viper to read in the config. Since viper makes all keys lowercase, we also have the same limitation. Camel case will be read in but be aware that a section named fooBar == Foobar == foobar etc. Service Accounts # Service Accounts are supported and interchangeable for tokens. If you wish to use a service account, simply put the token value from the service account for token:. Please make sure you&rsquo;ve granted the account the needed permissions for the operations you are trying to perform.
context_name: main contexts: main: url: https://grafana.example.org token: &quot;&lt;&lt;Grafana API Token&gt;&gt;&quot; output_path: &quot;myFolder&quot; ignore_filters: False # When set to true all Watched filtered folders will be ignored and ALL folders will be acted on watched: - Example connections: credential_rules: - rules: - field: &quot;name&quot; regex: &quot;misc&quot; - field: &quot;url&quot; value: &quot;.*esproxy2*&quot; secure_data: &quot;misc_auth.json&quot; - rules: - field: &quot;url&quot; regex: &quot;.*esproxy2*&quot; secure_data: &quot;proxy.json&quot; - rules: - field: &quot;name&quot; regex: &quot;.*&quot; secure_data: &quot;default.json&quot; global: debug: true ignore_ssl_errors: false Username / Password # You can also use username/password credentials of an admin user to authenticate with the Grafana API. You can specify them in your configuration file (eg. importer.yml).
context_name: main contexts: main: url: https://grafana.example.org user_name: &lt;your username&gt; password: &lt;your password&gt; output_path: &quot;myFolder&quot; watched: - Example global: debug: true ignore_ssl_errors: false Connection # Connection Credentials # Current Behavior (Version +0.5.2) # If the connection has BasicAuth enabled, then we&rsquo;ll attempt to set the auth with the following rules.
We will try to find a match given the rules specified:
field: matches any valid gjson path and retrieves it&rsquo;s value. ie. jsonData.maxConcurrentShardRequests and validates it against a golang supported Regex. It goes down the list of rules and returns the auth for the first matching one. The rules should be listed from more specific to more broad. The default rule ideally should be at the end. testing: output_path: testing_data connections: credential_rules: - rules: - field: &quot;name&quot; regex: &quot;misc&quot; - field: &quot;url&quot; regex: &quot;.*esproxy2*&quot; secure_data: &quot;default.json&quot; url: http://localhost:3000 user_name: admin password: admin ignore_filters: False # When set to true all Watched filtered folders will be ignored and ALL folders will be acted on watched: - General - Other the secure_data will read the file from {output_path}/secure/. It will then use that information to construct the datasource.
Default setting if you use basic auth is shown below.
{ &quot;basicAuthPassword&quot;: &quot;password&quot;, &quot;user&quot;: &quot;user&quot; } Version v0.4.2-v0.5.1 # Legacy Behavior Preview behavior did not support the use of a secure/secureData.json pattern, instead an auth: codeblock was used.
Please note that only basicAuth worked prior to version v0.5.2
Example can be seen below:
testing: output_path: testing_data connections: credential_rules: - rules: - field: name regex: .* auth: user: user password: secret url: http://localhost:3000 user_name: admin password: admin ignore_filters: False # When set to true all Watched filtered folders will be ignored and ALL folders will be acted on watched: - General - Other Version Prior to v0.4.2 # Legacy Behavior If the connection has BasicAuth enabled, then we&rsquo;ll attempt to set the auth with the following precedence on matches:
Match of DS credentials based on DS name. Match URL regex for the DS if regex specified. Use Default Credentials if the above two both failed. An example of a configuration can be seen below
testing: output_path: testing_data connections: credentials: default: user: user password: password misc: user: admin password: secret url_regex: .*esproxy2* url: http://localhost:3000 user_name: admin password: admin ignore_filters: False # When set to true all Watched filtered folders will be ignored and ALL folders will be acted on watched: - General - Other Connection Filters # Current Behavior (+v0.4.2) # You can filter based on any field and have it be an exclusive (default) or inclusive (ie Only allow values that match) to be listed/imported etc.
Pattern matching is the same as the Credentials mapping.
field represents any valid JSON Path regex: any valid regex supported by golang The example below will exclude any connections named &ldquo;Google Sheets&rdquo;. It will also only include connections with the type elasticsearch or mysql
contexts: testing: output_path: test/data connections: exclude_filters: - field: &quot;name&quot; regex: &quot;Google Sheets&quot; - field: &quot;type&quot; regex: &quot;elasticsearch|mysql&quot; inclusive: true Legacy Behavior # Legacy Behavior This feature allows you to exclude connection by name or include them by type. Please note that the logic switches based on the data type.
name filter:
... datasources: filters: name_exclusions: &quot;DEV-*|-Dev-*&quot; Will exclude any connection that matches the name regex.
Type Filter
Will ONLY include connection that are listed.
datasources: filters: valid_types: - elasticsearch The snippet above will ONLY import connections for elasticsearch
Notes # If you configure both, Auth Token and Username/Password, then the Token is given priority. Watched folders under grafana is a white list of folders that are being managed by the tool. By default only &ldquo;General&rdquo; is managed.
env.output defines where the files will be saved and imported from.
Global Flags # globals.debug when set will print a more verbose output (Development In Progress) globals.ignore_ssl_errors when set will disregard any SSL errors and proceed as expected
Environment Overrides # If you wish to override certain value via the environment, like credentials and such you can do so.
The pattern for GDG&rsquo;s is as follows: GDG_SECTION__SECTION__keyname
For example if I want to set the context name to a different value I can use:
GDG_CONTEXT_NAME=&quot;testing&quot; gdg tools ctx show ## Which will override the value from the context file. GDG_CONTEXTS__TESTING__URL=&quot;www.google.com&quot; Will override the URL with the one provided. NOTE: Complex data type are not supported, so if the value is an array it can&rsquo;t be currently set.
Building/Running the app # Running it then should be as simple as:
$ task build_all $ ./bin/gdg ## main binary $ ./bin/gdg-generate ## Dashboard Templating engine Requires task to be installed locally
`}),e.add({id:10,href:"/gdg/docs/gdg/cloud_configuration/",title:"Cloud Configuration",description:`Cloud Support # Support for using a few cloud providers as a storage engine is now supported. When enabled, the local file system is only used for reading configuration files. Everything else relies on the data from the cloud provider matching up to your configuration.
Currently the following providers are supported:
AWS S3 Google Storage (GS) Azure Custom (S3 Compatible clouds) 👉 https://github.com/google/go-cloud was used to support all of these providers.`,content:`Cloud Support # Support for using a few cloud providers as a storage engine is now supported. When enabled, the local file system is only used for reading configuration files. Everything else relies on the data from the cloud provider matching up to your configuration.
Currently the following providers are supported:
AWS S3 Google Storage (GS) Azure Custom (S3 Compatible clouds) 👉 https://github.com/google/go-cloud was used to support all of these providers. They should all work, but only S3 and Google have been properly tested. Most of these rely on the system configuration. Here are some references for each respective environment:
Google Storage: https://cloud.google.com/docs/authentication#service-accounts https://cloud.google.com/docs/authentication/provide-credentials-adc#local-user-cred S3: https://docs.aws.amazon.com/sdk-for-go/api/aws/session/ Azure: https://pkg.go.dev/github.com/Azure/azure-sdk-for-go/sdk/storage/azblob Cloud Configuration # General # storage_engine: any_label: kind: cloud cloud_type: [s3, gs, azblob] bucket_name: &quot;&quot; prefix: &quot;dummy&quot; All authentication and authorization is done outside of GDG.
Custom # Examples of these S3 compatible clouds would be minio and Ceph.
storage_engine: some_label: custom: true ## Required, if set to true most of the 'custom' configuration will be disregarded. kind: cloud cloud_type: s3 prefix: dummy bucket_name: &quot;mybucket&quot; access_id: &quot;&quot; ## this value can also be read from: AWS_ACCESS_KEY. config file is given precedence secret_key: &quot;&quot; ## same as above, can be read from: AWS_SECRET_KEY with config file is given precedence. init_bucket: &quot;true&quot; ## Only supported for custom workflows. Will attempt to create a bucket if one does not exist. endpoint: &quot;http://localhost:9000&quot; region: us-east-1 ssl_enabled: &quot;false&quot; for custom cloud, the cloud type will be s3, access_id and secret_key are needed and ONLY supported for the custom cloud. Additionally, the custom flag needs to be set to true.
init_bucket is another custom only feature that will attempt to create a bucket if one does not exist. endpoint is a required parameter though it does have a fallback to localhost:9000 region defaults to us-east-1 if not configured. Context Configuration # This is applicable both standard clouds and cusom. The only additional change to the context is to provide a storage label to use:
testing: output_path: testing_data ... storage: any_label ... So given the bucket name of foo with a prefix of bar with the output_path configured as testing_data the connections will be imported to:
s3://foo/bar/testing_data/connections/ and exported from the same location. If you need it to be in a different location you can update the prefix accordingly but at destination will follow the typical app patterns.
`}),e.add({id:11,href:"/gdg/docs/gdg/backup_guide/",title:"Backup Commands Guide",description:`Every namespace supporting CRUD operations has the functions: list, download, upload, clear operating on only the monitored folders.
Alert Notifications (DEPRECATED) # This will stop working soon both as a concept in grafana and something that GDG will support.
Allows you to manage alertnotifications (an) if you have any setup
./bin/gdg backup an list -- Lists all alert notifications ./bin/gdg backup an download -- retrieve and save all alertnotifications from grafana .`,content:`Every namespace supporting CRUD operations has the functions: list, download, upload, clear operating on only the monitored folders.
Alert Notifications (DEPRECATED) # This will stop working soon both as a concept in grafana and something that GDG will support.
Allows you to manage alertnotifications (an) if you have any setup
./bin/gdg backup an list -- Lists all alert notifications ./bin/gdg backup an download -- retrieve and save all alertnotifications from grafana ./bin/gdg backup an upload -- writes all local alert notifications to grafana ./bin/gdg backup an clear -- Deletes all alert notifications Connections # (was: DataSources) # Note: Starting with 0.4.6 this was renamed to connections.
Connections credentials are keyed by the name of the DataSource. See see config example. If the connection JSON doesn&rsquo;t have auth enabled, the credentials are ignored. If Credentials are missing, we&rsquo;ll fall back on default credentials if any exist. The password is set as a value for basicAuthPassword in the API payload. Datasources are imported or exported from organization specified in configuration file otherwise current organization user is used.
All commands can use connection or c to manage datasources. (Legacy options of datasource and ds are also supported)
./bin/gdg backup c list -- Lists all current connections ./bin/gdg backup c download -- Import all connections from grafana to local file system ./bin/gdg backup c upload -- Exports all dashboard from local filesystem (matching folder filter) to Grafana ./bin/gdg backup c clear -- Deletes all connections Dashboards # Dashboards are imported or exported from organization specified in configuration file otherwise current organization user is used.
All commands can use dashboards or dash to manage dashboards
./bin/gdg backup dash list -- Lists all current dashboards ./bin/gdg backup dash download -- Import all dashboards from grafana to local file system ./bin/gdg backup dash upload -- Exports all dashboard from local filesystem (matching folder filter) to Grafana ./bin/gdg backup dash clear -- Deletes all dashboards You can also use filtering options to list or import your dashboard by folder or by tags.
./bin/gdg backup dash download -f myFolder ./bin/gdg backup dash download -t myTag ./bin/gdg backup dash download -t tagA -t tagB -t complex,tagC The command above will return any dashboard that is tagged with tagA or tagB or complex,tagC
NOTE: Starting with v0.5.2 full crud support for tag filtering. You can list,upload,clear,download dashboards using tag filters. Keep in mind the tag filtering on any matching tags. ie. Any dashboard that has tagA or tagB or complex,tagC will be listed,uploaded, etc.
Folders # Mostly optional as Dashboards will create/delete these are needed but if there is additional metadata you wish to persist you can use this to manage them.
./bin/gdg backup folders list -- Lists all current folders ./bin/gdg backup folders download -- Import all folders from grafana to local file system ./bin/gdg backup folders upload -- Exports all folders from local filesystem ./bin/gdg backup folders clear -- Deletes all folders Folder Permissions # This CRUD allows you to import / export folder permissions. Initial release will be part of v0.4.4. There are a lot of nested relationship that go with this.
Expectations:
Users have to already exist. Teams (if used) need to already exist. Folders also need to already exist. The Folder Permissions will list, import and re-apply permissions. But the expectations is that all other entities are already there. Next few iteration will try to add more concurrency for this tool and more error checking when entities that don&rsquo;t exist are being referenced.
NOTE: Unlike other command, permissions does not have a clear function. Theoretically you could have a folder name with an emtpy array under folder-permissions to clear all known permissions to the folder, but otherwise clearing permissions from all folders seems too destructive to really be a useful function.
./bin/gdg backup folders list -- Lists all current folder permissions ./bin/gdg backup folders download -- Retrieve all folders permissions from Grafana ./bin/gdg backup folders upload -- Exports all folders from local filesystem ┌───────────┬──────────────────────────────────────┬───────────────────────────────────────────────────────────────────────────────────┬─────────────┬────────────────────────────────┬────────┬─────────────────┐ │ FOLDER ID │ FOLDERUID │ FOLDER NAME │ USERID │ TEAM NAME │ ROLE │ PERMISSION NAME │ ├───────────┼──────────────────────────────────────┼───────────────────────────────────────────────────────────────────────────────────┼─────────────┼────────────────────────────────┼────────┼─────────────────┤ │ 2272 │ dfba969d-565b-481e-a930-53aa5684992c │ sub-flow │ │ │ │ │ │ │ PERMISSION---&gt; │ admin │ │ Admin │ │ 520 │ GPmSOQNnk │ EngageMap (internal beta) │ │ │ │ │ │ │ PERMISSION---&gt; │ │ Admin │ Edit │ │ │ PERMISSION---&gt; │ │ Editor │ Edit │ │ │ PERMISSION---&gt; │ │ Viewer │ View │ │ 2031 │ n3xS8TwVk │ Team CMS - US dumb dumb │ │ │ │ │ │ │ PERMISSION---&gt; │ │ authscope_team_cms │ │ Edit │ │ 1746 │ pASPyoQVk │ Team DOE-IN-PNNL - DOE-IN Pacific Northwest National Laboratory │ │ │ │ │ └──────────────────────────────────────────────────┴───────────────────────────────────────────────────────────────────────────────────┴─────────────┴────────────────────────────────┴────────┴─────────────────┘ The listing includes the folder name, followed by several lines with &ldquo;PERMISSION&mdash;&gt;&rdquo; which will each list a permission. It can a user being granted access or a team being granted a role etc.
Library Elements # Library elements are components that can be shared among multiple dashboards. Folder matching will still be applied, so any folders not monitored will be ignored unless explicitly specified. If wildcard flag is enabled, all elements will be acted on irrelevant of folder location
All commands can use libraryelements aliased to library and lib for laziness purposes.
./bin/gdg backup lib list -- Lists all library components ./bin/gdg backup lib download -- Import all library components from grafana to local file system ./bin/gdg backup lib upload -- Exports all library components from local filesystem (matching folder filter) to Grafana ./bin/gdg backup lib clear -- Deletes all library components ./bin/gdg backup lib list-connections &lt;Lib Element UID&gt; -- Will list all of the dashboards connected to the Lib Element (Coming in v0.4.2) Organizations # Auth: Requires Grafana Admin (Tokens not supported, Org Admins don&rsquo;t have access) # Command can use organizations or org to manage organizations.
NOTE: this only manages top level of the orgs structure. It&rsquo;s mainly useful to maintain consistency.
./bin/gdg backup org list -- Lists all organizations ./bin/gdg backup org upload -- Upload Orgs to grafana ./bin/gdg backup org download -- Download Orgs to grafana Teams # 👉 Admin team members are unable to be exported back. Currently all members except the server admin will be exported as regular members 👉 Users need to be created before team export can succeed ./bin/gdg backup team list -- Lists all known team members ./bin/gdg backup team download -- download all known team members ./bin/gdg backup team upload -- upload all known team members ./bin/gdg backup team clear -- Delete all known team except admin Team Listing ┌────┬───────────┬───────┬───────┬─────────┬─────────────┬──────────────┬───────────────────┐ │ ID │ NAME │ EMAIL │ ORGID │ CREATED │ MEMBERCOUNT │ MEMBER LOGIN │ MEMBER PERMISSION │ ├────┼───────────┼───────┼───────┼─────────┼─────────────┼──────────────┼───────────────────┤ │ 4 │ engineers │ │ 1 │ 2 │ │ │ │ │ │ │ │ │ │ admin │ Admin │ │ │ │ │ │ │ │ tux │ Member │ │ │ 5 │ musicians │ │ 1 │ 1 │ │ │ │ │ │ │ │ │ │ admin │ Admin │ │ └────┴───────────┴───────┴───────┴─────────┴─────────────┴──────────────┴───────────────────┘ Users # Only supported with basic auth. Users is the only one where basic auth is given priority. API Auth is not supported, so will try to use basic auth if configured otherwise will warn the user and exit.
NOTE: admin user is always ignored.
./bin/gdg backup users list -- Lists all known users ./bin/gdg backup users download -- Lists all known users ./bin/gdg backup users upload -- Export all users (Not yet supported) ./bin/gdg backup users clear -- Delete all known users except admin `}),e.add({id:12,href:"/gdg/docs/gdg/tools_guide/",title:"Tools Guide",description:`This guide focuses on the &rsquo;tools&rsquo; subcommand. Every command that isn&rsquo;t specific to a CRUD operation falls under the tools command.
There are a few utility functions that have been introduced that might be useful to the user, or is geared at managing the configuration, switching contexts or Orgs for a given user and so on.
Authentication Management # This is mainly added as a convenience mechanism. It was needed to support some testing and exposing the feature is useful as a really simple CLI to create tokens / service Keys.`,content:`This guide focuses on the &rsquo;tools&rsquo; subcommand. Every command that isn&rsquo;t specific to a CRUD operation falls under the tools command.
There are a few utility functions that have been introduced that might be useful to the user, or is geared at managing the configuration, switching contexts or Orgs for a given user and so on.
Authentication Management # This is mainly added as a convenience mechanism. It was needed to support some testing and exposing the feature is useful as a really simple CLI to create tokens / service Keys. You probably should be using other tooling for managing all your service files and tokens. Unlike most other entities, this is not a backup feature as much as utility.
There are two sub commands for auth, service-accounts and tokens (will be deprecated at some point).
Token Management # ./bin/gdg tools auth tokens list -- list current tokens (No access to the actual token secret) ./bin/gdg tools auth tokens new -- Create a new token. new &lt;name&gt; &lt;role&gt; [ttl in seconds, forever otherwise] ./bin/gdg tools auth tokens clear -- Deletes all tokens Token Listing ┌────┬─────────┬───────┬───────────────┐ │ ID │ NAME │ ROLE │ EXPIRATION │ ├────┼─────────┼───────┼───────────────┤ │ 1 │ testing │ Admin │ No Expiration │ └────┴─────────┴───────┴───────────────┘ Example of creating a new token.
./bin/gdg auth tokens new foobar Admin 3600 New Token ┌────┬────────┬─────────────────────────────────────────────────────────────┐ │ ID │ NAME │ TOKEN │ ├────┼────────┼─────────────────────────────────────────────────────────────┤ │ 2 │ foobar │ eyJrIjoiNzU2WVhiMEZpVWNlV3hWSUVZQTuIjoiZm9vYmFyIiwiaWQiOjF9 │ └────┴────────┴─────────────────────────────────────────────────────────────┘ Service Accounts # ./bin/gdg tools auth svc clear delete all Service Accounts ./bin/gdg tools auth svc clearTokens delete all tokens for Service Account ./bin/gdg tools auth svc list list API Keys ./bin/gdg tools auth svc newService newService &lt;serviceName&gt; &lt;role&gt; [ttl in seconds] ./bin/gdg tools auth svc newToken newToken &lt;serviceAccountID&gt; &lt;name&gt; [ttl in seconds] ./bin/gdg tools auth svc newService AwesomeSauceSvc admin New Service ┌────┬─────────────────┬───────┐ │ ID │ NAME │ ROLE │ ├────┼─────────────────┼───────┤ │ 4 │ AwesomeSauceSvc │ Admin │ └────┴─────────────────┴───────┘ ./bin/gdg tools auth svc newToken 4 AwesomeToken New Service ┌───────────┬──────────┬──────────────┬────────────────────────────────────────────────┐ │ SERVICEID │ TOKEN_ID │ NAME │ TOKEN │ ├───────────┼──────────┼──────────────┼────────────────────────────────────────────────┤ │ 4 │ 3 │ AwesomeToken │ glsa_a14JOaGExOkDuJHjDWScXbxjTBIXScsw_39df7bf5 │ └───────────┴──────────┴──────────────┴────────────────────────────────────────────────┘ ./bin/gdg tools auth svc list Service Listing ┌────┬─────────────────┬───────┬────────┬──────────┬──────────────┬───────────────┐ │ ID │ SERVICE NAME │ ROLE │ TOKENS │ TOKEN ID │ TOKEN NAME │ EXPIRATION │ ├────┼─────────────────┼───────┼────────┼──────────┼──────────────┼───────────────┤ │ 4 │ AwesomeSauceSvc │ Admin │ 1 │ │ │ │ │ │ │ │ │ 3 │ AwesomeToken │ No Expiration │ └────┴─────────────────┴───────┴────────┴──────────┴──────────────┴───────────────┘ Devel # Some developer helper utilities
./bin/gdg tools devel completion [bash|fish|powershell|zsh] -- Will generate autocompletion for GDG for your favorite shell ./bin/gdg tools devel srvinfo -- print grafana server info Organizations # Command can use organizations or org to set the organizations in the configuration file.
NOTE: this only manages top level of the orgs structure. Mainly used for a lazy man pattern.
./bin/gdg tools org set &lt;orgID&gt; -- Sets a given Org filter. All Dashboards and Datasources etc are uploaded to the given Org only. Users # CRUD is under the &lsquo;backup&rsquo; command. The tools allows you to promote a given user to a grafana admin if you have the permission to do so.
NOTE: admin user is always ignored.
./bin/gdg tools users promote -u user@foobar.com -- promotes the user to a grafana admin `}),e.add({id:13,href:"/gdg/docs/gdg/enterprise_guide/",title:"Enterprise User Guide",description:`The features listed below are for the enterprise edition of Grafana only. They will not work on the OSS version.
In order to use these features you need.
Update your context to enable enterprise features. Simply add the following flag to your context. enterprise_support: true
Have a running Enterprise version of grafana, I&rsquo;ll defer to the grafana community on instructions on how to set this up. Connections Permissions # Note: Available with +v0.`,content:`The features listed below are for the enterprise edition of Grafana only. They will not work on the OSS version.
In order to use these features you need.
Update your context to enable enterprise features. Simply add the following flag to your context. enterprise_support: true
Have a running Enterprise version of grafana, I&rsquo;ll defer to the grafana community on instructions on how to set this up. Connections Permissions # Note: Available with +v0.4.6. All of these commands are a subset of the connection command.
All commands can use permission or p to manage connection permissions.
./bin/gdg c permission list -- Lists all current connections permissions ./bin/gdg c permission download -- Download all connections from grafana to local file system ./bin/gdg c permission upload -- Exports all dashboard from local filesystem (matching folder filter) to Grafana ./bin/gdg c permission clear -- Deletes all connections Permissions (Leaving only the default values) You can additionally filter by connection slug in order to only operate on a single connection.
./bin/gdg c permission list --connection my-elastic-connection ┌─────┬───────────┬──────────────────────────────────────────┬───────────────────────────────────────────────┬───────────────────────┬────────────────────────────────────────────┐ │ ID │ UID │ NAME │ SLUG │ TYPE │ DEFAULT │ URL │ ├─────┼───────────┼──────────────────────────────────────────┼──────────────────────────┼────────────────────┼───────────────────────┼────────────────────────────────────────────┤ │ 712 │ t5xBsTQ4k │ My Elastic Connection │ my-elastic-connection │ elasticsearch │ false │ http://localhost:3000//datasource/edit/712 │ │ 712 │ t5xBsTQ4k │ PERMISSION--&gt; │ Edit │ │ sa-gdg-authscope-test │ │ │ 712 │ t5xBsTQ4k │ PERMISSION--&gt; │ Query │ │ authscope_team_arm │ │ └─────┴───────────┴──────────────────────────────────────────┴──────────────────────────┴────────────────────┴───────────────────────┴────────────────────────────────────────────┘ `}),e.add({id:14,href:"/gdg/docs/gdg/other_commands/",title:"Other Commands",description:`These are miscellaneous commands that don&rsquo;t fit under any category.
Contexts # Starting with version 0.1.4 contexts are now supported. Your config can contain one or multiple contexts which are essentially a grafana server configuration.
ctx is shorthand for context and basic CRUD is supported which is mainly tooling to make it easier to avoid updating the yaml file manually
./bin/gdg tools ctx list -- Lists all known contexts ./bin/gdg tools ctx show qa -- shows the configuration for the selected context .`,content:`These are miscellaneous commands that don&rsquo;t fit under any category.
Contexts # Starting with version 0.1.4 contexts are now supported. Your config can contain one or multiple contexts which are essentially a grafana server configuration.
ctx is shorthand for context and basic CRUD is supported which is mainly tooling to make it easier to avoid updating the yaml file manually
./bin/gdg tools ctx list -- Lists all known contexts ./bin/gdg tools ctx show qa -- shows the configuration for the selected context ./bin/gdg tools ctx set production -- updates the active config and sets it to the request value. ./bin/gdg tools ctx delete qa -- Deletes the QA context ./bin/gdg tools ctx cp qa staging -- copies the qa context to staging and sets it as active ./bin/gdg tools ctx clear -- Will delete all active contexts leaving only a single example entry Version # Print the applications release version
./bin/gdg version Build Date: 2022-05-05-13:27:08 Git Commit: 34cc84b3d80080aa93e74ed37739bddc3638997c+CHANGES Version: 0.1.11 Go Version: go1.18 OS / Arch: darwin amd64 `}),e.add({id:15,href:"/gdg/docs/gdg/developer/",title:"Developer Guide",description:`Running Tests # Bring up a grafana instance locally with default credentials of admin/admin. docker-compose up -d grafana Once the instance is up simply run go test ./... or make test Making a release # Install goreleaser.
brew install goreleaser/tap/goreleaser brew reinstall goreleaser\` Alternatively if you have a more recent version of Go.
go install github.com/goreleaser/goreleaser@latest export your GITHUB_TOKEN.
export GITHUB_TOKEN=&quot;secret&quot; git tag v0.1.0 goreleaser release
NOTE: CI/CD pipeline should do all this automatically.`,content:`Running Tests # Bring up a grafana instance locally with default credentials of admin/admin. docker-compose up -d grafana Once the instance is up simply run go test ./... or make test Making a release # Install goreleaser.
brew install goreleaser/tap/goreleaser brew reinstall goreleaser\` Alternatively if you have a more recent version of Go.
go install github.com/goreleaser/goreleaser@latest export your GITHUB_TOKEN.
export GITHUB_TOKEN=&quot;secret&quot; git tag v0.1.0 goreleaser release
NOTE: CI/CD pipeline should do all this automatically. make release-snapshot is used to test the release build process. Once a build is tagged all artifacts should be built automatically and attached to the github release page.
NOTE: mac binary are not signed so will likely complain.
`}),e.add({id:16,href:"/gdg/docs/releases/gdg_0.5/",title:"version v0.5",description:"Release Notes for v0.5",content:`Release Notes for v0.5.2 # Changes # #229 Datasource auth has been moved to a file based configuration under secure/. This allows for any number of secure values to be passed in. Using the wizard for initial config is recommended, or see test data for some examples. #168 Introduced a new tool called gdg-generate which allows for templating of dashboards using go.tmpl syntax. gdg context has been moved under tools. ie. gdg tools ctx instead of gdg ctx #221 Version check no longer requires a valid configuration #236 Dashboard filter by tag support. Allows a user to only list,delete,upload dashboards that match a set of given tags. Bug Fixes # #235 Fixed a bug that prevented proxy grafana instances from working correctly. ie. someURL/grafana/ would not work since it expected grafana to hosted on slash (/). Developer Changes # Migrated to Office Grafana GoLang API refactored packages, moving cmd-&gt; cli, and created cmd/ to allow for multiple binaries to be generated. Release Notes for v0.5.1 # Release Date: 11/03/2023
Changes # TechDebt: Rewriting the CLI flag parsing to allow for easier testing patterns. Should mostly be transparent to the user. OrgWatchedFolders added a way to override watched folders for a given organization #93 Homebrew support added in. First pass at having a homebrew release. Bug Fixes # Tiny patch to fix website documentation navigatioin #205 fixes invalid cross-link device when symlink exists to /tmp filesystem. #206 fixed behavior issue Developer Changes # Replaced Makefile with Taskfiles. Added dockertest functionality. Allows for a consistent testing pattern on dev and CI. postcss security bug. Added a new integration pattern to allow all tests to be executed with tokens and basicauth to ensure behavior is consistent when expected Notes on 0.5.x # This is going to be a fairly big release and changing several of the expectations that GDG had before.
The main push for this was to support organizations a bit better, and the only way to really do this correctly was to change the destination path of where the orgs are being saved. Every entity that supports organization will now be namespace by the org it belongs to. This will now allow GDG to manage connections and dashboards across multiple organizations.
The other big change, is that most feature are now namespaced under either &lsquo;backup&rsquo; or &rsquo;tools&rsquo; with the exception context which a GDG concept. The intent of the CLI was getting a bit murky. There is functionality to create a service account, modify a user permission and so on which is a good bit different from the initial intent of GDG which was to simply manage entities. Any additional features beyond the crud are under tools. This might be split into two different binaries later down the line but the separation helps clarify the intent.
Datasources have also been deprecated in favor of &lsquo;Connections&rsquo; to match the Grafana naming convention changes.
Release Notes for v0.5.0 # Release Date: 09/01/2023
Changes # Adding support for Basic CRU for Orgs #179 Renamed &lsquo;DataSources&rsquo; command to &lsquo;Connections&rsquo; to match Grafana&rsquo;s naming convention. Connection Permissions are now supported. This is an enterprise features and will only function if you have an enterprise version of grafana. Enterprise features are enabled by setting enterprise_support: true for a given context. #166 Namespacing all supported entities by organization. Add support for custom S3 Provider (ie. enables ceph, minio and other S3 compatible providers to work with GDG), related discussion Technical Debt # Misc dependencies updates for website and gdg dependencies. Clean up of the Storage interface Updated CICD to only pushed documentation changes on tag release. Bug Fixes # Fixed issue with import team member with elevated permissions. #149 Breaking Changes # datasources have been renamed as connections. If you have an existing backup, simply rename the folder to &lsquo;connections&rsquo; and everything should continue working. All Orgs namespaced backups (ie. everything except users and orgs) need to be moved under their respective org folder. ie. org_1 where the given Org has an ID of 1. All commands have now been moved under &lsquo;backup&rsquo; or &rsquo;tools&rsquo; to better reflect their functionality. #183 organization config is deprecated in favor of organization_id. `}),e.add({id:17,href:"/gdg/docs/releases/gdg_0.4/",title:"version v0.4",description:"Release Notes for v0.4",content:`Release Notes for v0.4.5 # Release Date: 07/13/2023
Changes: # Fixing broken CICD release process Release Notes for v0.4.4 # Release Date: 07/13/2023
Changes # #159 Due to confusion that has been generated with using import/export. The action verbs were replaced with download/upload with the previous cmds still left in as functional elements. All &lsquo;import&rsquo; has been replaced with &lsquo;download&rsquo; action. All &rsquo;export&rsquo; has been replaced with an &lsquo;upload&rsquo; action. #160 Removed deprecated configuration patterns. Removed datasources.credentials and datasources.filters #167 Adding support for Folder Permissions #170 OS level characters are no longer supported in folders. For example &lsquo;/&rsquo; and &lsquo;' will not be support in any folder GDG backs up. The behavior combined with the mkdir / path command is too buggy to really allow such characters in the names. The complexity in code needed to support it vs just disallowing it isn&rsquo;t worth it. Bug Fixes # Bug #156 fixed. When gdg binary and config are in completely different paths, gdg is unable to load the configuration file and fallsback on the default config instead. BUG #170 fixed. Added disallowed characters. For example &ldquo;/&rdquo; and &ldquo;&quot; will not be supported in folder names Some calls failed with invalid SSL. Fixed secondary code path to also support unsigned SSL Release Notes for v0.4.3 # Release Date: 04/14/2023
New Features # Team CRUD support, allows full CRUD on all team and members. Fixes #127 and #147 Known Bug: Permissioning not persisted. All users are added as a member. See issue 149 CLI Tooling introduced to faciliate very basic service management, and token creations for both services and API tokens. Improved Credential mapping and filtering introduced. Allows filtering and credential mapping to be based on any JSON field and regex. Configuration Changes # DataSource has had a configuration overhaul. It is technically backward compatible, all previous tests work, with the previous config, but I would highly encourage people to migrate. Next feature I will drop the backward support. URLMatching for Credentials will not work (legacy pattern) if the URL AND the datasource do not match. If you need URL matching with variable datasource names, you will need to migrate to the new configuration. Release Notes for v0.4.2 # Issue with release, failed CI, so skipping version.
Release Notes for v0.4.1 # Release Date: 04/01/2023
New Features # Library Elements Connections # Added support for libraryelement connections. This option allows you to see what dashboards are using the given library. note: You won&rsquo;t be able to delete the library element while there are dashboards utilizing it. Bug Fixes # FIXED: Addressing Login issue when Basic Auth is omitted. #144 Release Notes for v0.4.0 # Release Date: 03/31/2023
This is a major change from the previous one, I&rsquo;ll likely cut the 1.x soon and start following the more typical Semver conventions. Aka Major version is a breaking change, Minor is just that, patches for previous versions.
Please see the API Changes notes below.
New Features # Wild card flag # You can now set a flag under each context that will ignore Watched Folders and retrieve all dashboards.
context_name: filter_override: ignore_dashboard_filters: false # LibraryElements support added. # Please see the usage guide here and a brief tutorial available here
Folders Update # Introducing a &ndash;use-filters. When enabled will only operate on folders configured. Default is to create/update/delete all folders in the grafana instance.
Breaking Changes: # SFTP support dropped. # See the Cloud configuration section. Switched out the library we relied on, which means the auth has moved out of GDG config and relies on the system config.
API SDK Changes: # I have been trying to find a proper library to use so I&rsquo;m not re-writing and reinventing the wheel so to speak.
For reference, here are all the current &ldquo;active&rdquo; (active can be a relative term for some of these project) development I&rsquo;m aware of.
Grafana Tools SDK Initial version of GDG was based on this project. It mostly works but getting any PRS accepted can be tedious and it&rsquo;s needs some help. Grafana API Go Client Owned by the Grafana Org which is nice, but it has a slightly different goal. It&rsquo;s primary goal is to support the terraform provider for Grafana. I also found some endpoints missing very early on. So decided not to go with it. Swagger Based: There&rsquo;s a branch that I&rsquo;ve been keeping an eye on. https://github.com/grafana/grafana-api-golang-client/tree/papagian/generate-client-from-swagger which makes an effort to generate code based on the swagger manifest that&rsquo;s available from Grafana. It&rsquo;s a mostly automated code that pulls data from the Schema and generates the underlying code. It hasn&rsquo;t had much traction of late so I ended up forking the project currently available here Final Choice: # Although the Swagger/OpenAPI based version is not great, I&rsquo;ve even ran into a few issues where the documented response does not match the result, it&rsquo;s a lot more encompassing and allows further development without being as limited on upstream changes.
DataModel Changes # I&rsquo;ve tried to utilize mostly the same endpoints to recreate the same behavior for all the various entities, but there is are some changes. For most use cases this shouldn&rsquo;t matter. But you have been officially warned.
Cloud Support # The previous abstraction library used to provide S3, GS, SFTP has limited activity and introduced some security vulnerabilities. 0.4.X also changes some of the cloud behavior. It relies on the system authentication rather than having the auth in the config file.
Please see the related docs on how to configure your environment.
As the Stow library was removed, SFTP has been dropped. The list of current supported cloud providers are: S3, GS, Azure.
`}),e.add({id:18,href:"/gdg/docs/",title:"Docs",description:"Docs Doks.",content:""}),search.addEventListener("input",t,!0);function t(){const s=5;var n=this.value,o=e.search(n,{limit:s,enrich:!0});const t=new Map;for(const e of o.flatMap(e=>e.result)){if(t.has(e.doc.href))continue;t.set(e.doc.href,e.doc)}if(suggestions.innerHTML="",suggestions.classList.remove("d-none"),t.size===0&&n){const e=document.createElement("div");e.innerHTML=`No results for "<strong>${n}</strong>"`,e.classList.add("suggestion__no-results"),suggestions.appendChild(e);return}for(const[r,a]of t){const n=document.createElement("div");suggestions.appendChild(n);const e=document.createElement("a");e.href=r,n.appendChild(e);const o=document.createElement("span");o.textContent=a.title,o.classList.add("suggestion__title"),e.appendChild(o);const i=document.createElement("span");if(i.textContent=a.description,i.classList.add("suggestion__description"),e.appendChild(i),suggestions.appendChild(n),suggestions.childElementCount==s)break}}})()