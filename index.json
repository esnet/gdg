[{"body":"Configuration ","link":"https://software.es.net/gdg/docs/","title":"GDG Docs"},{"body":"Installation The easiest way to install GDG is to get one of the pre-compiled binaries from our release page which can be found here. Packages are not yet supported but will be coming soon since goreleaser has that feature.\nPlanned package support for:\nHomeBrew Debian RPMs APK If you have go install you may run the following command to install gdg\n1go install github.com/esnet/gdg@latest You can verify the version by running gdg version.\nConfiguration You can then create a simple configuration using gdg ctx new which will do a best effort to guide to setup a basic config that will get you up and going or read the more detailed documentation that can be found here\n","link":"https://software.es.net/gdg/docs/installation/","title":"Installation"},{"body":"Getting started This project requires Go to be installed. On OS X with Homebrew you can just run brew install go.\nmake a copy of conf/importer-example.yml and name it conf/importer.yml You'll need GRAFANA ADMINISTRATIVE privileges to proceed.\nAuthentication Authentication Token You can use an Authentication Token / API Key to authenticate with the Grafana API, which can be generated in your Grafana Web UI =\u0026gt; Configuration =\u0026gt; API Keys. You can then use it in your configuration file (eg. importer.yml).\nWARNING: gdg is currently using viper to read in the config. Since viper makes all keys lowercase, we also have the same limitation. Camel case will be read in but be aware that a section named fooBar == Foobar == foobar etc.\ncontext_name: main contexts: main: url: https://grafana.example.org token: \u0026#34;\u0026lt;\u0026lt;Grafana API Token\u0026gt;\u0026gt;\u0026#34; output_path: \u0026#34;myFolder\u0026#34; ignore_filters: False # When set to true all Watched filtered folders will be ignored and ALL folders will be acted on watched: - Example datasources: credentials: default: user: admin password: secret url_regex: ## set to pattern to match as well as the name. misc: user: admin password: secret url_regex: .*esproxy2* global: debug: true ignore_ssl_errors: false Username / Password You can also use username/password credentials of an admin user to authenticate with the Grafana API. You can specify them in your configuration file (eg. importer.yml).\ncontext_name: main contexts: main: url: https://grafana.example.org user_name: \u0026lt;your username\u0026gt; password: \u0026lt;your password\u0026gt; output_path: \u0026#34;myFolder\u0026#34; watched: - Example global: debug: true ignore_ssl_errors: false DataSource DataSource Credentials If the datasource has BasicAuth enabled, then we'll attempt to set the auth with the following precedence on matches:\nMatch of DS credentials based on DS name. Match URL regex for the DS if regex specified. Use Default Credentials if the above two both failed. An example of a configuration can be seen below\n1 testing: 2 output_path: testing_data 3 datasources: 4 credentials: 5 default: 6 user: user 7 password: password 8 misc: 9 user: admin 10 password: secret 11 url_regex: .*esproxy2* 12 url: http://localhost:3000 13 user_name: admin 14 password: admin 15 ignore_filters: False # When set to true all Watched filtered folders will be ignored and ALL folders will be acted on 16 watched: 17 - General 18 - Other 19 DataSource Filters This feature allows you to exclude datasource by name or include them by type. Please note that the logic switches based on the data type.\nname filter:\n1... 2datasources: 3 filters: 4 name_exclusions: \u0026#34;DEV-*|-Dev-*\u0026#34; Will exclude any datasource that matches the name regex.\nType Filter\nWill ONLY include datasource that are listed.\n1datasources: 2 filters: 3 valid_types: 4 - elasticsearch The snippet above will ONLY import datasources for elasticsearch\nNotes If you configure both, Auth Token and Username/Password, then the Token is given priority. Watched folders under grafana is a white list of folders that are being managed by the tool. By default only \u0026quot;General\u0026quot; is managed.\nenv.output defines where the files will be saved and imported from.\nGlobal Flags globals.debug when set will print a more verbose output (Development In Progress) globals.ignore_ssl_errors when set will disregard any SSL errors and proceed as expected\nEnvironment Overrides If you wish to override certain value via the environment, like credentials and such you can do so.\nThe pattern for GDG's is as follows: \u0026quot;GDG_SECTION__SECTION__keyname\u0026quot;\nFor example if I want to set the context name to a different value I can use:\n1GDG_CONTEXT_NAME=\u0026#34;testing\u0026#34; gdg ctx show ## Which will override the value from the context file. 2GDG_CONTEXTS__TESTING__URL=\u0026#34;www.google.com\u0026#34; Will override the URL with the one provided. NOTE: Complex data type are not supported, so if the value is an array it can't be currently set. Building/Running the app Running it then should be as simple as:\n1$ make build 2$ ./bin/gdg ","link":"https://software.es.net/gdg/docs/configuration/","title":"Configuration"},{"body":"Cloud Support Support for using a few cloud providers as a storage engine is now supported. When enabled, the local file system is only used for reading configuration files. Everything else relies on the data from the cloud provider matching up to your configuration.\nCurrently the following providers are supported:\nAWS S3 Google Storage (GS) Azure SFTP (Not exactly cloud, but useful) NOTE: the stow was used to support all of these providers. They should all work, but only S3 and Google have been properly tested.\nGeneral Configuration 1storage_engine: 2 any_label: 3 kind: cloud 4 cloud_type: [s3, google, azure, sftp] 5 bucket_name: \u0026#34;\u0026#34; 6 prefix: \u0026#34;dummy\u0026#34; Additional configuration for the respective engines are dependent on the cloud providers.\nS3 config:\n1 access_key_id: \u0026#34;\u0026#34; 2 secret_key: \u0026#34;\u0026#34; Google config:\n1 project_id: esnet-sd-dev 2 json: keys/service.json Azure config:\n1 account: \u0026#34;\u0026#34; 2 key: \u0026#34;\u0026#34; SFTP config:\n1 host: 2 port: 3 password: 4 private_key: 5 base_path: 6 host_public_key: Context Configuration The only additional change to the context is to provide a storage label to use:\n1 testing: 2 output_path: testing_data 3 ... 4 storage: any_label 5 ... So given the bucket name of foo with a prefix of bar with the output_path configured as testing_data the datasources will be imported to:\ns3://foo/bar/testing_data/datasources/ and exported from the same location. If you need it to be in a different location you can update the prefix accordingly but at destination will follow the typical app patterns.\n","link":"https://software.es.net/gdg/docs/cloud_configuration/","title":"Cloud Configuration"},{"body":"Running Tests Bring up a grafana instance locally with default credentials of admin/admin. docker-compose up -d grafana Once the instance is up simply run go test ./... or make test Making a release Install goreleaser.\n1brew install goreleaser/tap/goreleaser 2brew reinstall goreleaser` Alternatively if you have a more recent version of Go.\n1go install github.com/goreleaser/goreleaser@latest export your GITHUB_TOKEN.\n1export GITHUB_TOKEN=\u0026#34;secret\u0026#34; git tag v0.1.0 goreleaser release\nNOTE: CI/CD pipeline should do all this automatically. make release-snapshot is used to test the release build process. Once a build is tagged all artifacts should be built automatically and attached to the github release page.\nNOTE: mac binary are not signed so will likely complain.\n","link":"https://software.es.net/gdg/docs/developer/","title":"Developer Guide"},{"body":"Setup new configuration You can create new context configuration using an interactive setup.\n$ ./bin/gdg ctx new mycontext Import / Download Dashboards Minimal configuration (eg. the importer.yml file) that you need to download your dashboards from your Grafana endpoint:\ncontext_name: all contexts: all: url: https://grafana.example.org token: \u0026#34;\u0026lt;\u0026lt;Grafana API Token\u0026gt;\u0026gt;\u0026#34; # user_name: admin # password: admin output_path: exports watched: - Example - Infrastructure global: debug: true ignore_ssl_errors: false You need to adjust three parts in the configuration in order to function:\nGrafana URL: This is just a URL where your Grafana is available. API Key OR Username / Passoword for Admin user. See authentication section if you need more information. Downloaded Folders: The watched field defines folders which will be considered for manipulation. You can see these folders in your Grafana Web UI, under Dashboards \u0026gt; Management. From there, you can simply define the folders you want to be downloaded in the watched list. The dashboards are downloaded as JSON files in the $OUTPUT_PATH/dashboards/$GRAFANA_FOLDER_NAME directory. Where $OUTPUT_PATH is the path defined in the dashbourd_output configuration property and $GRAFANA_FOLDER_NAME the name of the folder from which the dashboards were downloaded After you are done, and you can execute ./bin/gdg dash list successfully, eg.:\n$ ./bin/gdg dash list time=\u0026#34;2021-08-22T11:11:27+02:00\u0026#34; level=warning msg=\u0026#34;Error getting organizations: HTTP error 403: returns {\\\u0026#34;message\\\u0026#34;:\\\u0026#34;Permission denied\\\u0026#34;}\u0026#34; time=\u0026#34;2021-08-22T11:11:28+02:00\u0026#34; level=info msg=\u0026#34;Listing dashboards for context: \u0026#39;all\u0026#39;\u0026#34; ┌────┬───────────────────────────────────┬───────────────────────────────────┬────────────────┬────────────┬────────────────────────────────────────────────────────────────────────────┐ │ ID │ TITLE │ SLUG │ FOLDER │ UID │ URL │ ├────┼───────────────────────────────────┼───────────────────────────────────┼────────────────┼────────────┼────────────────────────────────────────────────────────────────────────────┤ │ 8 │ AWS CloudWatch Logs │ aws-cloudwatch-logs │ Infrastructure │ AWSLogs00 │ https://grafana.example.org/d/AWSLogs00/aws-cloudwatch-logs │ │ 6 │ AWS ECS │ aws-ecs │ Infrastructure │ ly9Y95XWk │ https://grafana.example.org/d/ly9Y95XWk/aws-ecs │ │ 5 │ AWS ELB Application Load Balancer │ aws-elb-application-load-balancer │ Infrastructure │ bt8qGKJZz │ https://grafana.example.org/d/bt8qGKJZz/aws-elb-application-load-balancer │ │ 4 │ AWS RDS │ aws-rds │ Infrastructure │ kCDpC5uWk │ https://grafana.example.org/d/kCDpC5uWk/aws-rds │ │ 3 │ AWS S3 │ aws-s3 │ Infrastructure │ AWSS31iWk │ https://grafana.example.org/d/AWSS31iWk/aws-s3 │ │ 17 │ Cluster Autoscaling │ cluster-autoscaling │ Example │ iHUYtABMk │ https://grafana.example.org/d/iHUYtABMk/cluster-autoscaling │ └────┴───────────────────────────────────┴───────────────────────────────────┴────────────────┴────────────┴────────────────────────────────────────────────────────────────────────────┘ After executing ./bin/gdg dash import you can find the dashboards of the Infrastructure folder in the local directory dashboards/dashboards/Infrastructure and the dashboards of the Example directory in the local directory dashboards/dashboards/Example.\nExport / Upload Dashboards Minimal configuration (eg. the importer.yml file) that you need to upload your dashboards from your Grafana endpoint:\ncontext_name: all contexts: all: url: https://grafana.example.org token: \u0026#34;\u0026lt;\u0026lt;Grafana API Token\u0026gt;\u0026gt;\u0026#34; # user_name: admin # password: admin output_path: exports watched: - Example - Infrastructure global: debug: true ignore_ssl_errors: false You need to adjust three parts in the configuration in order to function:\nGrafana URL: This is just a URL where your Grafana is available. API Key OR Username / Passoword for Admin user. See authentication section if you need more information. Uploaded Folders: The watched field defines folders which will be considered for manipulation. The dashboards should be stored as JSON files in the $OUTPUT_PATH/dashboards/$GRAFANA_FOLDER_NAME directory. Where $OUTPUT_PATH is the path defined in the dashbourd_output configuration property and $GRAFANA_FOLDER_NAME the name of the folder to which the dashboards will be uploaded. In case of the above configuration file, the dashboards should be stored locally in the dashboards/dashboards/Example and dashboards/dashboards/Infrastructure/ directories. ├── bin | └── gdg └── exports └── dashboards ├── Example | └── cluster-scaling.json └── Infrastructure └── aws-ecs.json You can execute ./bin/gdg dash export to upload the local dashboards to your Grafana. Afterwards, you can try running ./bin/gdg dash list in order to confirm that your dashboards were uploaded successfully.\n","link":"https://software.es.net/gdg/docs/examples/","title":"Example Usage"},{"body":"Every namespace supporting CRUD operations has the functions: list, import, export, clear operating on only the monitored folders.\nAlert Notifications Allows you to manage alertnotifications (an) if you have any setup\n1./bin/gdg an list -- Lists all alert notifications 2./bin/gdg an import -- retrieve and save all alertnotifications from grafana 3./bin/gdg an export -- writes all local alert notifications to grafana 4./bin/gdg an clear -- Deletes all alert notifications Contexts Starting with version 0.1.4 contexts are now supported. Your config can contain one or multiple contexts which are essentially a grafana server configuration.\nctx is shorthand for context and basic CRUD is supported which is mainly tooling to make it easier to avoid updating the yaml file manually\n1./bin/gdg ctx list -- Lists all known contexts 2./bin/gdg ctx show qa -- shows the configuration for the selected context 3./bin/gdg ctx set production -- updates the active config and sets it to the request value. 4./bin/gdg ctx delete qa -- Deletes the QA context 5./bin/gdg ctx cp qa staging -- copies the qa context to staging and sets it as active 6./bin/gdg ctx clear -- Will delete all active contexts leaving only a single example entry Dashboards Dashboards are imported or exported from organization specified in configuration file otherwise current organization user is used.\nAll commands can use dashboards or dash to manage dashboards\n1./bin/gdg dash list -- Lists all current dashboards 2./bin/gdg dash import -- Import all dashboards from grafana to local file system 3./bin/gdg dash export -- Exports all dashboard from local filesystem (matching folder filter) to Grafana 4./bin/gdg dash clear -- Deletes all dashboards You can also use filtering options to list or import your daashboard by folder or by tags.\n1./bin/gdg dash import -f myFolder 2./bin/gdg dash import -t myTag 3./bin/gdg dash import -t tagA -t tagB -t tagC DataSources DataSources credentials are keyed by the name of the DataSource. See see config example. If the datasource JSON doesn't have auth enabled, the credentials are ignored. If Credentials are missing, we'll fall back on default credentials if any exist. The password is set as a value for basicAuthPassword in the API payload. Datasources are imported or exported from organization specified in configuration file otherwise current organization user is used.\nAll commands can use datasources or ds to manage datasources\n1./bin/gdg ds list -- Lists all current datasources 2./bin/gdg ds import -- Import all datasources from grafana to local file system 3./bin/gdg ds export -- Exports all dashboard from local filesystem (matching folder filter) to Grafana 4./bin/gdg ds clear -- Deletes all datasources Devel Some developer helper utilities\n1./bin/gdg devel completion [bash|fish|powershell|zsh] -- Will generate autocompletion for GDG for your favorite shell 2./bin/gdg devel srvinfo -- print grafana server info Folders Mostly optional as Dashboards will create/delete these are needed but if there is additional metadata you wish to persist you can use this to manage them.\n1./bin/gdg folders list -- Lists all current folders 2./bin/gdg folders import -- Import all folders from grafana to local file system 3./bin/gdg folders export -- Exports all folders from local filesystem 4./bin/gdg folders clear -- Deletes all folders Organizations Command can use organizations or org to manage organizations.\n1./bin/gdg org list -- Lists all organizations Users Only supported with basic auth. Users is the only one where basic auth is given priority. API Auth is not supported, so will try to use basic auth if configured otherwise will warn the user and exit.\nNOTE: admin user is always ignored.\n1./bin/gdg users list -- Lists all known users 2./bin/gdg users promote -u user@foobar.com -- promotes the user to a grafana admin 3./bin/gdg users import -- Lists all known users 4./bin/gdg users export -- Export all users (Not yet supported) 5./bin/gdg users clear -- Delete all known users except admin Version Print the applications release version\n1./bin/gdg version Build Date: 2022-05-05-13:27:08 Git Commit: 34cc84b3d80080aa93e74ed37739bddc3638997c+CHANGES Version: 0.1.11 Go Version: go1.18 OS / Arch: darwin amd64 ","link":"https://software.es.net/gdg/docs/usage_guide/","title":"Usage Guide"},{"body":" Welcome to GDG Documentation Site These documents are provided for the Grafana Dash-n-Grab utility. It's a tool used to manage dashboards, datasources, orgs and various entities of the Grafana application. All interactions are done via the Grafana API.\nRead the Docs\n","link":"https://software.es.net/gdg/","title":"Grafana Dash-n-Go"}]