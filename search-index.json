[{"content":"","date":"2024-09-11","id":0,"permalink":"/gdg/docs/releases/","summary":"","tags":[],"title":"Releases"},{"content":"Dependencies Development requirements.\nAs gdg is written in go, a current compiler is required. task management tool go-task. Installation Docker for running tests Install the remaining dependencies via: task install_tools\nBuilding/Running gdg Running it then should be as simple as:\n$ task build_all $ ./bin/gdg ## main binary $ ./bin/gdg-generate ## Dashboard Templating engine\rRequires task to be installed locally\nRunning Tests BasicAuth: task test Token: task test_tokens\nMaking a release You can validate that goreleaser work appropriately via\ntask release-snapshot or task release\nThe actual release will be done once a tag has been created via the CICD pipeline, artifacts will be generated and a website update will be published.\n","date":"0001-01-01","id":1,"permalink":"/gdg/docs/developer/developer-guide/","summary":"Dependencies Development requirements.\nAs gdg is written in go, a current compiler is required. task management tool go-task. Installation Docker for running tests Install the remaining dependencies via: task install_tools","tags":[],"title":"Developer Guide"},{"content":"Can I use GDG to backup grafana? yes and no. GDG is not a full backup solution. If you are migrating from one server to another, doing disaster recovery gdg is not the right tool for the job. Grafana already has some really nice guides for how to do that.\nGDG is used to backup and recreate specific entities. Usually it is used to allow for a consistent way to move say a dashboard, connections, alerts etc from one installation of grafana to the next.\nThe typical use case can be to manage release cycles. Example:\nCreate dashboard on dev, test everything out, pull into on a feature branch, deploy to staging environment. Validate everything looks good and promote it to production.\nWhy does GDG not list all my dashboards? By default, GDG works on a select list of watched or monitored folders. If none are specified, it will limit itself to only operating on General.\nThe folders that it DOES monitor, it is assumed that gdg has full control over. Meaning, anything in those folders is under its pervue, so it may delete all connections and replace them with the ones in its exports. As far as it knows, nobody else should be writing to it. The upload operation implies that you want to sync the export data with the data found in the backup local, cloud, or otherwise.\nPS. if you want to list/import etc all dashboards, you can set the following config for your context.\ndashboard_settings: ignore_filters: false # When set to true all Watched filtered folders will be ignored and ALL folders will be acted on\rI need feature X, can you please add that in? Maybe? If there\u0026rsquo;s enough cycles, it could benefit others, and the feature makes sense I\u0026rsquo;d be happy to. It is also an OSS project, so contributions are always appreciated and welcome. See contributing for more info.\nI need help, where do I go? There is a \u0026ldquo;Discussion\u0026rdquo; area on github where you can start a conversation and ask questions. If you think this is a bug in GDG itself, then please file an issue here. There is a small slack on channel titled #gdg in the grafana slack, you\u0026rsquo;re free to join here\n","date":"0001-01-01","id":2,"permalink":"/gdg/docs/gdg/frequently-asked-questions/","summary":"Can I use GDG to backup grafana? yes and no. GDG is not a full backup solution. If you are migrating from one server to another, doing disaster recovery gdg is not the right tool for the job.","tags":[],"title":"Frequently Asked Questions"},{"content":"Installation The easiest way to install GDG is to get one of the pre-compiled binaries from our release page which can be found here. Packages for a few distributions have been added. The release cycle relies on goreleaser so anything that is well supported can be added it at some point. There is no APT or such you can connect to but the packages are available for download.\nThe following packages are currently supported:\nRPM APK Docker Brew Package Installation Install from package involves downloading the appropriate package from the release and installing it as you usually do on your favorite Distro.\nrpm -Uvh ./gdg_0.6.0_amd64.rpm dpkg -i ./gdg_0.6.0_amd64.deb\rHomebrew Installation brew tap esnet/gdg brew update brew install gdg\rIf there is a conflict you can try to be explicit.\nbrew install esnet/gdg/gdg\rDocker usage The docker tags are released started with 0.3.1. Each release will generate a major version and minor version tag.\nYou can see the available images here\ndocker pull ghcr.io/esnet/gdg:0.6.0\rNOTE: ghcr.io/esnet/gdg:0.3 will also point to 0.3.1 until 0.3.2 is released after which it\u0026rsquo;ll point to 0.3.2\nExample compose.\nversion: \u0026#39;3.7\u0026#39; services: gdg: image: ghcr.io/esnet/gdg:0.6.0 command: \u0026#34;--help\u0026#34; ## Add additional parameters here # command: \u0026#34;ds export\u0026#34; ## Pass any cmd on here. volumes: - ./config:/app/config ## where the configuration lives - ./exports:/app/exports ## doesn\u0026#39;t need to be /app/exports but you should export the destination of where exports are being written out to.\rFrom the CLI:\ndocker run -it --rm -v $(pwd)/config:/app/config -v $(pwd)/exports:/app/exports ghcr.io/esnet/gdg:latest ds --help\rInstalling via Go If you have go install you may run the following command to install gdg. Keep in mind there are two binaries you may install.\ngdg ==\u0026gt; Main binary that manages the various entities supported. gdg-generate =\u0026gt; Helper utility that allows you to generate multiple dashboards given a valid configuration and seed data. gdg\ngo install github.com/esnet/gdg/cmd/gdg@latest #for latest go install github.com/esnet/gdg/cmd/gdg@v0.6.0 #for a specific version\rYou can verify the version by running gdg version.\ngdg-generate\ngo install github.com/esnet/gdg/cmd/gdg-generate@latest #for latest go install github.com/esnet/gdg/cmd/gdg-generate@v0.6.0 #for a specific version\rConfiguration You can then create a simple configuration using gdg tools ctx new which will do a best effort to guide to setup a basic config that will get you up and going or read the more detailed documentation that can be found here\nNOTE: wizard doesn\u0026rsquo;t currently support ALL features but it should help you get a head start.\n","date":"0001-01-01","id":3,"permalink":"/gdg/docs/gdg/installation/","summary":"Installation The easiest way to install GDG is to get one of the pre-compiled binaries from our release page which can be found here.","tags":[],"title":"Installation"},{"content":"GDG has now introduced a new supporting tool that works in conjunction with GDG. It is currently dependent on the GDG configuration since it will operate on the currently selected context. You can confirm what the current context is by running gdg tools ctx show\nFor example, my current output is as follows:\ncontext_name: storage: \u0026#34;\u0026#34; enterprise_support: true url: http://localhost:3000 token: \u0026#34;\u0026#34; user_name: admin password: admin organization_name: Main Org. watched_folders_override: [ ] watched: - General - Other connections: credential_rules: - rules: - field: name regex: misc - field: url secure_data: \u0026#34;misc.json\u0026#34; - rules: - field: url regex: .*esproxy2* secure_data: \u0026#34;proxy.json\u0026#34; - rules: - field: name regex: .* secure_data: \u0026#34;default.json\u0026#34; dashboard_settings: ignore_filters: false output_path: test/data\rMost of the config isn\u0026rsquo;t that interesting, except the output_path will be used to determine where the newly generated dashboards will be. Make sure you have a valid configuration before continuing.\nWhat does gdg-generate do? There are use cases where an almost identical dashboard is needed except we need to replace certain parts of it.\nFor example, parts of a query need to be different, a different title, brand it to specific customer with a different logo, or footer. All of these are difficult to control from grafana itself and even in the best case scenario it\u0026rsquo;s not great user experience. This allows you to configure and generate a new dashboard with any set of variables and dictionaries that you will seed to the tool.\nConfiguration The configuration that drives this application is templates.yml. You can see an example below.\nentities: dashboards: - template_name: \u0026#34;template_example\u0026#34; ##Matches the name to a file under ouput_path/templates/*.go.tmpl output: ## The section below defines one or multiple destination and the associated configuration ## that goes with it. - folder: \u0026#34;General\u0026#34; ## Name of the new folder where the template will be created organization_name: \u0026#34;Main Org.\u0026#34; dashboard_name: \u0026#34;\u0026#34; ## Optional, defaults to template_name.json template_data: ## Template Data the dictionary of datasets that can be used in the template, # it\u0026#39;s basically your \u0026#39;seed data\u0026#39;. Everything is contains is absolutely arbitrary # and can have any structure as long as it\u0026#39;s valid yaml Title: \u0026#34;Bob Loves Candy\u0026#34; ## Dashboard Titlte enabledlight: false ## Boolean check to enable/disable behavior lightsources: ## some arbitrary list we get to play with - sun - moon - lightbulb - office lights\rOne caveat. The \u0026ldquo;Keys\u0026rdquo; will all be lowercased due to how the data is being read in. Meaning, even though Title is specified, the template will see the value under \u0026ldquo;title\u0026rdquo; instead.\nAvailable Functions Additionally, there a few functions exposed and available to you that allows you to modify\n| Function Name | Example | Input | Output | |------------------|-----------------------------------------|----------------------|--------------------------| | ToSlug | {{ .title \\| ToSlug }} | Bob Candy | bob-candy | | QuotedStringJoin | {{ .lightsources \\| QuotedStringJoin }} | [sun,moon,lightbulb] | \u0026#34;sun\u0026#34;,\u0026#34;moon\u0026#34;,\u0026#34;lightbulb\u0026#34; |\rThere is also a large collection of functions that have been imported from sprig and are available for use.\nExample Templating Snippets Data Injection\n{ \u0026#34;annotations\u0026#34;: { \u0026#34;list\u0026#34;: [ { \u0026#34;$$hashKey\u0026#34;: \u0026#34;{{ .title | lower | ToSlug}}\u0026#34;, // Inserting data and piping it to two different functions. In this case, ToLower is redundant, but it serves as a chained example. \u0026#34;builtIn\u0026#34;: 1, \u0026#34;datasource\u0026#34;: \u0026#34;Grafana\u0026#34;, \u0026#34;enable\u0026#34;: true, \u0026#34;hide\u0026#34;: true, \u0026#34;iconColor\u0026#34;: \u0026#34;rgba(0, 211, 255, 1)\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Annotations Alerts\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;dashboard\u0026#34; } ] } }\rIterating and conditionals.\n{ \u0026#34;link_text\u0026#34;: [ {{ if .enabledlight }} // conditional to check if to insert or not {{ range $v: = .lightsources }} // Iterating through list {{ $v }} // Inserting value {{ end }} {{ end }} ] }\rInserting a comma delimited list\n\u0026#34;link_url\u0026#34;: [ \u0026#34;{{ .lightsources | join \u0026#34;, \u0026#34; }}\u0026#34;, \u0026#34;/grafana/d/000000003/bandwidth-dashboard\u0026#34;, \u0026#34;/grafana/d/xk26IFhmk/flow-data\u0026#34;, ]\rUsage As part of the installation you will have access to gdg-generate.\n\u0026ndash;config, \u0026ndash;template-config, and -t are optional parameters. gdg-generate will fallback on defaults if none are specified. If -t is not provided, all templates will be processed\ngdg-generate --config config/importer.yml --template-config config/template.yaml template generate -t template_example\rExample output:\n2023-11-16 09:49:03 INF gen/main.go:16 Reading GDG configuration 2023-11-16 09:49:03 INF gen/main.go:20 Configuration file is: config=importer.yml 2023-11-16 09:49:03 INF gen/main.go:29 Context is set to: context=testing 2023-11-16 09:49:03 INF templating/templating.go:83 Processing template template=template_example 2023-11-16 09:49:03 INF templating/templating.go:97 Creating a new template folder=General orgId=2 data=\u0026#34;map[enabledlight:false lightsources:[sun moon lightbulb office lights] title:Bob Loves Candy]\u0026#34; 2023-11-16 09:49:03 INF templating/templating.go:100 Writing data to destination output=test/data/org_2/dashboards 2023-11-16 09:49:03 INF templating/templating.go:131 template Path: path=test/data/templates\rA new file has been created under test/data/org_2/dashboards/General/template_example.json\n","date":"0001-01-01","id":4,"permalink":"/gdg/docs/templating/usage-guide/","summary":"GDG has now introduced a new supporting tool that works in conjunction with GDG. It is currently dependent on the GDG configuration since it will operate on the currently selected context.","tags":[],"title":"Usage Guide"},{"content":"First of all, gdg contains two binaries. gdg which manages grafana entities and provide some tooling facilities and gdg-generate a tool to help generate dashboards from templates to allow for some more flexible management. gdg-generate is fairly new, but the same quality of PRs would be nice to have.\nGDG There two types of features that get added to gdg, a tool or backup feature.\nBackup Feature A backup feature is some entity that you want to add to GDG that it will track.\nFor example, if you want to add support for managing a playlist.\nTypically, we want to be able to:\nList all entities in the current namespace (or Org) Download all entities Upload all entities In order to add a new feature you will need to:\nCreate an issue to track this work and explain the feature being added/requested. Create a new CLI subcommand for playlist. under the backup command. Extend the service to be able to list/download/upload etc the entities. Write a unit test for the given entities. If need be add some seed data under test/data/ Update the documentation accordingly to reflect the new changes. All docs live under the website/content. All files are in markdown. If you wish you can load the website locally by running: npm install \u0026amp;\u0026amp; hugo serve Testing There are multiple types of tests.\nIntegration tests. The most common one, an instance of grafana will be available and will connect to it to create/update/delete entities. Unit tests can be created for any unit of work, and will always be executed. CLI tooling tests. use task mocks to generate mocks for your tests. The purpose of this test is to validate the CLI parsing behavior rather than the service functionality. Ensure that filtering works, stdout is redirected to the test and can validate the output matches the expectations. Tools Feature This area is more about managing grafana entities. The tools would provide way for creating service accounts, listing tokens, adding user to orgs, etc.\nTesting such features can be a bit more difficult, but we can see enough data to validate the behavior that\u0026rsquo;s always great and makes for a much more stable feature long term.\nEnterprise features Caution\nThere are a few enterprise features that GDG supports, but unfortunately as there is no enterprise version we can access in CICD testing is very limited.\n","date":"0001-01-01","id":5,"permalink":"/gdg/docs/developer/contributing/","summary":"First of all, gdg contains two binaries. gdg which manages grafana entities and provide some tooling facilities and gdg-generate a tool to help generate dashboards from templates to allow for some more flexible management.","tags":[],"title":"Contributing"},{"content":"","date":"0001-01-01","id":6,"permalink":"/gdg/docs/gdg/","summary":"","tags":[],"title":"GDG Docs"},{"content":"Starting with version 0.4, library panels are going to be supported. It\u0026rsquo;s a bit special and the behavior is somewhat unique.\nRules:\nLibrary Panels are immutable. They cannot be moved to a different folder. They are linked to one or multiple dashboards. The only way I can see to move a lib element is to unlink the panel, delete the panel and re-create it in a different folder, then re-link it. In theory it\u0026rsquo;s supposed to move with the dashboards but I haven\u0026rsquo;t been able to re-create that behavior. You cannot delete a library element while a dashboard is still using it. Import components will retrieve all the components from Grafana and save to local file system.\ngdg lib download ┌─────────┬───────────────────────────────────────────────────────────────────────────────────────────────────────┐ │ TYPE │ FILENAME │ ├─────────┼───────────────────────────────────────────────────────────────────────────────────────────────────────┤ │ library │ testing_data/libraryelements/General/dashboard-makeover-extra-cleaning-duty-assignment-today.json │ │ library │ testing_data/libraryelements/General/dashboard-makeover-lighting-status.json │ │ library │ testing_data/libraryelements/General/dashboard-makeover-side-dish-prep-times-past-7-days.json │ │ library │ testing_data/libraryelements/General/dashboard-makeover-time-since-we-purchased-these-spices.json │ │ library │ testing_data/libraryelements/General/extreme-dashboard-makeover-grill.json │ │ library │ testing_data/libraryelements/General/extreme-dashboard-makeover-mac-oven.json │ │ library │ testing_data/libraryelements/General/extreme-dashboard-makeover-refrigerator-temperature-f.json │ │ library │ testing_data/libraryelements/General/extreme-dashboard-makeover-room-temperature-f.json │ │ library │ testing_data/libraryelements/General/extreme-dashboard-makeover-salmon-cooking-times-past-7-days.json │ └─────────┴───────────────────────────────────────────────────────────────────────────────────────────────────────┘\rImporting Dashboards Now that we the library components, pulled let\u0026rsquo;s pull the Dashboard.\ngdg dash download INFO[0002] Importing dashboards for context: \u0026#39;local\u0026#39; ┌───────────┬───────────────────────────────────────────────────────────────────┐ │ TYPE │ FILENAME │ ├───────────┼───────────────────────────────────────────────────────────────────┤ │ dashboard │ testing_data/dashboards/General/bandwidth-dashboard.json │ │ dashboard │ testing_data/dashboards/General/bandwidth-patterns.json │ │ dashboard │ testing_data/dashboards/Other/dashboard-makeover-challenge.json │ \u0026lt;== uses library panels │ dashboard │ testing_data/dashboards/Other/flow-analysis.json │ │ dashboard │ testing_data/dashboards/Other/flow-data-for-circuits.json │ │ dashboard │ testing_data/dashboards/Other/flow-data-for-projects.json │ │ dashboard │ testing_data/dashboards/Other/flow-data-per-country.json │ │ dashboard │ testing_data/dashboards/Other/flow-data-per-organization.json │ │ dashboard │ testing_data/dashboards/Other/flow-information.json │ │ dashboard │ testing_data/dashboards/Other/flows-by-science-discipline.json │ │ dashboard │ testing_data/dashboards/General/individual-flows.json │ │ dashboard │ testing_data/dashboards/General/individual-flows-per-country.json │ │ dashboard │ testing_data/dashboards/Ignored/latency-patterns.json │ │ dashboard │ testing_data/dashboards/General/loss-patterns.json │ │ dashboard │ testing_data/dashboards/General/other-flow-stats.json │ │ dashboard │ testing_data/dashboards/General/science-discipline-patterns.json │ │ dashboard │ testing_data/dashboards/General/top-talkers-over-time.json │ └───────────┴───────────────────────────────────────────────────────────────────┘\rThe dashboards will have a reference to the library panel linked by UID.\nHere\u0026rsquo;s the json from the dashboard JSON:\n\u0026#34;libraryPanel\u0026#34;: { \u0026#34;description\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;meta\u0026#34;: { \u0026#34;connectedDashboards\u0026#34;: 3, \u0026#34;created\u0026#34;: \u0026#34;2022-05-17T19:35:06Z\u0026#34;, \u0026#34;createdBy\u0026#34;: { \u0026#34;avatarUrl\u0026#34;: \u0026#34;/avatar/579fc54abdc9ab34fb4865322f2870a1\u0026#34;, \u0026#34;id\u0026#34;: 13, \u0026#34;name\u0026#34;: \u0026#34;mike.johnson@grafana.com\u0026#34; }, \u0026#34;folderName\u0026#34;: \u0026#34;mj\u0026#34;, \u0026#34;folderUid\u0026#34;: \u0026#34;R0bMCcW7z\u0026#34;, \u0026#34;updated\u0026#34;: \u0026#34;2022-05-17T19:37:14Z\u0026#34;, \u0026#34;updatedBy\u0026#34;: { \u0026#34;avatarUrl\u0026#34;: \u0026#34;/avatar/579fc54abdc9ab34fb4865322f2870a1\u0026#34;, \u0026#34;id\u0026#34;: 13, \u0026#34;name\u0026#34;: \u0026#34;mike.johnson@grafana.com\u0026#34; } }, \u0026#34;name\u0026#34;: \u0026#34;Extreme Dashboard Makeover - Grill\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;graph\u0026#34;, \u0026#34;uid\u0026#34;: \u0026#34;y1C0A5unz\u0026#34;, \u0026#34;version\u0026#34;: 2 },\rPlease note, this is the Grill panel.\n{ \u0026#34;name\u0026#34;: \u0026#34;Extreme Dashboard Makeover - Grill\u0026#34;, \u0026#34;orgId\u0026#34;: 1, \u0026#34;type\u0026#34;: \u0026#34;graph\u0026#34;, \u0026#34;uid\u0026#34;: \u0026#34;y1C0A5unz\u0026#34;, \u0026#34;version\u0026#34;: 1 }\rDeleting Elements If we try to delete all the Library elements, that won\u0026rsquo;t be allowed.\n./bin/gdg lib clear ERRO[0000] Failed to delete library panel titled: Dashboard Makeover - Extra Cleaning Duty Assignment Today ErrorMessage=\u0026#34;the library element has connections\u0026#34; ERRO[0000] Failed to delete library panel titled: Dashboard Makeover - Lighting Status ErrorMessage=\u0026#34;the library element has connections\u0026#34; ERRO[0000] Failed to delete library panel titled: Dashboard Makeover - Side Dish Prep Times, past 7 days ErrorMessage=\u0026#34;the library element has connections\u0026#34; ERRO[0000] Failed to delete library panel titled: Dashboard Makeover - Time since we purchased these spices ErrorMessage=\u0026#34;the library element has connections\u0026#34; ERRO[0000] Failed to delete library panel titled: Extreme Dashboard Makeover - Grill ErrorMessage=\u0026#34;the library element has connections\u0026#34; ERRO[0000] Failed to delete library panel titled: Extreme Dashboard Makeover - Mac Oven ErrorMessage=\u0026#34;the library element has connections\u0026#34; ERRO[0000] Failed to delete library panel titled: Extreme Dashboard Makeover - Refrigerator Temperature (F) ErrorMessage=\u0026#34;the library element has connections\u0026#34; ERRO[0000] Failed to delete library panel titled: Extreme Dashboard Makeover - Room Temperature (F) ErrorMessage=\u0026#34;the library element has connections\u0026#34; ERRO[0000] Failed to delete library panel titled: Extreme Dashboard Makeover - Salmon Cooking Times, past 7 days ErrorMessage=\u0026#34;the library element has connections\u0026#34; INFO[0000] No library were found. 0 librarys removed\rDeleting related dashboard (Future version will allow you to inspect which dashboard has a link to which dashboards)\n./bin/gdg dash clear -d dashboard-makeover-challenge (gke_esnet-sd-dev_us-central1-c_dev-staging-kafka-3/default) INFO[0000] 1 dashboards were deleted ┌───────────┬──────────────────────────────┐ │ TYPE │ FILENAME │ ├───────────┼──────────────────────────────┤ │ dashboard │ Dashboard Makeover Challenge │ └───────────┴──────────────────────────────┘\rPlease note the -d, we\u0026rsquo;re explicitly only deleting one dashboard. We can verify the list.\n./bin/gdg dash list ┌────┬──────────────────────────────┬──────────────────────────────┬─────────┬───────────┬────────────────────────────────────────────────────────────────┐ │ ID │ TITLE │ SLUG │ FOLDER │ UID │ URL │ ├────┼──────────────────────────────┼──────────────────────────────┼─────────┼───────────┼────────────────────────────────────────────────────────────────┤ │ 80 │ Bandwidth Dashboard │ bandwidth-dashboard │ General │ 000000003 │ http://localhost:3000/d/000000003/bandwidth-dashboard │ │ 81 │ Bandwidth Patterns │ bandwidth-patterns │ General │ 000000004 │ http://localhost:3000/d/000000004/bandwidth-patterns │ │ 90 │ Flow Analysis │ flow-analysis │ Other │ VuuXrnPWz │ http://localhost:3000/d/VuuXrnPWz/flow-analysis │ │ 91 │ Flow Data for Circuits │ flow-data-for-circuits │ Other │ xk26IFhmk │ http://localhost:3000/d/xk26IFhmk/flow-data-for-circuits │ │ 92 │ Flow Data for Projects │ flow-data-for-projects │ Other │ ie7TeomGz │ http://localhost:3000/d/ie7TeomGz/flow-data-for-projects │ │ 93 │ Flow Data per Country │ flow-data-per-country │ Other │ fgrOzz_mk │ http://localhost:3000/d/fgrOzz_mk/flow-data-per-country │ │ 94 │ Flow Data per Organization │ flow-data-per-organization │ Other │ QfzDJKhik │ http://localhost:3000/d/QfzDJKhik/flow-data-per-organization │ │ 95 │ Flow Information │ flow-information │ Other │ nzuMyBcGk │ http://localhost:3000/d/nzuMyBcGk/flow-information │ │ 96 │ Flows by Science Discipline │ flows-by-science-discipline │ Other │ WNn1qyaiz │ http://localhost:3000/d/WNn1qyaiz/flows-by-science-discipline │ │ 83 │ Individual Flows │ individual-flows │ General │ -l3_u8nWk │ http://localhost:3000/d/-l3_u8nWk/individual-flows │ │ 82 │ Individual Flows per Country │ individual-flows-per-country │ General │ 80IVUboZk │ http://localhost:3000/d/80IVUboZk/individual-flows-per-country │ │ 88 │ Latency Patterns │ latency-patterns │ Ignored │ 000000005 │ http://localhost:3000/d/000000005/latency-patterns │ │ 84 │ Loss Patterns │ loss-patterns │ General │ 000000006 │ http://localhost:3000/d/000000006/loss-patterns │ │ 85 │ Other Flow Stats │ other-flow-stats │ General │ CJC1FFhmz │ http://localhost:3000/d/CJC1FFhmz/other-flow-stats │ │ 86 │ Science Discipline Patterns │ science-discipline-patterns │ General │ ufIS9W7Zk │ http://localhost:3000/d/ufIS9W7Zk/science-discipline-patterns │ │ 87 │ Top Talkers Over Time │ top-talkers-over-time │ General │ b35BWxAZz │ http://localhost:3000/d/b35BWxAZz/top-talkers-over-time │ └────┴──────────────────────────────┴──────────────────────────────┴─────────┴───────────┴────────────────────────────────────────────────────────────────┘\rRemoving related components ./bin/gdg lib clear (gke_esnet-sd-dev_us-central1-c_dev-staging-kafka-3/default) INFO[0000] 9 library were deleted ┌─────────┬────────────────────────────────────────────────────────────────┐ │ TYPE │ FILENAME │ ├─────────┼────────────────────────────────────────────────────────────────┤ │ library │ Dashboard Makeover - Extra Cleaning Duty Assignment Today │ │ library │ Dashboard Makeover - Lighting Status │ │ library │ Dashboard Makeover - Side Dish Prep Times, past 7 days │ │ library │ Dashboard Makeover - Time since we purchased these spices │ │ library │ Extreme Dashboard Makeover - Grill │ │ library │ Extreme Dashboard Makeover - Mac Oven │ │ library │ Extreme Dashboard Makeover - Refrigerator Temperature (F) │ │ library │ Extreme Dashboard Makeover - Room Temperature (F) │ │ library │ Extreme Dashboard Makeover - Salmon Cooking Times, past 7 days │ └─────────┴────────────────────────────────────────────────────────────────┘\r","date":"0001-01-01","id":7,"permalink":"/gdg/docs/tutorials/working-with-library-panels/","summary":"Starting with version 0.4, library panels are going to be supported. It\u0026rsquo;s a bit special and the behavior is somewhat unique.","tags":[],"title":"Working with Library Panels"},{"content":"Concepts At it\u0026rsquo;s core an Organization in grafana is an entity that allows you (the user) to organize and structure entities to seperate access for both usability and security. So a Connection under org1 would never be able to be configured to use a dashboard under Org2.\nAuthentication with GDG and grafana can take a few different patterns.\nGrafana Admin - this is your typical admin/admin default user that comes with most installs. You have full access to do everything. Org Admin - this is a user that is an admin for one or multiple Orgs and can manage most entities under the given org but not high level entities. Each user can be authenticated with \u0026lsquo;BasicAuth\u0026rsquo; or APIKeys/Service Tokens.\nBasic Auth allows a user to change Orgs context if they have access to more than one. Service Token/API Keys are bound to a given org, so if the user tries to change the Org, it won\u0026rsquo;t work. It grants access, viewer, editor, admin for a given Org. If you are working with multiple Orgs, you will have a much easier time if you use basic auth. You can certainly simply rotate the tokens as you like though GDG is a bit better at dealing with basic auth and switching orgs accordingly.\nOrganization Workflow List Orgs (Grafana Admin) will retrieve all the components from Grafana and save to local file system.\ngdg backup orgs list ┌────┬───────────┐ │ ID │ ORG │ ├────┼───────────┤ │ 1 │ Main Org. │ │ 2 │ DumbDumb │ │ 3 │ Moo │ └────┴───────────┘\rLet\u0026rsquo;s take a look at our context\n---local: storage: \u0026#34;\u0026#34; enterprise_support: false url: http://localhost:3000 token: \u0026#34;SomeTokenHere\u0026#34; user_name: admin password: admin organization_name: Main Org. watched: - General - Other connections: credential_rules: - rules: - field: name regex: .* auth: user: user password: password datasources: {} dashboard_settings: ignore_filters: false output_path: test/data\rThe organization_name is set to Main Org. and is the default if unspecified.\nInspect Current Auth Org Let\u0026rsquo;s have a look at our Token.\ngdg tools org tokenOrg\r┌────┬───────────┐ │ ID │ NAME │ ├────┼───────────┤ │ 1 │ Main Org. │ └────┴───────────┘\rThis is an immutable value and may cause issues if we switch. Depending on the call the behavior is to give token preference or basic auth. So if the basic auth is succesfully namespace into a given org, the token will still point to the wrong one and cause issues. IF you wish to use Tokens, then avoid using basic auth.\nWe can also look at what our User Org is set to using:\ngdg tools org userOrg\r┌────┬───────────┐ │ ID │ NAME │ ├────┼───────────┤ │ 1 │ Main Org. │ └────┴───────────┘\rThis value though IS changeable.\nList Dashboards Now that we take a look at the dashboards under Org 1.\ngdg b dash list INFO[0002] Listing dashboards for context: \u0026#39;local\u0026#39; ┌─────┬──────────────────────────────┬──────────────────────────────┬─────────┬───────────┬──────────────┬────────────────────────────────────────────────────────────────┐ │ ID │ TITLE │ SLUG │ FOLDER │ UID │ TAGS │ URL │ ├─────┼──────────────────────────────┼──────────────────────────────┼─────────┼───────────┼──────────────┼────────────────────────────────────────────────────────────────┤ │ 166 │ Bandwidth Dashboard │ bandwidth-dashboard │ General │ 000000003 │ netsage │ http://localhost:3000/d/000000003/bandwidth-dashboard │ │ 167 │ Bandwidth Patterns │ bandwidth-patterns │ General │ 000000004 │ netsage │ http://localhost:3000/d/000000004/bandwidth-patterns │ │ 174 │ Dashboard Makeover Challenge │ dashboard-makeover-challenge │ Other │ F3eInwQ7z │ │ http://localhost:3000/d/F3eInwQ7z/dashboard-makeover-challenge │ │ 175 │ Flow Analysis │ flow-analysis │ Other │ VuuXrnPWz │ flow,netsage │ http://localhost:3000/d/VuuXrnPWz/flow-analysis │ │ 176 │ Flow Data for Circuits │ flow-data-for-circuits │ Other │ xk26IFhmk │ flow,netsage │ http://localhost:3000/d/xk26IFhmk/flow-data-for-circuits │ │ 177 │ Flow Data for Projects │ flow-data-for-projects │ Other │ ie7TeomGz │ │ http://localhost:3000/d/ie7TeomGz/flow-data-for-projects │ │ 178 │ Flow Data per Country │ flow-data-per-country │ Other │ fgrOzz_mk │ flow,netsage │ http://localhost:3000/d/fgrOzz_mk/flow-data-per-country │ │ 179 │ Flow Data per Organization │ flow-data-per-organization │ Other │ QfzDJKhik │ flow,netsage │ http://localhost:3000/d/QfzDJKhik/flow-data-per-organization │ │ 180 │ Flow Information │ flow-information │ Other │ nzuMyBcGk │ │ http://localhost:3000/d/nzuMyBcGk/flow-information │ │ 181 │ Flows by Science Discipline │ flows-by-science-discipline │ Other │ WNn1qyaiz │ flow,netsage │ http://localhost:3000/d/WNn1qyaiz/flows-by-science-discipline │ │ 169 │ Individual Flows │ individual-flows │ General │ -l3_u8nWk │ netsage │ http://localhost:3000/d/-l3_u8nWk/individual-flows │ │ 168 │ Individual Flows per Country │ individual-flows-per-country │ General │ 80IVUboZk │ netsage │ http://localhost:3000/d/80IVUboZk/individual-flows-per-country │ │ 170 │ Loss Patterns │ loss-patterns │ General │ 000000006 │ netsage │ http://localhost:3000/d/000000006/loss-patterns │ │ 171 │ Other Flow Stats │ other-flow-stats │ General │ CJC1FFhmz │ flow,netsage │ http://localhost:3000/d/CJC1FFhmz/other-flow-stats │ │ 172 │ Science Discipline Patterns │ science-discipline-patterns │ General │ ufIS9W7Zk │ flow,netsage │ http://localhost:3000/d/ufIS9W7Zk/science-discipline-patterns │ │ 173 │ Top Talkers Over Time │ top-talkers-over-time │ General │ b35BWxAZz │ │ http://localhost:3000/d/b35BWxAZz/top-talkers-over-time │ └─────┴──────────────────────────────┴──────────────────────────────┴─────────┴───────────┴──────────────┴────────────────────────────────────────────────────────────────┘\rSwitching Organizations Switching context to Org 2.\ngdg tools orgs set 2 INFO[0000] Succesfully set Org ID for context: local\rLet\u0026rsquo;s confirm that we trully changed contexts.\ngdg tools org userOrg\r┌────┬───────────┐ │ ID │ NAME │ ├────┼───────────┤ │ 2 │ DumbDumb │ └────┴───────────┘\rListing Orgs Dashboards Listing dashboards under Org 2 will result in an empty set.\ngdg b dash list INFO[0000] Listing dashboards for context: \u0026#39;local\u0026#39; INFO[0000] No dashboards found\rLet\u0026rsquo;s switch back to org 1 and donwload our dashboards.\ngdg tools orgs set 1 INFO[0000] Succesfully set Org ID for context: local\rDownload Orgs Dashboards gdg backup dash download\rINFO[0000] Importing dashboards for context: \u0026#39;local\u0026#39; ┌───────────┬──────────────────────────────────────────────────────────────────────┐ │ TYPE │ FILENAME │ ├───────────┼──────────────────────────────────────────────────────────────────────┤ │ dashboard │ test/data/org_1/dashboards/General/bandwidth-dashboard.json │ │ dashboard │ test/data/org_1/dashboards/General/bandwidth-patterns.json │ │ dashboard │ test/data/org_1/dashboards/Other/dashboard-makeover-challenge.json │ │ dashboard │ test/data/org_1/dashboards/Other/flow-analysis.json │ │ dashboard │ test/data/org_1/dashboards/Other/flow-data-for-circuits.json │ │ dashboard │ test/data/org_1/dashboards/Other/flow-data-for-projects.json │ │ dashboard │ test/data/org_1/dashboards/Other/flow-data-per-country.json │ │ dashboard │ test/data/org_1/dashboards/Other/flow-data-per-organization.json │ │ dashboard │ test/data/org_1/dashboards/Other/flow-information.json │ │ dashboard │ test/data/org_1/dashboards/Other/flows-by-science-discipline.json │ │ dashboard │ test/data/org_1/dashboards/General/individual-flows.json │ │ dashboard │ test/data/org_1/dashboards/General/individual-flows-per-country.json │ │ dashboard │ test/data/org_1/dashboards/General/loss-patterns.json │ │ dashboard │ test/data/org_1/dashboards/General/other-flow-stats.json │ │ dashboard │ test/data/org_1/dashboards/General/science-discipline-patterns.json │ │ dashboard │ test/data/org_1/dashboards/General/top-talkers-over-time.json │ └───────────┴──────────────────────────────────────────────────────────────────────┘\rPlease note the path has org_1 in the path. Starting with version 0.5 of GDG we always namespace the entities we back by the org they belong to.\n","date":"2023-09-01","id":8,"permalink":"/gdg/docs/tutorials/organization-and-authentication/","summary":"Concepts At it\u0026rsquo;s core an Organization in grafana is an entity that allows you (the user) to organize and structure entities to seperate access for both usability and security.","tags":[],"title":"Organization and Authentication"},{"content":"","date":"0001-01-01","id":9,"permalink":"/gdg/docs/usage_guide/","summary":"","tags":[],"title":"Usage Guide"},{"content":"","date":"0001-01-01","id":10,"permalink":"/gdg/docs/templating/","summary":"","tags":[],"title":"GDG Generate Docs (templating)"},{"content":"Starting with GDG 0.7, support for nested folders has been added. This feature requires grafana 11+. You can watch a Intro video or read the offical annoucements here.\nIt is current behind a feature toggle. You will need to set the folliwing value in your grafana.ini\n[feature_toggles] enable = nestedFolders,...\ror have the following ENV variable set\nGF_FEATURE_TOGGLES_ENABLE=nestedFolders\rAdditionaly GDG configuration needs to have the behavior enabled.\ndashboard_settings: nested_folders: true\rOnce enabled, the behavior for Dashboards and folders should reflect that.\nDashboards For example:\ngdg backup dashboard list\n┌────┬───────────────────────────────────┬─────────────────────────────┬────────────┬──────────────┬────────────────┬───────────────────────────────┬────────────────────────────────────────────────────────────────────┐ │ ID │ TITLE │ SLUG │ FOLDER │ NESTEDPATH │ UID │ TAGS │ URL │ ├────┼───────────────────────────────────┼─────────────────────────────┼────────────┼──────────────┼────────────────┼───────────────────────────────┼────────────────────────────────────────────────────────────────────┤ │ 21 │ RabbitMQ-Overview │ rabbitmq-overview │ General │ General │ Kn5xm-gZk │ [\u0026#34;rabbitmq-prometheus\u0026#34;] │ http://localhost:3000/d/Kn5xm-gZk/rabbitmq-overview │ │ 24 │ Node Exporter Full │ node-exporter-full │ dummy │ Others/dummy │ rYdddlPWk │ [\u0026#34;linux\u0026#34;] │ http://localhost:3000/d/rYdddlPWk/node-exporter-full │ │ 26 │ K8s / Storage / Volumes / Cluster │ k8s-storage-volumes-cluster │ someFolder │ Others/someFolder │ bdx48n30kejuoa │ [\u0026#34;k8s\u0026#34;,\u0026#34;openshift\u0026#34;,\u0026#34;storage\u0026#34;] │ http://localhost:3000/d/bdx48n30kejuoa/k8s-storage-volumes-cluster │ └────┴───────────────────────────────────┴─────────────────────────────┴────────────┴──────────────┴────────────────┴───────────────────────────────┴────────────────────────────────────────────────────────────────────┘\rNote the folder of Node Exporter Full is now Others/dummy, the watched_folders would also need to be updated as it does a substring match, but it might give you plenty of false positives.\nExample: filter on \u0026lsquo;dummy\u0026rsquo; folder also matches /dummy and /a/b/c/d/dummy and /a/dummy/ etc. It\u0026rsquo;s better to be explicit or have a regex Patern\nwatched: - Others/*\rOR\nwatched: - Others/dummy - Others/someFolder\rFolders gdg backup folders list ┌────────────────┬──────────────┬────────────┐ │ UID │ TITLE │ NESTEDPATH │ ├────────────────┼──────────────┼────────────┤ │ ddxll3n7dse80d │ dummy │ Others/dummy │ │ edx4a6qbjt5hcd │ dummy │ dummy │ │ fdxll3n62cbnkf │ Others │ Others │ │ fdxll3nd7jv9cc │ someFolder │ Others/someFolder │ └────────────────┴────────────┴──────────────┘\rFolder Permission Starging with GDG v0.7 file name convention are the slug of the full nested path rather than folder name.\n┌─────────────────────────────────────────────────────────────┐ │ FILENAME │ ├─────────────────────────────────────────────────────────────┤ │ test/data/org_testing/folders-permissions/others-dummy.json │ │ test/data/org_testing/folders-permissions/dummy.json │ │ test/data/org_testing/folders-permissions/others.json │ │ test/data/org_testing/folders-permissions/somefolder.json │ └─────────────────────────────────────────────────────────────┘\r","date":"0001-01-01","id":11,"permalink":"/gdg/docs/tutorials/working-with-nested-folders/","summary":"Starting with GDG 0.7, support for nested folders has been added. This feature requires grafana 11+. You can watch a Intro video or read the offical annoucements here.","tags":[],"title":"Working with Nested Folders"},{"content":"","date":"2023-09-01","id":12,"permalink":"/gdg/docs/tutorials/","summary":"","tags":[],"title":"Tutorials"},{"content":"","date":"0001-01-01","id":13,"permalink":"/gdg/docs/developer/","summary":"","tags":[],"title":"Developer Guide"},{"content":"Setup new configuration You can create new context configuration using an interactive setup.\n$ ./bin/gdg tools ctx new mycontext\rWhen creating a new context, you will be asked for authorization type, your default datasource and username/password, along with which folders you wish to manage under the context. You have three options:\nDefault option (\u0026ldquo;General\u0026rdquo;) List of folders you wish to manage Wildcard configuration (all folders) Import / Download Dashboards Minimal configuration (eg. the importer.yml file) that you need to download your dashboards from your Grafana endpoint:\ncontext_name: all contexts: all: url: https://grafana.example.org token: \u0026#34;\u0026lt;\u0026lt;Grafana API Token\u0026gt;\u0026gt;\u0026#34; # user_name: admin # password: admin output_path: exports watched: - Example - Infrastructure global: debug: true ignore_ssl_errors: false\rYou need to adjust three parts in the configuration in order to function:\nGrafana URL: This is just a URL where your Grafana is available. API Key OR Username / Passoword for Admin user. See authentication section if you need more information. Downloaded Folders: The watched field defines folders which will be considered for manipulation. You can see these folders in your Grafana Web UI, under Dashboards \u0026gt; Management. From there, you can simply define the folders you want to be downloaded in the watched list. The dashboards are downloaded as JSON files in the $OUTPUT_PATH/dashboards/$GRAFANA_FOLDER_NAME directory. Where $OUTPUT_PATH is the path defined in the dashboard_output configuration property and $GRAFANA_FOLDER_NAME the name of the folder from which the dashboards were downloaded. Note\nStarting with verions 0.7.0 regex patterns for folders are now supported, ex: Other|General, folder/*\nAfter you are done, and you can execute ./bin/gdg dash list successfully, eg.:\n$ ./bin/gdg dash list time=\u0026#34;2021-08-22T11:11:27+02:00\u0026#34; level=warning msg=\u0026#34;Error getting organizations: HTTP error 403: returns {\\\u0026#34;message\\\u0026#34;:\\\u0026#34;Permission denied\\\u0026#34;}\u0026#34; time=\u0026#34;2021-08-22T11:11:28+02:00\u0026#34; level=info msg=\u0026#34;Listing dashboards for context: \u0026#39;all\u0026#39;\u0026#34; ┌────┬───────────────────────────────────┬───────────────────────────────────┬────────────────┬────────────┬────────────────────────────────────────────────────────────────────────────┐ │ ID │ TITLE │ SLUG │ FOLDER │ UID │ URL │ ├────┼───────────────────────────────────┼───────────────────────────────────┼────────────────┼────────────┼────────────────────────────────────────────────────────────────────────────┤ │ 8 │ AWS CloudWatch Logs │ aws-cloudwatch-logs │ Infrastructure │ AWSLogs00 │ https://grafana.example.org/d/AWSLogs00/aws-cloudwatch-logs │ │ 6 │ AWS ECS │ aws-ecs │ Infrastructure │ ly9Y95XWk │ https://grafana.example.org/d/ly9Y95XWk/aws-ecs │ │ 5 │ AWS ELB Application Load Balancer │ aws-elb-application-load-balancer │ Infrastructure │ bt8qGKJZz │ https://grafana.example.org/d/bt8qGKJZz/aws-elb-application-load-balancer │ │ 4 │ AWS RDS │ aws-rds │ Infrastructure │ kCDpC5uWk │ https://grafana.example.org/d/kCDpC5uWk/aws-rds │ │ 3 │ AWS S3 │ aws-s3 │ Infrastructure │ AWSS31iWk │ https://grafana.example.org/d/AWSS31iWk/aws-s3 │ │ 17 │ Cluster Autoscaling │ cluster-autoscaling │ Example │ iHUYtABMk │ https://grafana.example.org/d/iHUYtABMk/cluster-autoscaling │ └────┴───────────────────────────────────┴───────────────────────────────────┴────────────────┴────────────┴────────────────────────────────────────────────────────────────────────────┘\rAfter executing ./bin/gdg dash import you can find the dashboards of the Infrastructure folder in the local directory dashboards/dashboards/Infrastructure and the dashboards of the Example directory in the local directory dashboards/dashboards/Example.\nExport / Upload Dashboards Minimal configuration (eg. the importer.yml file) that you need to upload your dashboards from your Grafana endpoint:\ncontext_name: all contexts: all: url: https://grafana.example.org token: \u0026#34;\u0026lt;\u0026lt;Grafana API Token\u0026gt;\u0026gt;\u0026#34; # user_name: admin # password: admin output_path: exports watched: - Example - Infrastructure global: debug: true ignore_ssl_errors: false\rYou need to adjust three parts in the configuration in order to function:\nGrafana URL: This is just a URL where your Grafana is available. API Key OR Username / Passoword for Admin user. See authentication section if you need more information. Uploaded Folders: The watched field defines folders which will be considered for manipulation. The dashboards should be stored as JSON files in the $OUTPUT_PATH/dashboards/$GRAFANA_FOLDER_NAME directory. Where $OUTPUT_PATH is the path defined in the dashboard_output configuration property and $GRAFANA_FOLDER_NAME the name of the folder to which the dashboards will be uploaded. In case of the above configuration file, the dashboards should be stored locally in the dashboards/dashboards/Example and dashboards/dashboards/Infrastructure/ directories. ├── bin | └── gdg └── exports └── org_main-org | └── dashboards | └─ Example | | └── cluster-scaling.json | └─ Infrastructure | └── aws-ecs.json\rYou can execute ./bin/gdg backup dash export to upload the local dashboards to your Grafana. Afterwards, you can try running ./bin/gdg dash list in order to confirm that your dashboards were uploaded successfully.\n","date":"0001-01-01","id":14,"permalink":"/gdg/docs/gdg/getting-started/","summary":"Setup new configuration You can create new context configuration using an interactive setup.\n$ ./bin/gdg tools ctx new mycontext\rWhen creating a new context, you will be asked for authorization type, your default datasource and username/password, along with which folders you wish to manage under the context.","tags":[],"title":"Getting Started"},{"content":"Configuration make a copy of config/importer-example.yml and name it config/importer.yml or simply run gdg tools ctx new \u0026lt;name\u0026gt; which will walk you through setting up a new context to use with your grafana installation.\nAuthentication Authentication Token You can use an Authentication Token / API Key to authenticate with the Grafana API, which can be generated in your Grafana Web UI =\u0026gt; Configuration =\u0026gt; API Keys. You can then use it in your configuration file (eg. importer.yml).\nCaution\ngdg is currently using viper to read in the config. Since viper makes all keys lowercase, we also have the same limitation. Camel case will be read in but be aware that a section named fooBar == Foobar == foobar etc.\nService Accounts Service Accounts are supported and interchangeable for tokens. If you wish to use a service account, simply put the token value from the service account for token:. Please make sure you\u0026rsquo;ve granted the account the needed permissions for the operations you are trying to perform.\ncontext_name: main contexts: main: url: https://grafana.example.org token: \u0026#34;\u0026lt;\u0026lt;Grafana API Token\u0026gt;\u0026gt;\u0026#34; output_path: \u0026#34;myFolder\u0026#34; ignore_filters: False # When set to true all Watched filtered folders will be ignored and ALL folders will be acted on watched: - Example connections: credential_rules: - rules: - field: \u0026#34;name\u0026#34; regex: \u0026#34;misc\u0026#34; - field: \u0026#34;url\u0026#34; value: \u0026#34;.*esproxy2*\u0026#34; secure_data: \u0026#34;misc_auth.json\u0026#34; - rules: - field: \u0026#34;url\u0026#34; regex: \u0026#34;.*esproxy2*\u0026#34; secure_data: \u0026#34;proxy.json\u0026#34; - rules: - field: \u0026#34;name\u0026#34; regex: \u0026#34;.*\u0026#34; secure_data: \u0026#34;default.json\u0026#34; global: debug: true ignore_ssl_errors: false\rUsername / Password You can also use username/password credentials of an admin user to authenticate with the Grafana API. You can specify them in your configuration file (eg. importer.yml).\ncontext_name: main contexts: main: url: https://grafana.example.org user_name: \u0026lt;your username\u0026gt; password: \u0026lt;your password\u0026gt; output_path: \u0026#34;myFolder\u0026#34; watched: - Example global: debug: true ignore_ssl_errors: false\rCloud Configuration Several S3 compatible cloud providers are supported. Please see this section for more detailed instructions.\nConnection Connection Credentials Current Behavior (Version +0.5.2) If the connection has BasicAuth enabled, then we\u0026rsquo;ll attempt to set the auth with the following rules.\nWe will try to find a match given the rules specified:\nfield: matches any valid json path and retrieves its value. ie. jsonData.maxConcurrentShardRequests and validates it against a golang supported Regex. It goes down the list of rules and returns the auth for the first matching one. The rules should be listed from more specific to more broad. The default rule ideally should be at the end. testing: output_path: testing_data connections: credential_rules: - rules: - field: \u0026#34;name\u0026#34; regex: \u0026#34;misc\u0026#34; - field: \u0026#34;url\u0026#34; regex: \u0026#34;.*esproxy2*\u0026#34; secure_data: \u0026#34;default.json\u0026#34; url: http://localhost:3000 user_name: admin password: admin ignore_filters: False # When set to true all Watched filtered folders will be ignored and ALL folders will be acted on watched: - General - Other\rthe secure_data will read the file from {output_path}/secure/. It will then use that information to construct the datasource.\nDefault setting if you use basic auth is shown below.\n{ \u0026#34;basicAuthPassword\u0026#34;: \u0026#34;password\u0026#34;, \u0026#34;user\u0026#34;: \u0026#34;user\u0026#34; }\rVersion v0.4.2-v0.5.1 Legacy Behavior\rPreview behavior did not support the use of a secure/secureData.json pattern, instead an auth: codeblock was used.\nPlease note that only basicAuth worked prior to version v0.5.2\nExample can be seen below:\ntesting: output_path: testing_data connections: credential_rules: - rules: - field: name regex: .* auth: user: user password: secret url: http://localhost:3000 user_name: admin password: admin ignore_filters: False # When set to true all Watched filtered folders will be ignored and ALL folders will be acted on watched: - General - Other\rVersion Prior to v0.4.2 Legacy Behavior\rIf the connection has BasicAuth enabled, then we\u0026rsquo;ll attempt to set the auth with the following precedence on matches:\nMatch of DS credentials based on DS name. Match URL regex for the DS if regex specified. Use Default Credentials if the above two both failed. An example of a configuration can be seen below\ntesting: output_path: testing_data connections: credentials: default: user: user password: password misc: user: admin password: secret url_regex: .*esproxy2* url: http://localhost:3000 user_name: admin password: admin ignore_filters: False # When set to true all Watched filtered folders will be ignored and ALL folders will be acted on watched: - General - Other\rConnection Filters Current Behavior (+v0.4.2) You can filter based on any field and have it be an exclusive (default) or inclusive (ie Only allow values that match) to be listed/imported etc.\nPattern matching is the same as the Credentials mapping.\nfield represents any valid JSON Path regex: any valid regex supported by golang The example below will exclude any connections named \u0026ldquo;Google Sheets\u0026rdquo;. It will also only include connections with the type elasticsearch or mysql\ncontexts: testing: output_path: test/data connections: filters: - field: \u0026#34;name\u0026#34; regex: \u0026#34;Google Sheets\u0026#34; - field: \u0026#34;type\u0026#34; regex: \u0026#34;elasticsearch|mysql\u0026#34; inclusive: true\rLegacy Behavior Legacy Behavior\rThis feature allows you to exclude connection by name or include them by type. Please note that the logic switches based on the data type.\nname filter:\n... datasources: filters: name_exclusions: \u0026#34;DEV-*|-Dev-*\u0026#34;\rWill exclude any connection that matches the name regex.\nType Filter\nWill ONLY include connection that are listed.\ndatasources: filters: valid_types: - elasticsearch\rThe snippet above will ONLY import connections for elasticsearch\nNote\nIf you configure both, an auth Token and BasicAuth, then the Token is given priority. Watched folders under grafana is a white list of folders that are being managed by gdg. By default, only \u0026ldquo;General\u0026rdquo; is managed.\nDashboards By default ONLY the General folder is inspected. You may override this behavior by\nOrganization The organization is set for a given context via the orgnization_name. If the org is not set, gdg will fallback on the default value that grafana starts out with Main Org.\nAdditionally, if there is an organization specific behavior, it can be added to a context by adding the following config to your config:\nwatched_folders_override: - organization_name: \u0026#34;Special Org\u0026#34; folders: - General - SpecialFolder\rIn this case, watched_folder is ignored in favor of the newly provided list.\nUsers Users can be imported/exported but the behavior is a bit limited. We cannot retrieve the credentials of the given user. If the users are uploaded, then any user uploaded will have a new password set. The default behavior is set password to the sha256 of the login.json\nExample:\necho -n admin.json | openssl sha256 \u0026gt; SHA2-256(stdin)= f172318957c89be30c2c54abcebb778a86246bbad2325d7133c4dc605319f72b\rAs this can be a security risk if an intruder knows the algorithm, an option to generate random passwords is also available. This can be configured for any context\nuser: random_password: true min_length: 8 max_length: 20\rThe downside, is naturally this is a one time operation. Once the password is set it once again can no longer be retrieved. The only time the password is printed is after the successful upload of all users.\nGlobal Flags These are flags that apply across all contexts. They are top level configuration and are used to drive gdg\u0026rsquo;s application behavior.\nHere are the currently supported flags you may configure.\nglobal: debug: true ignore_ssl_errors: false ##when set to true will ignore invalid SSL errors retry_count: 3 ## Will retry any failed API request up to 3 times. retry_delay: 5s ## will wait for specified duration before trying again.\rdebug: when set will print a more verbose output (Development In Progress). Setting the env flag of DEBUG=1 will also generate verbose output for all HTTP calls. ignore_ssl_errors: when set will disregard any SSL errors and proceed as expected retry_count: will try N number of times before giving up retry_delay: a duration to wait before trying again. Be careful with this setting, if it\u0026rsquo;s too short, the retry won\u0026rsquo;t matter, if too long the app will be very slow. Debugging / Trouble shooting There are two configuration flags that can be very useful to determine the issue.\n... global: debug: true api_debug: true\rThe debug flag enables very logging which may provide some insight on the core issue that you\u0026rsquo;re running into. Additionally, api_debug when enabled with print every request being made and response.\nFor example, attempting to upload all the given folders I get the follow response.\nAPI Logs\rPOST /api/folders HTTP/1.1 Host: localhost:3000 User-Agent: Go-http-client/1.1 Content-Length: 36 Accept: application/json Authorization: Basic YWRtaW46YWRtaW4= Content-Type: application/json X-Grafana-Org-Id: 1 Accept-Encoding: gzip {\u0026#34;title\u0026#34;:\u0026#34;Other\u0026#34;,\u0026#34;uid\u0026#34;:\u0026#34;CWSuYt_nk\u0026#34;} HTTP/1.1 409 Conflict Content-Length: 80 Cache-Control: no-store Content-Type: application/json Date: Wed, 11 Sep 2024 17:07:57 GMT X-Content-Type-Options: nosniff X-Frame-Options: deny X-Xss-Protection: 1; mode=block {\u0026#34;message\u0026#34;:\u0026#34;a folder with the same name already exists in the current location\u0026#34;}\rAs you can see from the logs, a POST request was made to http://localhost:3000/api/folders, the payload was\n{\u0026#34;title\u0026#34;:\u0026#34;Other\u0026#34;,\u0026#34;uid\u0026#34;:\u0026#34;CWSuYt_nk\u0026#34;}\rIt returned a 409 status since the folder already exists and the response was:\n{\u0026#34;message\u0026#34;:\u0026#34;a folder with the same name already exists in the current location\u0026#34;}\rEnvironment Overrides Caution\nComplex data type is not supported. If the value is an array it can\u0026rsquo;t be currently set, via ENV overrides.\nIf you wish to override certain value via the environment, like credentials and such you can do so.\nThe pattern for GDG\u0026rsquo;s is as follows: GDG_SECTION__SECTION__keyname\nFor example if I want to set the context name to a different value I can use:\nGDG_CONTEXT_NAME=\u0026#34;testing\u0026#34; gdg tools ctx show ## Which will override the value from the context file. GDG_CONTEXTS__TESTING__URL=\u0026#34;www.google.com\u0026#34; Will override the URL with the one provided.\r","date":"0001-01-01","id":15,"permalink":"/gdg/docs/gdg/configuration/","summary":"Configuration make a copy of config/importer-example.yml and name it config/importer.yml or simply run gdg tools ctx new \u0026lt;name\u0026gt; which will walk you through setting up a new context to use with your grafana installation.","tags":[],"title":"Configuration"},{"content":"Cloud Support Support for using a few cloud providers as a storage engine is now supported. When enabled, the local file system is only used for reading configuration files. Everything else relies on the data from the cloud provider matching up to your configuration.\nCurrently the following providers are supported:\nAWS S3 Google Storage (GS) Azure Custom (S3 Compatible clouds) Caution\nhttps://github.com/google/go-cloud was used to support all of these providers. They should all work, but only S3 and Google have been properly tested.\nMost of these rely on the system configuration. Here are some references for each respective environment:\nGoogle Storage: https://cloud.google.com/docs/authentication#service-accounts https://cloud.google.com/docs/authentication/provide-credentials-adc#local-user-cred S3: https://docs.aws.amazon.com/sdk-for-go/api/aws/session/ Azure: https://pkg.go.dev/github.com/Azure/azure-sdk-for-go/sdk/storage/azblob Cloud Configuration General storage_engine: any_label: kind: cloud cloud_type: [s3, gs, azblob] bucket_name: \u0026#34;\u0026#34; prefix: \u0026#34;dummy\u0026#34;\rAll authentication and authorization is done outside of GDG.\nCustom Examples of these S3 compatible clouds would be minio and Ceph.\nstorage_engine: some_label: custom: true ## Required, if set to true most of the \u0026#39;custom\u0026#39; configuration will be disregarded. kind: cloud cloud_type: s3 prefix: dummy bucket_name: \u0026#34;mybucket\u0026#34; access_id: \u0026#34;\u0026#34; ## this value can also be read from: AWS_ACCESS_KEY. config file is given precedence secret_key: \u0026#34;\u0026#34; ## same as above, can be read from: AWS_SECRET_KEY with config file is given precedence. init_bucket: \u0026#34;true\u0026#34; ## Only supported for custom workflows. Will attempt to create a bucket if one does not exist. endpoint: \u0026#34;http://localhost:9000\u0026#34; region: us-east-1 ssl_enabled: \u0026#34;false\u0026#34;\rfor custom cloud, the cloud type will be s3, access_id and secret_key are needed and ONLY supported for the custom cloud. Additionally, the custom flag needs to be set to true.\ninit_bucket is another custom only feature that will attempt to create a bucket if one does not exist. endpoint is a required parameter though it does have a fallback to localhost:9000 region defaults to us-east-1 if not configured. Context Configuration This is applicable both standard clouds and cusom. The only additional change to the context is to provide a storage label to use:\ntesting: output_path: testing_data ... storage: any_label ...\rSo given the bucket name of foo with a prefix of bar with the output_path configured as testing_data the connections will be imported to:\ns3://foo/bar/testing_data/connections/ and exported from the same location. If you need it to be in a different location you can update the prefix accordingly but at destination will follow the typical app patterns.\n","date":"0001-01-01","id":16,"permalink":"/gdg/docs/gdg/cloud-configuration/","summary":"Cloud Support Support for using a few cloud providers as a storage engine is now supported. When enabled, the local file system is only used for reading configuration files.","tags":[],"title":"Cloud Configuration"},{"content":"Every namespace supporting CRUD operations has the functions: list, download, upload, clear operating on only the monitored folders.\nConnections Starting with v0.4.6 \u0026ldquo;Datasources\u0026rdquo; was renamed to connections.\nConnections credentials are keyed by the name of the DataSource. See config example. If the connection JSON doesn\u0026rsquo;t have auth enabled, the credentials are ignored. If Credentials are missing, we\u0026rsquo;ll fall back on default credentials if any exist. The password is set as a value for basicAuthPassword in the API payload. Datasources are imported or exported from organization specified in configuration file otherwise current organization user is used.\nAll commands can use connection or c to manage datasources.\n./bin/gdg backup c list -- Lists all current connections ./bin/gdg backup c download -- Import all connections from grafana to local file system ./bin/gdg backup c upload -- Exports all dashboard from local filesystem (matching folder filter) to Grafana ./bin/gdg backup c clear -- Deletes all connections\rDashboards Dashboards are imported or exported from organization specified in configuration file otherwise current organization user is used.\nAll commands can use dashboards or dash to manage dashboards\n./bin/gdg backup dash list -- Lists all current dashboards ./bin/gdg backup dash download -- Import all dashboards from grafana to local file system ./bin/gdg backup dash upload -- Exports all dashboard from local filesystem (matching folder filter) to Grafana ./bin/gdg backup dash clear -- Deletes all dashboards\rYou can also use filtering options to list or import your dashboard by folder or by tags.\n./bin/gdg backup dash download -f myFolder ./bin/gdg backup dash download -t myTag ./bin/gdg backup dash download -t tagA -t tagB -t complex,tagC\rThe command above will return any dashboard that is tagged with tagA or tagB or complex,tagC\nNOTE: Starting with v0.5.2 full crud support for tag filtering. You can list,upload,clear,download dashboards using tag filters. Keep in mind the tag filtering on any matching tags. ie. Any dashboard that has tagA or tagB or complex,tagC will be listed,uploaded, etc.\nFolders Mostly optional as Dashboards will create/delete these are needed but if there is additional metadata you wish to persist you can use this to manage them.\n./bin/gdg backup folders list -- Lists all current folders ./bin/gdg backup folders download -- Import all folders from grafana to local file system ./bin/gdg backup folders upload -- Exports all folders from local filesystem ./bin/gdg backup folders clear -- Deletes all folders\rFolder Permissions This CRUD allows you to import / export folder permissions. Initial release will be part of v0.4.4. There are a lot of nested relationship that go with this.\nExpectations:\nUsers have to already exist. Teams (if used) need to already exist. Folders also need to already exist. The Folder Permissions will list, import and re-apply permissions. But the expectations is that all other entities are already there. Next few iteration will try to add more concurrency for this tool and more error checking when entities that don\u0026rsquo;t exist are being referenced.\nNOTE: Unlike other command, permissions does not have a clear function. Theoretically you could have a folder name with an emtpy array under folder-permissions to clear all known permissions to the folder, but otherwise clearing permissions from all folders seems too destructive to really be a useful function.\n./bin/gdg backup folders list -- Lists all current folder permissions ./bin/gdg backup folders download -- Retrieve all folders permissions from Grafana ./bin/gdg backup folders upload -- Exports all folders from local filesystem\r┌───────────┬──────────────────────────────────────┬───────────────────────────────────────────────────────────────────────────────────┬─────────────┬────────────────────────────────┬────────┬─────────────────┐ │ FOLDER ID │ FOLDERUID │ FOLDER NAME │ USERID │ TEAM NAME │ ROLE │ PERMISSION NAME │ ├───────────┼──────────────────────────────────────┼───────────────────────────────────────────────────────────────────────────────────┼─────────────┼────────────────────────────────┼────────┼─────────────────┤ │ 2272 │ dfba969d-565b-481e-a930-53aa5684992c │ sub-flow │ │ │ │ │ │ │ PERMISSION---\u0026gt; │ admin │ │ Admin │ │ 520 │ GPmSOQNnk │ EngageMap (internal beta) │ │ │ │ │ │ │ PERMISSION---\u0026gt; │ │ Admin │ Edit │ │ │ PERMISSION---\u0026gt; │ │ Editor │ Edit │ │ │ PERMISSION---\u0026gt; │ │ Viewer │ View │ │ 2031 │ n3xS8TwVk │ Team CMS - US dumb dumb │ │ │ │ │ │ │ PERMISSION---\u0026gt; │ │ authscope_team_cms │ │ Edit │ │ 1746 │ pASPyoQVk │ Team DOE-IN-PNNL - DOE-IN Pacific Northwest National Laboratory │ │ │ │ │ └──────────────────────────────────────────────────┴───────────────────────────────────────────────────────────────────────────────────┴─────────────┴────────────────────────────────┴────────┴─────────────────┘\rThe listing includes the folder name, followed by several lines with \u0026ldquo;PERMISSION\u0026mdash;\u0026gt;\u0026rdquo; which will each list a permission. It can a user being granted access or a team being granted a role etc.\nLibrary Elements Library elements are components that can be shared among multiple dashboards. Folder matching will still be applied, so any folders not monitored will be ignored unless explicitly specified. If wildcard flag is enabled, all elements will be acted on irrelevant of folder location\nAll commands can use libraryelements aliased to library and lib for laziness purposes. A more extensive tutorial is available here\n./bin/gdg backup lib list -- Lists all library components ./bin/gdg backup lib download -- Import all library components from grafana to local file system ./bin/gdg backup lib upload -- Exports all library components from local filesystem (matching folder filter) to Grafana ./bin/gdg backup lib clear -- Deletes all library components ./bin/gdg backup lib list-connections \u0026lt;Lib Element UID\u0026gt; -- Will list all of the dashboards connected to the Lib Element (Coming in v0.4.2)\rOrganizations Danger\nAuth: Requires Grafana Admin\nTokens/service account tokens are tied to a specific org and are therefore not supported. Organization Admins don\u0026rsquo;t have access to list all Orgs, therefore are also not supported. Command can use organizations or org to manage organizations.\n./bin/gdg backup org list -- Lists all organizations ./bin/gdg backup org upload -- Upload Orgs to grafana ./bin/gdg backup org download -- Download Orgs to grafana\rA tutorial on working with organizations is available.\nTeams Caution\nUsers need to be created before team export can succeed\n./bin/gdg backup team list -- Lists all known team members ./bin/gdg backup team download -- download all known team members ./bin/gdg backup team upload -- upload all known team members ./bin/gdg backup team clear -- Delete all known team except admin\rTeam Listing\r┌────┬───────────┬───────┬───────┬─────────┬─────────────┬──────────────┬───────────────────┐ │ ID │ NAME │ EMAIL │ ORGID │ CREATED │ MEMBERCOUNT │ MEMBER LOGIN │ MEMBER PERMISSION │ ├────┼───────────┼───────┼───────┼─────────┼─────────────┼──────────────┼───────────────────┤ │ 4 │ engineers │ │ 1 │ 2 │ │ │ │ │ │ │ │ │ │ admin │ Admin │ │ │ │ │ │ │ │ tux │ Member │ │ │ 5 │ musicians │ │ 1 │ 1 │ │ │ │ │ │ │ │ │ │ admin │ Admin │ │ └────┴───────────┴───────┴───────┴─────────┴─────────────┴──────────────┴───────────────────┘\rUsers Only supported with basic auth. Users is the only one where basic auth is given priority. API Auth is not supported, so will try to use basic auth if configured otherwise will warn the user and exit.\nNOTE: admin user is always ignored.\n./bin/gdg backup users list -- Lists all known users ./bin/gdg backup users download -- Lists all known users ./bin/gdg backup users upload -- Export all users (Not yet supported) ./bin/gdg backup users clear -- Delete all known users except admin\r","date":"0001-01-01","id":17,"permalink":"/gdg/docs/usage_guide/backup-guide/","summary":"Every namespace supporting CRUD operations has the functions: list, download, upload, clear operating on only the monitored folders.\nConnections Starting with v0.","tags":[],"title":"Backup Guide"},{"content":"This guide focuses on the \u0026rsquo;tools\u0026rsquo; subcommand. Every command that isn\u0026rsquo;t specific to a CRUD operation falls under the tools command.\nThere are a few utility functions that have been introduced that might be useful to the user, or is geared at managing the configuration, switching contexts or Orgs for a given user and so on.\nAuthentication Management This is mainly added as a convenience mechanism. It was needed to support some testing and exposing the feature is useful as a really simple CLI to create tokens / service Keys. You probably should be using other tooling for managing all your service files and tokens. Unlike most other entities, this is not a backup feature as much as utility.\nThere are two sub commands for auth, service-accounts and tokens (will be deprecated at some point).\nToken Management ./bin/gdg tools auth tokens list -- list current tokens (No access to the actual token secret) ./bin/gdg tools auth tokens new -- Create a new token. new \u0026lt;name\u0026gt; \u0026lt;role\u0026gt; [ttl in seconds, forever otherwise] ./bin/gdg tools auth tokens clear -- Deletes all tokens\rToken Listing\r┌────┬─────────┬───────┬───────────────┐ │ ID │ NAME │ ROLE │ EXPIRATION │ ├────┼─────────┼───────┼───────────────┤ │ 1 │ testing │ Admin │ No Expiration │ └────┴─────────┴───────┴───────────────┘\rExample of creating a new token.\n./bin/gdg auth tokens new foobar Admin 3600\rNew Token\r┌────┬────────┬─────────────────────────────────────────────────────────────┐ │ ID │ NAME │ TOKEN │ ├────┼────────┼─────────────────────────────────────────────────────────────┤ │ 2 │ foobar │ eyJrIjoiNzU2WVhiMEZpVWNlV3hWSUVZQTuIjoiZm9vYmFyIiwiaWQiOjF9 │ └────┴────────┴─────────────────────────────────────────────────────────────┘ Service Accounts ./bin/gdg tools auth svc clear delete all Service Accounts ./bin/gdg tools auth svc clearTokens delete all tokens for Service Account ./bin/gdg tools auth svc list list API Keys ./bin/gdg tools auth svc newService newService \u0026lt;serviceName\u0026gt; \u0026lt;role\u0026gt; [ttl in seconds] ./bin/gdg tools auth svc newToken newToken \u0026lt;serviceAccountID\u0026gt; \u0026lt;name\u0026gt; [ttl in seconds]\r./bin/gdg tools auth svc newService AwesomeSauceSvc admin\rNew Service\r┌────┬─────────────────┬───────┐ │ ID │ NAME │ ROLE │ ├────┼─────────────────┼───────┤ │ 4 │ AwesomeSauceSvc │ Admin │ └────┴─────────────────┴───────┘ ./bin/gdg tools auth svc newToken 4 AwesomeToken\rNew Service\r┌───────────┬──────────┬──────────────┬────────────────────────────────────────────────┐ │ SERVICEID │ TOKEN_ID │ NAME │ TOKEN │ ├───────────┼──────────┼──────────────┼────────────────────────────────────────────────┤ │ 4 │ 3 │ AwesomeToken │ glsa_a14JOaGExOkDuJHjDWScXbxjTBIXScsw_39df7bf5 │ └───────────┴──────────┴──────────────┴────────────────────────────────────────────────┘ ./bin/gdg tools auth svc list\rService Listing\r┌────┬─────────────────┬───────┬────────┬──────────┬──────────────┬───────────────┐ │ ID │ SERVICE NAME │ ROLE │ TOKENS │ TOKEN ID │ TOKEN NAME │ EXPIRATION │ ├────┼─────────────────┼───────┼────────┼──────────┼──────────────┼───────────────┤ │ 4 │ AwesomeSauceSvc │ Admin │ 1 │ │ │ │ │ │ │ │ │ 3 │ AwesomeToken │ No Expiration │ └────┴─────────────────┴───────┴────────┴──────────┴──────────────┴───────────────┘ Dashboard Linter Integrated the official grafana linter into GDG. Allows you to run the linter as part of gdg.\ngdg tools dashboard lint -d bandwidth-patterns -f testing\rYou can execute this on a single dashboard, or a folder. \u0026ndash;autofix is available but should be considered a beta feature.\nDevel Some developer helper utilities\n./bin/gdg tools devel completion [bash|fish|powershell|zsh] -- Will generate autocompletion for GDG for your favorite shell ./bin/gdg tools devel srvinfo -- print grafana server info\rOrganizations Command can use organizations or org to set the organizations in the configuration file.\nNOTE: this only manages top level of the orgs structure. Mainly used for a lazy man pattern.\n./bin/gdg tools org set --orgName \u0026lt;name\u0026gt; OR --orgSlugName \u0026lt;name\u0026gt; -- Sets a given Org filter. All Dashboards and Datasources etc are uploaded to the given Org only.\rAdditionally addUser, updateUserRole, deleteUser, listUsers are all used to manage a user\u0026rsquo;s membership within a given organization.\nOrganizations Preferences There are a few properties that can be set to change behavior. Keep in mind that all of these entity need to be owned by the Org, you cannot reference to a dashboard outside of a given org.\n## will set the weekstart as Tuesday and a default Org theme of dark gdg t orgs prefs set --orgName \u0026#34;Main Org.\u0026#34; --theme dark --weekstart tuesday ## Retrieve the Orgs Preferences gdg t orgs prefs get --orgName \u0026#34;Main Org.\u0026#34;\r┌──────────────────┬─────────┐ │ FIELD │ VALUE │ ├──────────────────┼─────────┤ │ HomeDashboardUID │ │ │ Theme │ dark │ │ WeekStart │ tuesday │ └──────────────────┴─────────┘\rOrganization Users CRUD gdg tools organizations users add [OrgSlug] [userID] Role[admin,editor,viewer] ## Add user to org example: gdg tools organizations users add testing 3 admin gdg tools organizations users list OrgID ## List all users for a given org example: gdg tools organizations users list 4 gdg tools organizations users updateRole [OrgSlug] [UserId] Role[admin,editor,viewer] example: gdg tools organizations users updateRole testing 2 admin gdg tools organizations users currentOrg ## displays the logged in User\u0026#39;s current associated Org gdg tools organizations users delete OrgID ## Removes a user from the given org\rUsers CRUD is under the \u0026lsquo;backup\u0026rsquo; command. The tools subcommand allows you to promote a given user to a grafana admin if you have the permission to do so.\nNOTE: admin user is always ignored.\n./bin/gdg tools users promote -u user@foobar.com -- promotes the user to a grafana admin\r","date":"0001-01-01","id":18,"permalink":"/gdg/docs/usage_guide/tools-guide/","summary":"This guide focuses on the \u0026rsquo;tools\u0026rsquo; subcommand. Every command that isn\u0026rsquo;t specific to a CRUD operation falls under the tools command.","tags":[],"title":"Tools Guide"},{"content":"The features listed below are for the enterprise edition of Grafana only. They will not work on the OSS version.\nIn order to use these features you need.\nHave a running Enterprise version of grafana, I\u0026rsquo;ll defer to the grafana community on instructions on how to set this up. For a docker setup, you need to set:\nGF_ENTERPRISE_LICENSE_TEXT='jwt token value'\nConnections Permissions Note: Available with +v0.4.6. All of these commands are a subset of the connection command. Requires grafana version: +v10.2.3\nAll commands can use permission or p to manage connection permissions.\n./bin/gdg c permission list -- Lists all current connections permissions ./bin/gdg c permission download -- Download all connections from grafana to local file system ./bin/gdg c permission upload -- Exports all dashboard from local filesystem (matching folder filter) to Grafana ./bin/gdg c permission clear -- Deletes all connections Permissions (Leaving only the default values)\rYou can additionally filter by connection slug in order to only operate on a single connection.\n./bin/gdg c permission list --connection my-elastic-connection Permission Listing\r┌────┬───────────┬───────────────────┬───────────────┬─────────────────────────────────┬────────────────────────────────┬──────────────────────────────────────────────────────────────┐ │ ID │ UID │ NAME │ SLUG │ TYPE │ DEFAULT │ URL │ ├────┼───────────┼───────────────────┼───────────────┼─────────────────────────────────┼────────────────────────────────┼──────────────────────────────────────────────────────────────┤ │ 1 │ uL86Byf4k │ Google Sheets │ google-sheets │ grafana-googlesheets-datasource │ false │ http://localhost:3000/connections/datasources/edit/uL86Byf4k │ │ 1 │ uL86Byf4k │ PERMISSION--\u0026gt; │ Admin │ User │ user:admin │ │ │ 1 │ uL86Byf4k │ PERMISSION--\u0026gt; │ Edit │ User │ user:tux │ │ │ 1 │ uL86Byf4k │ PERMISSION--\u0026gt; │ Query │ User │ user:sa-1-test-service-account │ │ │ 1 │ uL86Byf4k │ PERMISSION--\u0026gt; │ Query │ Team │ team:engineers │ │ │ 1 │ uL86Byf4k │ PERMISSION--\u0026gt; │ Admin │ BuiltinRole │ builtInRole:Admin │ │ │ 1 │ uL86Byf4k │ PERMISSION--\u0026gt; │ Query │ BuiltinRole │ builtInRole:Viewer │ │ │ 1 │ uL86Byf4k │ PERMISSION--\u0026gt; │ Query │ BuiltinRole │ builtInRole:Editor │ │ │ 3 │ rg9qPqP7z │ netsage │ netsage │ elasticsearch │ true │ http://localhost:3000/connections/datasources/edit/rg9qPqP7z │ │ 3 │ rg9qPqP7z │ PERMISSION--\u0026gt; │ Admin │ User │ user:admin │ │ │ 3 │ rg9qPqP7z │ PERMISSION--\u0026gt; │ Query │ BuiltinRole │ builtInRole:Editor │ │ │ 3 │ rg9qPqP7z │ PERMISSION--\u0026gt; │ Admin │ BuiltinRole │ builtInRole:Admin │ │ │ 3 │ rg9qPqP7z │ PERMISSION--\u0026gt; │ Query │ BuiltinRole │ builtInRole:Viewer │ │ │ 2 │ i6uqEqE7k │ Netsage TSDS │ netsage-tsds │ globalnoc-tsds-datasource │ false │ http://localhost:3000/connections/datasources/edit/i6uqEqE7k │ │ 2 │ i6uqEqE7k │ PERMISSION--\u0026gt; │ Admin │ User │ user:admin │ │ │ 2 │ i6uqEqE7k │ PERMISSION--\u0026gt; │ Query │ BuiltinRole │ builtInRole:Viewer │ │ │ 2 │ i6uqEqE7k │ PERMISSION--\u0026gt; │ Query │ BuiltinRole │ builtInRole:Editor │ │ │ 2 │ i6uqEqE7k │ PERMISSION--\u0026gt; │ Admin │ BuiltinRole │ builtInRole:Admin │ │ └────┴───────────┴───────────────────┴───────────────┴─────────────────────────────────┴────────────────────────────────┴──────────────────────────────────────────────────────────────┘\r","date":"0001-01-01","id":19,"permalink":"/gdg/docs/usage_guide/enterprise-guide/","summary":"The features listed below are for the enterprise edition of Grafana only. They will not work on the OSS version.","tags":[],"title":"Enterprise Guide"},{"content":"These are miscellaneous commands that don\u0026rsquo;t fit under any category.\nContexts Starting with version 0.1.4 contexts are now supported. Your config can contain one or multiple contexts which are essentially a grafana server configuration.\nctx is shorthand for context and basic CRUD is supported which is mainly tooling to make it easier to avoid updating the yaml file manually\n./bin/gdg tools ctx list -- Lists all known contexts ./bin/gdg tools ctx show qa -- shows the configuration for the selected context ./bin/gdg tools ctx set production -- updates the active config and sets it to the request value. ./bin/gdg tools ctx delete qa -- Deletes the QA context ./bin/gdg tools ctx cp qa staging -- copies the qa context to staging and sets it as active ./bin/gdg tools ctx clear -- Will delete all active contexts leaving only a single example entry\rVersion Print the applications release version\n./bin/gdg version\rBuild Date: 2022-05-05-13:27:08 Git Commit: 34cc84b3d80080aa93e74ed37739bddc3638997c+CHANGES Version: 0.1.11 Go Version: go1.18 OS / Arch: darwin amd64\r","date":"0001-01-01","id":20,"permalink":"/gdg/docs/usage_guide/other-commands/","summary":"These are miscellaneous commands that don\u0026rsquo;t fit under any category.\nContexts Starting with version 0.1.4 contexts are now supported. Your config can contain one or multiple contexts which are essentially a grafana server configuration.","tags":[],"title":"Other Commands"},{"content":"Release Notes for v0.7.0 Issues with go releaser process. No ChangeLog\nRelease Notes for v0.7.1 Major features in this release are:\nImprovement in performance when dealing with multiple organizations users and preference management. Support for nested folders which affects folders, folder permissions, and dashboards. See blog post here Regex pattern matching dashboard watched folder (nested folders would require the full path name to match otherwise) Additionally, api_debug has been introduced. When enabled it will print every request made to grafana as well as the response recieved from the server.\nBreaking Changes #289 Config: Connection settings renamed exclude_filters to filters Folder Permissions are now saving as uid.json rather than folder name. Nested folder allows for name collisions, using uids should avoid that issue. Folder Permissions are now saving as slug of nested folder path rather than folder name. Nested folder allows for name collisions, so foobar/dummy/abcd ==\u0026gt; foobar-dummy-abcd.json Config: ignore_dashboard_filters property has been renamed to dashboard_settings.ignore_filters. Previous behavior:\nfilter_override: ignore_dashboard_filters: true\rhas been deprecated in favor of\ndashboard_settings: ignore_filters: true\rChanges #171 Nested Folder support added. (Only available in grafana +v11) Enterprise config flag removed, future versions will programmatically determine version of grafana. #283 Fixing small bug with library connections #288 Enterprise: Connection permission will require min. v10.2.3 Bug/Security Fixes #268 Fixing some bad URLs in release #270 Fixing cli docs for deletingUserFromOrg, performance tweak to org upload. dependabot Bump github.com/docker/docker from 25.0.0+incompatible to 25.0.6+incompatible. #285 Fixing Security issue #283 Small bug with dispalying library connections data Developer Changes Upgraded to latest grafana openapi client. #269 Adding a google analytics tracking on the gdg website. Release Notes for v0.7.0 ","date":"2024-09-11","id":21,"permalink":"/gdg/docs/releases/version-v0.7/","summary":"Release Notes for v0.7.0 Issues with go releaser process. No ChangeLog\nRelease Notes for v0.7.1 Major features in this release are:","tags":[],"title":"version v0.7"},{"content":"Release Notes for v0.6.0 Release Date: 03/11/2024\nBreaking Changes This is a major release, so once again doing some cleanups and introducing some breaking changes. Please use version v0.5.2 if you wish to maintain backward compatibility. Previous version organized downloads by org_id. Example an export for dashboards would be stored in export/org_1/dashboards. The org ID is inconsistent and something that cannot be guaranteed across installations of grafana. Instead, we\u0026rsquo;ve switched over to using a slug of the OrgName. The default dashboard backup will go in: export/org_main-org/dashboards.\nCaution\nIf you renamed the default organization to something else besides Main Org., be sure to set organization_name in your config, otherwise nothing will work.\nThe import/export dashboards keyword provided confusion. It has been phased out bit by bit. In version 0.6 all references have now been removed. Import has been renamed to download, and export is now upload.\norganization_id is deprecated in the importer config in favor of organization_name.\nNew Features Retry logic. You can now set a number of retry_count and retry_delay in the configuration that retries failed API calls User upload now has the ability to generate random passwords. (Please be aware that those values can\u0026rsquo;t be recreated) JSON output has been added. This can be somewhat unstructured but is available to the user. --output json with the default rendering being table format. Linter support! (Beta) Grafana official linter has been added to GDG tools dashboard lint. gdg-generate CLI behavior has been updated to better mimic what gdg is already doing. Restructuring into subcommands. Org Preferences can now be retrieved when listing Orgs. --with-preferences Caution\nThis is a heavy call currently till this issue is resolved. Use with caution if you have many Organizations in your grafana instance.\nChanges #192 Dropping support for various entities. import/export no longer supported. Removed warning for datasources (Deprecated config). Removed AlertNotification as it\u0026rsquo;s been deprecated from grafana for a while now. #254 #258 org_id usage has been deprecated. Switching mainly using orgName / SlugName to allow for a more consistent experience between grafana installations. Change affects gdg and gdg-generate User import now has support for random password generator. Only printed upon import. #259 Adding support for Org Properties. Allowing a user to update a given orgs properties. Data also added to org Listing. #251 Adding a dashboard linter tool. The official grafana is recommended, but GDG will provide similar functionality. Bug Fixes #253 In order to manage orgs, the grafana admin that is configured needs to be a part of all organizations. This ticket adds a sanity check to ensure that the configured Grafana Admin is part of all known organizations. It then programmatically adds the user (if user confirms and the feature is supported), otherwise gdg will list all orgs that the user needs to be added. Developer Changes Upgraded to go 1.22 Updated documentation instructions relating to install Website theme upgraded to latest version ","date":"2023-09-01","id":22,"permalink":"/gdg/docs/releases/version-v0.6/","summary":"Release Notes for v0.6.0 Release Date: 03/11/2024\nBreaking Changes This is a major release, so once again doing some cleanups and introducing some breaking changes.","tags":[],"title":"version v0.6"},{"content":"Release Notes for v0.5.2 Changes #229 Datasource auth has been moved to a file based configuration under secure/. This allows for any number of secure values to be passed in. Using the wizard for initial config is recommended, or see test data for some examples. #168 Introduced a new tool called gdg-generate which allows for templating of dashboards using go.tmpl syntax. gdg context has been moved under tools. ie. gdg tools ctx instead of gdg ctx #221 Version check no longer requires a valid configuration #236 Dashboard filter by tag support. Allows a user to only list,delete,upload dashboards that match a set of given tags. Bug Fixes #235 Fixed a bug that prevented proxy grafana instances from working correctly. ie. someURL/grafana/ would not work since it expected grafana to hosted on slash (/). Developer Changes Migrated to Office Grafana GoLang API refactored packages, moving cmd-\u0026gt; cli, and created cmd/ to allow for multiple binaries to be generated. Release Notes for v0.5.1 Release Date: 11/03/2023\nChanges TechDebt: Rewriting the CLI flag parsing to allow for easier testing patterns. Should mostly be transparent to the user. OrgWatchedFolders added a way to override watched folders for a given organization #93 Homebrew support added in. First pass at having a homebrew release. Bug Fixes Tiny patch to fix website documentation navigatioin #205 fixes invalid cross-link device when symlink exists to /tmp filesystem. #206 fixed behavior issue Developer Changes Replaced Makefile with Taskfiles. Added dockertest functionality. Allows for a consistent testing pattern on dev and CI. postcss security bug. Added a new integration pattern to allow all tests to be executed with tokens and basicauth to ensure behavior is consistent when expected Notes on 0.5.x This is going to be a fairly big release and changing several of the expectations that GDG had before.\nThe main push for this was to support organizations a bit better, and the only way to really do this correctly was to change the destination path of where the orgs are being saved. Every entity that supports organization will now be namespace by the org it belongs to. This will now allow GDG to manage connections and dashboards across multiple organizations.\nThe other big change, is that most feature are now namespaced under either \u0026lsquo;backup\u0026rsquo; or \u0026rsquo;tools\u0026rsquo; with the exception context which a GDG concept. The intent of the CLI was getting a bit murky. There is functionality to create a service account, modify a user permission and so on which is a good bit different from the initial intent of GDG which was to simply manage entities. Any additional features beyond the crud are under tools. This might be split into two different binaries later down the line but the separation helps clarify the intent.\nDatasources have also been deprecated in favor of \u0026lsquo;Connections\u0026rsquo; to match the Grafana naming convention changes.\nRelease Notes for v0.5.0 Release Date: 09/01/2023\nChanges Adding support for Basic CRU for Orgs #179 Renamed \u0026lsquo;DataSources\u0026rsquo; command to \u0026lsquo;Connections\u0026rsquo; to match Grafana\u0026rsquo;s naming convention. Connection Permissions are now supported. This is an enterprise features and will only function if you have an enterprise version of grafana. Enterprise features are enabled by setting enterprise_support: true for a given context. #166 Namespacing all supported entities by organization. Add support for custom S3 Provider (ie. enables ceph, minio and other S3 compatible providers to work with GDG), related discussion Technical Debt Misc dependencies updates for website and gdg dependencies. Clean up of the Storage interface Updated CICD to only pushed documentation changes on tag release. Bug Fixes Fixed issue with import team member with elevated permissions. #149 Breaking Changes datasources have been renamed as connections. If you have an existing backup, simply rename the folder to \u0026lsquo;connections\u0026rsquo; and everything should continue working. All Orgs namespaced backups (ie. everything except users and orgs) need to be moved under their respective org folder. ie. org_1 where the given Org has an ID of 1. All commands have now been moved under \u0026lsquo;backup\u0026rsquo; or \u0026rsquo;tools\u0026rsquo; to better reflect their functionality. #183 organization config is deprecated in favor of organization_id. ","date":"2023-09-01","id":23,"permalink":"/gdg/docs/releases/version-v0.5/","summary":"Release Notes for v0.5.2 Changes #229 Datasource auth has been moved to a file based configuration under secure/. This allows for any number of secure values to be passed in.","tags":[],"title":"version v0.5"},{"content":"Release Notes for v0.4.5 Release Date: 07/13/2023\nChanges: Fixing broken CICD release process Release Notes for v0.4.4 Release Date: 07/13/2023\nChanges #159 Due to confusion that has been generated with using import/export. The action verbs were replaced with download/upload with the previous cmds still left in as functional elements. All \u0026lsquo;import\u0026rsquo; has been replaced with \u0026lsquo;download\u0026rsquo; action. All \u0026rsquo;export\u0026rsquo; has been replaced with an \u0026lsquo;upload\u0026rsquo; action. #160 Removed deprecated configuration patterns. Removed datasources.credentials and datasources.filters #167 Adding support for Folder Permissions #170 OS level characters are no longer supported in folders. For example \u0026lsquo;/\u0026rsquo; and \u0026lsquo;' will not be support in any folder GDG backs up. The behavior combined with the mkdir / path command is too buggy to really allow such characters in the names. The complexity in code needed to support it vs just disallowing it isn\u0026rsquo;t worth it. Bug Fixes Bug #156 fixed. When gdg binary and config are in completely different paths, gdg is unable to load the configuration file and fallsback on the default config instead. BUG #170 fixed. Added disallowed characters. For example \u0026ldquo;/\u0026rdquo; and \u0026ldquo;\u0026quot; will not be supported in folder names Some calls failed with invalid SSL. Fixed secondary code path to also support unsigned SSL Release Notes for v0.4.3 Release Date: 04/14/2023\nNew Features Team CRUD support, allows full CRUD on all team and members. Fixes #127 and #147 Known Bug: Permissioning not persisted. All users are added as a member. See issue 149 CLI Tooling introduced to faciliate very basic service management, and token creations for both services and API tokens. Improved Credential mapping and filtering introduced. Allows filtering and credential mapping to be based on any JSON field and regex. Configuration Changes DataSource has had a configuration overhaul. It is technically backward compatible, all previous tests work, with the previous config, but I would highly encourage people to migrate. Next feature I will drop the backward support. URLMatching for Credentials will not work (legacy pattern) if the URL AND the datasource do not match. If you need URL matching with variable datasource names, you will need to migrate to the new configuration. Release Notes for v0.4.2 Issue with release, failed CI, so skipping version.\nRelease Notes for v0.4.1 Release Date: 04/01/2023\nNew Features Library Elements Connections Added support for libraryelement connections. This option allows you to see what dashboards are using the given library. note: You won\u0026rsquo;t be able to delete the library element while there are dashboards utilizing it. Bug Fixes FIXED: Addressing Login issue when Basic Auth is omitted. #144 Release Notes for v0.4.0 Release Date: 03/31/2023\nThis is a major change from the previous one, I\u0026rsquo;ll likely cut the 1.x soon and start following the more typical Semver conventions. Aka Major version is a breaking change, Minor is just that, patches for previous versions.\nPlease see the API Changes notes below.\nNew Features Wild card flag You can now set a flag under each context that will ignore Watched Folders and retrieve all dashboards.\ncontext_name: dashboard_settings: ignore_filters: false #\rLibraryElements support added. Please see the usage guide here and a brief tutorial available here\nFolders Update Introducing a \u0026ndash;use-filters. When enabled will only operate on folders configured. Default is to create/update/delete all folders in the grafana instance.\nBreaking Changes: SFTP support dropped. See the Cloud configuration section. Switched out the library we relied on, which means the auth has moved out of GDG config and relies on the system config.\nAPI SDK Changes: I have been trying to find a proper library to use so I\u0026rsquo;m not re-writing and reinventing the wheel so to speak.\nFor reference, here are all the current \u0026ldquo;active\u0026rdquo; (active can be a relative term for some of these project) development I\u0026rsquo;m aware of.\nGrafana Tools SDK Initial version of GDG was based on this project. It mostly works but getting any PRS accepted can be tedious and it\u0026rsquo;s needs some help. Grafana API Go Client Owned by the Grafana Org which is nice, but it has a slightly different goal. It\u0026rsquo;s primary goal is to support the terraform provider for Grafana. I also found some endpoints missing very early on. So decided not to go with it. Swagger Based: There\u0026rsquo;s a branch that I\u0026rsquo;ve been keeping an eye on. https://github.com/grafana/grafana-api-golang-client/tree/papagian/generate-client-from-swagger which makes an effort to generate code based on the swagger manifest that\u0026rsquo;s available from Grafana. It\u0026rsquo;s a mostly automated code that pulls data from the Schema and generates the underlying code. It hasn\u0026rsquo;t had much traction of late so I ended up forking the project currently available here Final Choice: Although the Swagger/OpenAPI based version is not great, I\u0026rsquo;ve even ran into a few issues where the documented response does not match the result, it\u0026rsquo;s a lot more encompassing and allows further development without being as limited on upstream changes.\nDataModel Changes I\u0026rsquo;ve tried to utilize mostly the same endpoints to recreate the same behavior for all the various entities, but there is are some changes. For most use cases this shouldn\u0026rsquo;t matter. But you have been officially warned.\nCloud Support The previous abstraction library used to provide S3, GS, SFTP has limited activity and introduced some security vulnerabilities. 0.4.X also changes some of the cloud behavior. It relies on the system authentication rather than having the auth in the config file.\nPlease see the related docs on how to configure your environment.\nAs the Stow library was removed, SFTP has been dropped. The list of current supported cloud providers are: S3, GS, Azure.\n","date":"2023-03-31","id":24,"permalink":"/gdg/docs/releases/version-v0.4/","summary":"Release Notes for v0.4.5 Release Date: 07/13/2023\nChanges: Fixing broken CICD release process Release Notes for v0.4.4 Release Date: 07/13/2023","tags":[],"title":"version v0.4"},{"content":"","date":"2020-10-06","id":25,"permalink":"/gdg/docs/","summary":"","tags":[],"title":"GDG - Grafana Dash-n-Grab"},{"content":"","date":"2020-10-06","id":26,"permalink":"/gdg/","summary":"","tags":[],"title":"GDG - Grafana Dash-n-Grab"},{"content":"","date":"0001-01-01","id":27,"permalink":"/gdg/categories/","summary":"","tags":[],"title":"Categories"},{"content":"","date":"0001-01-01","id":28,"permalink":"/gdg/contributors/","summary":"","tags":[],"title":"Contributors"},{"content":"","date":"0001-01-01","id":29,"permalink":"/gdg/tags/","summary":"","tags":[],"title":"Tags"}]