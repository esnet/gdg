[{"content":"","date":"2025-05-15","id":0,"permalink":"/gdg/docs/releases/","summary":"","tags":[],"title":"Releases"},{"content":"","date":"0001-01-01","id":1,"permalink":"/gdg/docs/gdg/configuration/","summary":"","tags":[],"title":"Configuration"},{"content":"","date":"0001-01-01","id":2,"permalink":"/gdg/docs/gdg/","summary":"","tags":[],"title":"GDG"},{"content":"","date":"0001-01-01","id":3,"permalink":"/gdg/docs/usage_guide/","summary":"","tags":[],"title":"Usage Guide"},{"content":"Release Notes for v0.4.5 Release Date: 07/13/2023\nChanges: Fixing broken CICD release process Release Notes for v0.4.4 Release Date: 07/13/2023\nChanges #159 Due to confusion that has been generated with using import/export. The action verbs were replaced with download/upload with the previous cmds still left in as functional elements. All \u0026lsquo;import\u0026rsquo; has been replaced with \u0026lsquo;download\u0026rsquo; action. All \u0026rsquo;export\u0026rsquo; has been replaced with an \u0026lsquo;upload\u0026rsquo; action. #160 Removed deprecated configuration patterns. Removed datasources.credentials and datasources.filters #167 Adding support for Folder Permissions #170 OS level characters are no longer supported in folders. For example \u0026lsquo;/\u0026rsquo; and \u0026lsquo;' will not be support in any folder GDG backs up. The behavior combined with the mkdir / path command is too buggy to really allow such characters in the names. The complexity in code needed to support it vs just disallowing it isn\u0026rsquo;t worth it. Bug Fixes Bug #156 fixed. When gdg binary and config are in completely different paths, gdg is unable to load the configuration file and fallsback on the default config instead. BUG #170 fixed. Added disallowed characters. For example \u0026ldquo;/\u0026rdquo; and \u0026ldquo;\u0026quot; will not be supported in folder names Some calls failed with invalid SSL. Fixed secondary code path to also support unsigned SSL Release Notes for v0.4.3 Release Date: 04/14/2023\nNew Features Team CRUD support, allows full CRUD on all team and members. Fixes #127 and #147 Known Bug: Permissioning not persisted. All users are added as a member. See issue 149 CLI Tooling introduced to faciliate very basic service management, and token creations for both services and API tokens. Improved Credential mapping and filtering introduced. Allows filtering and credential mapping to be based on any JSON field and regex. Configuration Changes DataSource has had a configuration overhaul. It is technically backward compatible, all previous tests work, with the previous config, but I would highly encourage people to migrate. Next feature I will drop the backward support. URLMatching for Credentials will not work (legacy pattern) if the URL AND the datasource do not match. If you need URL matching with variable datasource names, you will need to migrate to the new configuration. Release Notes for v0.4.2 Issue with release, failed CI, so skipping version.\nRelease Notes for v0.4.1 Release Date: 04/01/2023\nNew Features Library Elements Connections Added support for libraryelement connections. This option allows you to see what dashboards are using the given library. note: You won\u0026rsquo;t be able to delete the library element while there are dashboards utilizing it. Bug Fixes FIXED: Addressing Login issue when Basic Auth is omitted. #144 Release Notes for v0.4.0 Release Date: 03/31/2023\nThis is a major change from the previous one, I\u0026rsquo;ll likely cut the 1.x soon and start following the more typical Semver conventions. Aka Major version is a breaking change, Minor is just that, patches for previous versions.\nPlease see the API Changes notes below.\nNew Features Wild card flag You can now set a flag under each context that will ignore Watched Folders and retrieve all dashboards.\ncontext_name: dashboard_settings: ignore_filters: false #\rLibraryElements support added. Please see the usage guide here and a brief tutorial available here\nFolders Update Introducing a \u0026ndash;use-filters. When enabled will only operate on folders configured. Default is to create/update/delete all folders in the grafana instance.\nBreaking Changes: SFTP support dropped. See the Cloud configuration section. Switched out the library we relied on, which means the auth has moved out of GDG config and relies on the system config.\nAPI SDK Changes: I have been trying to find a proper library to use so I\u0026rsquo;m not re-writing and reinventing the wheel so to speak.\nFor reference, here are all the current \u0026ldquo;active\u0026rdquo; (active can be a relative term for some of these project) development I\u0026rsquo;m aware of.\nGrafana Tools SDK Initial version of GDG was based on this project. It mostly works but getting any PRS accepted can be tedious and it\u0026rsquo;s needs some help. Grafana API Go Client Owned by the Grafana Org which is nice, but it has a slightly different goal. It\u0026rsquo;s primary goal is to support the terraform provider for Grafana. I also found some endpoints missing very early on. So decided not to go with it. Swagger Based: There\u0026rsquo;s a branch that I\u0026rsquo;ve been keeping an eye on. https://github.com/grafana/grafana-api-golang-client/tree/papagian/generate-client-from-swagger which makes an effort to generate code based on the swagger manifest that\u0026rsquo;s available from Grafana. It\u0026rsquo;s a mostly automated code that pulls data from the Schema and generates the underlying code. It hasn\u0026rsquo;t had much traction of late so I ended up forking the project currently available here Final Choice: Although the Swagger/OpenAPI based version is not great, I\u0026rsquo;ve even ran into a few issues where the documented response does not match the result, it\u0026rsquo;s a lot more encompassing and allows further development without being as limited on upstream changes.\nDataModel Changes I\u0026rsquo;ve tried to utilize mostly the same endpoints to recreate the same behavior for all the various entities, but there is are some changes. For most use cases this shouldn\u0026rsquo;t matter. But you have been officially warned.\nCloud Support The previous abstraction library used to provide S3, GS, SFTP has limited activity and introduced some security vulnerabilities. 0.4.X also changes some of the cloud behavior. It relies on the system authentication rather than having the auth in the config file.\nPlease see the related docs on how to configure your environment.\nAs the Stow library was removed, SFTP has been dropped. The list of current supported cloud providers are: S3, GS, Azure.\n","date":"2023-03-31","id":4,"permalink":"/gdg/docs/releases/version-v0.4/","summary":"Release Notes for v0.4.5 Release Date: 07/13/2023\nChanges: Fixing broken CICD release process Release Notes for v0.4.4 Release Date: 07/13/2023","tags":[],"title":"version v0.4"},{"content":"","date":"0001-01-01","id":5,"permalink":"/gdg/docs/templating/","summary":"","tags":[],"title":"Generate Docs (templating)"},{"content":"","date":"2023-09-01","id":6,"permalink":"/gdg/docs/tutorials/","summary":"","tags":[],"title":"Tutorials"},{"content":"Release Notes for v0.5.2 Changes #229 Datasource auth has been moved to a file based configuration under secure/. This allows for any number of secure values to be passed in. Using the wizard for initial config is recommended, or see test data for some examples. #168 Introduced a new tool called gdg-generate which allows for templating of dashboards using go.tmpl syntax. gdg context has been moved under tools. ie. gdg tools ctx instead of gdg ctx #221 Version check no longer requires a valid configuration #236 Dashboard filter by tag support. Allows a user to only list,delete,upload dashboards that match a set of given tags. Bug Fixes #235 Fixed a bug that prevented proxy grafana instances from working correctly. ie. someURL/grafana/ would not work since it expected grafana to hosted on slash (/). Developer Changes Migrated to Office Grafana GoLang API refactored packages, moving cmd-\u0026gt; cli, and created cmd/ to allow for multiple binaries to be generated. Release Notes for v0.5.1 Release Date: 11/03/2023\nChanges TechDebt: Rewriting the CLI flag parsing to allow for easier testing patterns. Should mostly be transparent to the user. OrgWatchedFolders added a way to override watched folders for a given organization #93 Homebrew support added in. First pass at having a homebrew release. Bug Fixes Tiny patch to fix website documentation navigatioin #205 fixes invalid cross-link device when symlink exists to /tmp filesystem. #206 fixed behavior issue Developer Changes Replaced Makefile with Taskfiles. Added dockertest functionality. Allows for a consistent testing pattern on dev and CI. postcss security bug. Added a new integration pattern to allow all tests to be executed with tokens and basicauth to ensure behavior is consistent when expected Notes on 0.5.x This is going to be a fairly big release and changing several of the expectations that GDG had before.\nThe main push for this was to support organizations a bit better, and the only way to really do this correctly was to change the destination path of where the orgs are being saved. Every entity that supports organization will now be namespace by the org it belongs to. This will now allow GDG to manage connections and dashboards across multiple organizations.\nThe other big change, is that most feature are now namespaced under either \u0026lsquo;backup\u0026rsquo; or \u0026rsquo;tools\u0026rsquo; with the exception context which a GDG concept. The intent of the CLI was getting a bit murky. There is functionality to create a service account, modify a user permission and so on which is a good bit different from the initial intent of GDG which was to simply manage entities. Any additional features beyond the crud are under tools. This might be split into two different binaries later down the line but the separation helps clarify the intent.\nDatasources have also been deprecated in favor of \u0026lsquo;Connections\u0026rsquo; to match the Grafana naming convention changes.\nRelease Notes for v0.5.0 Release Date: 09/01/2023\nChanges Adding support for Basic CRU for Orgs #179 Renamed \u0026lsquo;DataSources\u0026rsquo; command to \u0026lsquo;Connections\u0026rsquo; to match Grafana\u0026rsquo;s naming convention. Connection Permissions are now supported. This is an enterprise features and will only function if you have an enterprise version of grafana. Enterprise features are enabled by setting enterprise_support: true for a given context. #166 Namespacing all supported entities by organization. Add support for custom S3 Provider (ie. enables ceph, minio and other S3 compatible providers to work with GDG), related discussion Technical Debt Misc dependencies updates for website and gdg dependencies. Clean up of the Storage interface Updated CICD to only pushed documentation changes on tag release. Bug Fixes Fixed issue with import team member with elevated permissions. #149 Breaking Changes datasources have been renamed as connections. If you have an existing backup, simply rename the folder to \u0026lsquo;connections\u0026rsquo; and everything should continue working. All Orgs namespaced backups (ie. everything except users and orgs) need to be moved under their respective org folder. ie. org_1 where the given Org has an ID of 1. All commands have now been moved under \u0026lsquo;backup\u0026rsquo; or \u0026rsquo;tools\u0026rsquo; to better reflect their functionality. #183 organization config is deprecated in favor of organization_id. ","date":"2023-09-01","id":7,"permalink":"/gdg/docs/releases/version-v0.5/","summary":"Release Notes for v0.5.2 Changes #229 Datasource auth has been moved to a file based configuration under secure/. This allows for any number of secure values to be passed in.","tags":[],"title":"version v0.5"},{"content":"Release Notes for v0.6.0 Release Date: 03/11/2024\nBreaking Changes This is a major release, so once again doing some cleanups and introducing some breaking changes. Please use version v0.5.2 if you wish to maintain backward compatibility. Previous version organized downloads by org_id. Example an export for dashboards would be stored in export/org_1/dashboards. The org ID is inconsistent and something that cannot be guaranteed across installations of grafana. Instead, we\u0026rsquo;ve switched over to using a slug of the OrgName. The default dashboard backup will go in: export/org_main-org/dashboards.\nCaution\nIf you renamed the default organization to something else besides Main Org., be sure to set organization_name in your config, otherwise nothing will work.\nThe import/export dashboards keyword provided confusion. It has been phased out bit by bit. In version 0.6 all references have now been removed. Import has been renamed to download, and export is now upload.\norganization_id is deprecated in the importer config in favor of organization_name.\nNew Features Retry logic. You can now set a number of retry_count and retry_delay in the configuration that retries failed API calls User upload now has the ability to generate random passwords. (Please be aware that those values can\u0026rsquo;t be recreated) JSON output has been added. This can be somewhat unstructured but is available to the user. --output json with the default rendering being table format. Linter support! (Beta) Grafana official linter has been added to GDG tools dashboard lint. gdg-generate CLI behavior has been updated to better mimic what gdg is already doing. Restructuring into subcommands. Org Preferences can now be retrieved when listing Orgs. --with-preferences Caution\nThis is a heavy call currently till this issue is resolved. Use with caution if you have many Organizations in your grafana instance.\nChanges #192 Dropping support for various entities. import/export no longer supported. Removed warning for datasources (Deprecated config). Removed AlertNotification as it\u0026rsquo;s been deprecated from grafana for a while now. #254 #258 org_id usage has been deprecated. Switching mainly using orgName / SlugName to allow for a more consistent experience between grafana installations. Change affects gdg and gdg-generate User import now has support for random password generator. Only printed upon import. #259 Adding support for Org Properties. Allowing a user to update a given orgs properties. Data also added to org Listing. #251 Adding a dashboard linter tool. The official grafana is recommended, but GDG will provide similar functionality. Bug Fixes #253 In order to manage orgs, the grafana admin that is configured needs to be a part of all organizations. This ticket adds a sanity check to ensure that the configured Grafana Admin is part of all known organizations. It then programmatically adds the user (if user confirms and the feature is supported), otherwise gdg will list all orgs that the user needs to be added. Developer Changes Upgraded to go 1.22 Updated documentation instructions relating to install Website theme upgraded to latest version ","date":"2023-09-01","id":8,"permalink":"/gdg/docs/releases/version-v0.6/","summary":"Release Notes for v0.6.0 Release Date: 03/11/2024\nBreaking Changes This is a major release, so once again doing some cleanups and introducing some breaking changes.","tags":[],"title":"version v0.6"},{"content":"","date":"0001-01-01","id":9,"permalink":"/gdg/docs/cookbook/","summary":"","tags":[],"title":"Cookbook"},{"content":"Release Notes for v0.7.2 Release Date: 01/17/2025\nBreaking Changes #318 Only affects those with no valid configuration present. Removed the default config fall back. For backup and tools functionality a valid configuration file is now required. A new cli parameter is introduced: default-config which will print an example configuration to stdout. Feature Changes #319 Remove the requirement for GF_FEATURE_TOGGLES_ENABLE for nested folder as it was incorrectly required in 0.7.1 #302 Adding Alerting Contact Points support. (Beta Feature, API/format may change in the next release) #303 Cleaning up Permission based listings. (Visualization) #274 Adding Dashboard Permissions, enterprise feature. #337 Fix to maintain UIDs when updating dashboards #324 Introducing a new config option to disregard bad folders Example:\ndashboard_settings: ignore_bad_folders: true\rBug Fixes #330 Fix bug with leading prefix in path when using cloud storage #333 Fix bug with documentation search #314 Update README to reflected newly supported features Security Fixes / Technical Debt #326 Bump golang.org/x/crypto from 0.28.0 to 0.31.0 #327 Security Fix: Non-linear parsing of case-insensitive content in net/html #328 Security: Fixing NPM security issues. #328 320 Changed default branch from master to main 332 Added a VHS tape to programmatically re-generate quickstart.gif Release Notes for v0.7.1 Release Date: 09/11/2024\nMajor features in this release are:\nImprovement in performance when dealing with multiple organizations users and preference management. Support for nested folders which affects folders, folder permissions, and dashboards. See blog post here Regex pattern matching dashboard watched folder (nested folders would require the full path name to match otherwise) Additionally, api_debug has been introduced. When enabled it will print every request made to grafana as well as the response recieved from the server.\nBreaking Changes #289 Config: Connection settings renamed exclude_filters to filters Folder Permissions are now saving as uid.json rather than folder name. Nested folder allows for name collisions, using uids should avoid that issue. Folder Permissions are now saving as slug of nested folder path rather than folder name. Nested folder allows for name collisions, so foobar/dummy/abcd ==\u0026gt; foobar-dummy-abcd.json Config: ignore_dashboard_filters property has been renamed to dashboard_settings.ignore_filters. Previous behavior:\nfilter_override: ignore_dashboard_filters: true\rhas been deprecated in favor of\ndashboard_settings: ignore_filters: true\rChanges #171 Nested Folder support added. (Only available in grafana +v11) Enterprise config flag removed, future versions will programmatically determine version of grafana. #283 Fixing small bug with library connections #288 Enterprise: Connection permission will require min. v10.2.3 Bug/Security Fixes #268 Fixing some bad URLs in release #270 Fixing cli docs for deletingUserFromOrg, performance tweak to org upload. dependabot Bump github.com/docker/docker from 25.0.0+incompatible to 25.0.6+incompatible. #285 Fixing Security issue #283 Small bug with dispalying library connections data Developer Changes Upgraded to latest grafana openapi client. #269 Adding a google analytics tracking on the gdg website. Release Notes for v0.7.0 Release Date: 09/11/2024\nIssues with go releaser process. No ChangeLog\n","date":"2024-09-11","id":10,"permalink":"/gdg/docs/releases/version-v0.7/","summary":"Release Notes for v0.7.2 Release Date: 01/17/2025\nBreaking Changes #318 Only affects those with no valid configuration present. Removed the default config fall back.","tags":[],"title":"version v0.7"},{"content":"","date":"0001-01-01","id":11,"permalink":"/gdg/docs/developer/","summary":"","tags":[],"title":"Developer Guide"},{"content":"Release Notes for v0.8.1 Release Date: 06/30/2025\nBugFix: #456 Issued with folders containing spaces Changes: #450 Update GoReleaser configurations (#453) Changes the patterns for brew installs from Formula to Cask: https://goreleaser.com/deprecations/#brews #454 Adding a logo GDG logo (#454) #445 Added a global \u0026ndash;context to easy switch without needing a config change. Release Notes for v0.8.0 Release Date: 06/25/2025\nMajor features in this release are:\nDropped the configuration flag for nested folders (nested_folders) as it is now the default behavior. Dropped the configuration flag to ignore bad folders (nested_folders), instead special characters are handled by URL encoding the output. aka. Folder named /t/'n / r'/booh/k \u0026amp; r will be stored locally as: t/n+%2F+r/booh/n+%2F+r.json\nThis should allow us to support any folder name but if you have a folder with special characters in its name any regex you are using should be updated accordingly.\nMin Recommended Grafana Versions: While most behavior should be backward compatible gdg v0.8.x is tested with grafana 11 and 12. Anything older use at your own risk. Please use grafana +11.\nBreaking Changes #374 Removed Tooling around creating a token, service account has replaced this feature. #412 Updates to library elements introducing a new data model. Previous backups will not be compatible with v0.8 Changes #408 Nested Folder support added as a default behavior #134 Adding support for Alerting entities. (rules, contact points, templates, policies) #421 Added support for an auth file as well as secure location override. Bug/Security Fixes #425 Fixing behavior with missing trailing slash Developer Changes #411 [TechDebt] Removing references to InitTestLegacy (#411) Upgraded to latest grafana openapi client. #427 Re-enabling code coverage report uploading to cobertura Tech Updates updated to latest grafana-api client. various golang/npm updates removed and updated tests to no longer use a deprecated pattern. gopls modernize tool updates ","date":"2025-05-15","id":12,"permalink":"/gdg/docs/releases/version-v0.8/","summary":"Release Notes for v0.8.1 Release Date: 06/30/2025\nBugFix: #456 Issued with folders containing spaces Changes: #450 Update GoReleaser configurations (#453) Changes the patterns for brew installs from Formula to Cask: https://goreleaser.","tags":[],"title":"version v0.8"},{"content":"Setup new configuration You can create new context configuration using an interactive setup.\n$ gdg tools contexts new mycontext\rWhen creating a new context, you will be asked for authorization type, your default datasource and username/password, along with which folders you wish to manage under the context. You have three options:\nDefault option (\u0026ldquo;General\u0026rdquo;) List of folders you wish to manage Wildcard configuration (all folders) Authentication Concepts First let\u0026rsquo;s touch on a few things regrading grafana and authentication. You can connect to the grafana API (which is what GDG is using) by either using basic authentication (aka. username/password) or using a service token.\nTokens are bound to a specific org and cannot cross the Org separation no matter what permission they are given. Users can be grafana admins, org admins ect. What they can/cannot do will vary on what entities you\u0026rsquo;re trying to access.\nAnything do to with Org will require a grafana admin. If you\u0026rsquo;re trying to fetch dashboards a service token will work fine.\n1. Using Config: The simplest way to set up you auth is to have everything in the importer.yml. It\u0026rsquo;s not a very secure pattern if you\u0026rsquo;re deploying this to a remote server as everything is in plaintext, but it will get you started.\nThis should be perfectly fine if you\u0026rsquo;re only running this locally.\nSimply use the new context wizard reference above to set that up or set a value for: password and token for the given context.\n2. Using Environment Variables: You can also override the value using ENV var that line up to the section you want do override:\nEx:\nGDG_CONTEXTS__TESTING__PASSWORD=1234 GDG_CONTEXTS__TESTING__TOKED=1234\rwill set the token and password value to the one in the ENV.\nKeep in mind that the config entry for token and password still need to exist in the config file even if it\u0026rsquo;s set to an empty value.\nDanger\nBe careful with using convenience utility around contexts (ake set, copy, delete, etc.) Anything that write to the config file will leak those credentials and persist them to the given config file.\nAll alerting entities will ignore folder watch list, and any other filter set.\n3. Using a secure auth location: You can create an auth file in the secure folder with tho following format:\n{ \u0026#34;password\u0026#34;: \u0026#34;4321\u0026#34;, \u0026#34;token\u0026#34;: \u0026#34;shhh\u0026#34; }\rfor context named testing, the file would be called testing_auth.json stored is output_path/secure/ or whatever location you\u0026rsquo;ve configured to store your secure data in.\nPriority Secure Auth takes precedence over environment variables, and then config file.\nImport / Download Dashboards Minimal configuration (eg. the importer.yml file) that you need to download your dashboards from your Grafana endpoint:\ncontext_name: all contexts: all: url: https://grafana.example.org token: \u0026#34;\u0026lt;\u0026lt;Grafana API Token\u0026gt;\u0026gt;\u0026#34; # user_name: admin # password: admin output_path: exports watched: - Example - Infrastructure global: debug: true ignore_ssl_errors: false\rYou need to adjust three parts in the configuration in order to function:\nGrafana URL: This is just a URL where your Grafana is available. API Key OR Username / Passoword for Admin user. See authentication section if you need more information. Downloaded Folders: The watched field defines folders which will be considered for manipulation. You can see these folders in your Grafana Web UI, under Dashboards \u0026gt; Management. From there, you can simply define the folders you want to be downloaded in the watched list. The dashboards are downloaded as JSON files in the $OUTPUT_PATH/dashboards/$GRAFANA_FOLDER_NAME directory. Where $OUTPUT_PATH is the path defined in the dashboard_output configuration property and $GRAFANA_FOLDER_NAME the name of the folder from which the dashboards were downloaded. Note\nStarting with verions 0.7.0 regex patterns for folders are now supported, ex: Other|General, folder/*\nAfter you are done, and you can execute ./bin/gdg dash list successfully, eg.:\n$ ./bin/gdg dash list time=\u0026#34;2021-08-22T11:11:27+02:00\u0026#34; level=warning msg=\u0026#34;Error getting organizations: HTTP error 403: returns {\\\u0026#34;message\\\u0026#34;:\\\u0026#34;Permission denied\\\u0026#34;}\u0026#34; time=\u0026#34;2021-08-22T11:11:28+02:00\u0026#34; level=info msg=\u0026#34;Listing dashboards for context: \u0026#39;all\u0026#39;\u0026#34; ┌────┬───────────────────────────────────┬───────────────────────────────────┬────────────────┬────────────┬────────────────────────────────────────────────────────────────────────────┐ │ ID │ TITLE │ SLUG │ FOLDER │ UID │ URL │ ├────┼───────────────────────────────────┼───────────────────────────────────┼────────────────┼────────────┼────────────────────────────────────────────────────────────────────────────┤ │ 8 │ AWS CloudWatch Logs │ aws-cloudwatch-logs │ Infrastructure │ AWSLogs00 │ https://grafana.example.org/d/AWSLogs00/aws-cloudwatch-logs │ │ 6 │ AWS ECS │ aws-ecs │ Infrastructure │ ly9Y95XWk │ https://grafana.example.org/d/ly9Y95XWk/aws-ecs │ │ 5 │ AWS ELB Application Load Balancer │ aws-elb-application-load-balancer │ Infrastructure │ bt8qGKJZz │ https://grafana.example.org/d/bt8qGKJZz/aws-elb-application-load-balancer │ │ 4 │ AWS RDS │ aws-rds │ Infrastructure │ kCDpC5uWk │ https://grafana.example.org/d/kCDpC5uWk/aws-rds │ │ 3 │ AWS S3 │ aws-s3 │ Infrastructure │ AWSS31iWk │ https://grafana.example.org/d/AWSS31iWk/aws-s3 │ │ 17 │ Cluster Autoscaling │ cluster-autoscaling │ Example │ iHUYtABMk │ https://grafana.example.org/d/iHUYtABMk/cluster-autoscaling │ └────┴───────────────────────────────────┴───────────────────────────────────┴────────────────┴────────────┴────────────────────────────────────────────────────────────────────────────┘\rAfter executing ./bin/gdg dash import you can find the dashboards of the Infrastructure folder in the local directory dashboards/dashboards/Infrastructure and the dashboards of the Example directory in the local directory dashboards/dashboards/Example.\nExport / Upload Dashboards Minimal configuration (eg. the importer.yml file) that you need to upload your dashboards from your Grafana endpoint:\ncontext_name: all contexts: all: url: https://grafana.example.org token: \u0026#34;\u0026lt;\u0026lt;Grafana API Token\u0026gt;\u0026gt;\u0026#34; # user_name: admin # password: admin output_path: exports watched: - Example - Infrastructure global: debug: true ignore_ssl_errors: false\rYou need to adjust three parts in the configuration in order to function:\nGrafana URL: This is just a URL where your Grafana is available. API Key OR Username / Passoword for Admin user. See authentication section if you need more information. Uploaded Folders: The watched field defines folders which will be considered for manipulation. The dashboards should be stored as JSON files in the $OUTPUT_PATH/dashboards/$GRAFANA_FOLDER_NAME directory. Where $OUTPUT_PATH is the path defined in the dashboard_output configuration property and $GRAFANA_FOLDER_NAME the name of the folder to which the dashboards will be uploaded. In case of the above configuration file, the dashboards should be stored locally in the dashboards/dashboards/Example and dashboards/dashboards/Infrastructure/ directories. ├── bin | └── gdg └── exports └── org_main-org | └── dashboards | └─ Example | | └── cluster-scaling.json | └─ Infrastructure | └── aws-ecs.json\rYou can execute ./bin/gdg backup dash export to upload the local dashboards to your Grafana. Afterwards, you can try running ./bin/gdg dash list in order to confirm that your dashboards were uploaded successfully.\n","date":"0001-01-01","id":13,"permalink":"/gdg/docs/gdg/getting-started/","summary":"Setup new configuration You can create new context configuration using an interactive setup.\n$ gdg tools contexts new mycontext\rWhen creating a new context, you will be asked for authorization type, your default datasource and username/password, along with which folders you wish to manage under the context.","tags":[],"title":"Getting Started"},{"content":"Installation The easiest way to install GDG is to get one of the pre-compiled binaries from our release page which can be found here. Packages for a few distributions have been added. The release cycle relies on goreleaser so anything that is well supported can be added it at some point. There is no APT or such you can connect to but the packages are available for download.\nThe following packages are currently supported:\nRPM APK Docker Brew Package Installation Install from package involves downloading the appropriate package from the release and installing it as you usually do on your favorite Distro.\nrpm -Uvh ./gdg_0.6.0_amd64.rpm dpkg -i ./gdg_0.6.0_amd64.deb\rHomebrew Installation brew tap esnet/gdg brew update brew install gdg\rIf there is a conflict you can try to be explicit.\nbrew install esnet/gdg/gdg\rDocker usage The docker tags are released started with 0.3.1. Each release will generate a major version and minor version tag.\nYou can see the available images here\ndocker pull ghcr.io/esnet/gdg:0.6.0\rNOTE: ghcr.io/esnet/gdg:0.3 will also point to 0.3.1 until 0.3.2 is released after which it\u0026rsquo;ll point to 0.3.2\nExample compose.\nversion: \u0026#39;3.7\u0026#39; services: gdg: image: ghcr.io/esnet/gdg:0.6.0 command: \u0026#34;--help\u0026#34; ## Add additional parameters here # command: \u0026#34;ds export\u0026#34; ## Pass any cmd on here. volumes: - ./config:/app/config ## where the configuration lives - ./exports:/app/exports ## doesn\u0026#39;t need to be /app/exports but you should export the destination of where exports are being written out to.\rFrom the CLI:\ndocker run -it --rm -v $(pwd)/config:/app/config -v $(pwd)/exports:/app/exports ghcr.io/esnet/gdg:latest ds --help\rInstalling via Go If you have go install you may run the following command to install gdg. Keep in mind there are two binaries you may install.\ngdg ==\u0026gt; Main binary that manages the various entities supported. gdg-generate =\u0026gt; Helper utility that allows you to generate multiple dashboards given a valid configuration and seed data. gdg\ngo install github.com/esnet/gdg/cmd/gdg@latest #for latest go install github.com/esnet/gdg/cmd/gdg@v0.6.0 #for a specific version\rYou can verify the version by running gdg version.\ngdg-generate\ngo install github.com/esnet/gdg/cmd/gdg-generate@latest #for latest go install github.com/esnet/gdg/cmd/gdg-generate@v0.6.0 #for a specific version\rConfiguration You can then create a simple configuration using gdg tools ctx new which will do a best effort to guide to setup a basic config that will get you up and going or read the more detailed documentation that can be found here\nNOTE: wizard doesn\u0026rsquo;t currently support ALL features but it should help you get a head start.\n","date":"0001-01-01","id":14,"permalink":"/gdg/docs/gdg/installation/","summary":"Installation The easiest way to install GDG is to get one of the pre-compiled binaries from our release page which can be found here.","tags":[],"title":"Installation"},{"content":"Can I use GDG to backup grafana? yes and no. GDG is not a full backup solution. If you are migrating from one server to another, doing disaster recovery gdg is not the right tool for the job. Grafana already has some really nice guides for how to do that.\nGDG is used to backup and recreate specific entities. Usually it is used to allow for a consistent way to move say a dashboard, connections, alerts etc from one installation of grafana to the next.\nThe typical use case can be to manage release cycles. Example:\nCreate dashboard on dev, test everything out, pull into on a feature branch, deploy to staging environment. Validate everything looks good and promote it to production.\nWhy does GDG not list all my dashboards? By default, GDG works on a select list of watched or monitored folders. If none are specified, it will limit itself to only operating on General.\nThe folders that it DOES monitor, it is assumed that gdg has full control over. Meaning, anything in those folders is under its pervue, so it may delete all connections and replace them with the ones in its exports. As far as it knows, nobody else should be writing to it. The upload operation implies that you want to sync the export data with the data found in the backup local, cloud, or otherwise.\nPS. if you want to list/import etc all dashboards, you can set the following config for your context.\ndashboard_settings: ignore_filters: false # When set to true all Watched filtered folders will be ignored and ALL folders will be acted on\rI need feature X, can you please add that in? Maybe? If there\u0026rsquo;s enough cycles, it could benefit others, and the feature makes sense I\u0026rsquo;d be happy to. It is also an OSS project, so contributions are always appreciated and welcome. See contributing for more info.\nI need help, where do I go? There is a \u0026ldquo;Discussion\u0026rdquo; area on github where you can start a conversation and ask questions. If you think this is a bug in GDG itself, then please file an issue here. There is a small slack on channel titled #gdg in the grafana slack, you\u0026rsquo;re free to join here\nI don\u0026rsquo;t like GDG because of: A, B, C\u0026hellip; what else can I use Grafanactl Recently Grafana released an official tool to manage resources. Grizzly Prior version of GrafanaCTL Know of any others? Create a PR and add it to the list\n","date":"0001-01-01","id":15,"permalink":"/gdg/docs/gdg/frequently-asked-questions/","summary":"Can I use GDG to backup grafana? yes and no. GDG is not a full backup solution. If you are migrating from one server to another, doing disaster recovery gdg is not the right tool for the job.","tags":[],"title":"Frequently Asked Questions"},{"content":"Every namespace supporting CRUD operations has the functions: list, download, upload, clear operating on only the monitored folders.\nAlerting Alerting is made up of several type of entities: ContactPoints, Alert Rules, Notification Policy and finally Templates.\nSome entities have dependencies on one another.\nExample: Alert Rules need the contact points to exist in older to be created. They also need the folders or dashboards that they operate on to exist.\nDanger\nUnlike most other entities that GDG operates on, Alerting will be global to the Grafana organisation.\nAll alerting entities will ignore folder watch list, and any other filter set.\nContact Points Grafana has a contact point type named \u0026lsquo;grafana-default-email\u0026rsquo; that has an inconsistent behavior. Unless it has been modified, GDG will ignore it on listing, download and upload. If it has been modified, it will not be able to clear it due to grafana restriction and show an error for that particular entity.\n./bin/gdg backup alerting contactpoints list -- Lists all current contact points ./bin/gdg backup alerting contactpoints download -- Download all known contact points ./bin/gdg backup alerting contactpoints upload -- Upload all contact points ./bin/gdg backup alerting contactpoints clear -- Clear all contact points\rExample Output:\r┌────────────────┬─────────┬─────────┬───────────────────────────────────────────────────┐ │ UID │ NAME │ TYPE │ SETTINGS │ ├────────────────┼─────────┼─────────┼───────────────────────────────────────────────────┤ │ fdxmqkyb5gl4xb │ discord │ discord │ {\u0026#34;url\u0026#34;:\u0026#34;[REDACTED]\u0026#34;,\u0026#34;use_discord_username\u0026#34;:false} │ │ aeov0rrgij7r4a │ slack │ slack │ {\u0026#34;recipient\u0026#34;:\u0026#34;testing\u0026#34;,\u0026#34;token\u0026#34;:\u0026#34;[REDACTED]\u0026#34;} │ └────────────────┴─────────┴─────────┴───────────────────────────────────────────────────┘\rNotifications ./bin/gdg backup alerting notifications list -- Lists all current contact points ./bin/gdg backup alerting notifications download -- Download all known contact points ./bin/gdg backup alerting notifications upload -- Upload all contact points ./bin/gdg backup alerting notifications clear -- Clear all contact points\rExample Output:\r┌───────────────────────┬──────────────┐ │ UID │ │ │ RECEIVER │ MATCHERS │ ├───────────────────────┼──────────────┤ │ grafana-default-email │ [[foo = 22]] │ │ slack │ [[moo = 23]] │ └───────────────────────┴──────────────┘\rRules ./bin/gdg backup alerting rules list -- Lists all rules ./bin/gdg backup alerting rules download -- Download all known rules ./bin/gdg backup alerting rules upload -- Upload all rules ./bin/gdg backup alerting rules clear -- Clear all rules\rExample Output:\r┌──────┬────────────────┬────────────────┬───────────┬───────┐ │ NAME │ UID │ FOLDERUID │ RULEGROUP │ FOR │ ├──────┼────────────────┼────────────────┼───────────┼───────┤ │ boom │ aeozpk1wn93b4b │ aen349iiivdhcf │ L2 │ 10m0s │ │ moo │ ceozp0ovszy80c │ den349iklsbuoc │ L1 │ 1m0s │ └──────┴────────────────┴────────────────┴───────────┴───────┘\rTemplates ./bin/gdg backup alerting templates list -- Lists all templates ./bin/gdg backup alerting templates download -- Download all templates ./bin/gdg backup alerting templates upload -- Upload all contact templates ./bin/gdg backup alerting templates clear -- Clear all templates\rExample Output:\r┌───────────┬────────────┬───────────────────────────────────────────────────────┬──────────────────┐ │ NAME │ PROVENANCE │ TEMPLATE SNIPPET │ VERSION │ ├───────────┼────────────┼───────────────────────────────────────────────────────┼──────────────────┤ │ test_tpl1 │ api │ {{- /* This is a copy of the \u0026#34;default.message\u0026#34; tem... │ ea62014659bb56f7 │ │ tpl2_test │ api │ {{- /* Example displaying additional information, ... │ 53e8e4dd5634e38a │ └───────────┴────────────┴───────────────────────────────────────────────────────┴──────────────────┘\rConnections Starting with v0.4.6 \u0026ldquo;Datasources\u0026rdquo; was renamed to connections.\nConnections credentials are keyed by the name of the DataSource. See config example. If the connection JSON doesn\u0026rsquo;t have auth enabled, the credentials are ignored. If Credentials are missing, we\u0026rsquo;ll fall back on default credentials if any exist. The password is set as a value for basicAuthPassword in the API payload. Datasources are imported or exported from organization specified in configuration file otherwise current organization user is used.\nAll commands can use connection or c to manage datasources.\n./bin/gdg backup c list -- Lists all current connections ./bin/gdg backup c download -- Import all connections from grafana to local file system ./bin/gdg backup c upload -- Exports all dashboard from local filesystem (matching folder filter) to Grafana ./bin/gdg backup c clear -- Deletes all connections\rDashboards Dashboards are imported or exported from organization specified in configuration file otherwise current organization user is used.\nAll commands can use dashboards or dash to manage dashboards\n./bin/gdg backup dash list -- Lists all current dashboards ./bin/gdg backup dash download -- Import all dashboards from grafana to local file system ./bin/gdg backup dash upload -- Exports all dashboard from local filesystem (matching folder filter) to Grafana ./bin/gdg backup dash clear -- Deletes all dashboards\rYou can also use filtering options to list or import your dashboard by folder or by tags.\n./bin/gdg backup dash download -f myFolder ./bin/gdg backup dash download -t myTag ./bin/gdg backup dash download -t tagA -t tagB -t complex,tagC\rThe command above will return any dashboard that is tagged with tagA or tagB or complex,tagC\nNOTE: Starting with v0.5.2 full crud support for tag filtering. You can list,upload,clear,download dashboards using tag filters. Keep in mind the tag filtering on any matching tags. ie. Any dashboard that has tagA or tagB or complex,tagC will be listed,uploaded, etc.\nFolders Mostly optional as Dashboards will create/delete these are needed but if there is additional metadata you wish to persist you can use this to manage them.\n./bin/gdg backup folders list -- Lists all current folders ./bin/gdg backup folders download -- Import all folders from grafana to local file system ./bin/gdg backup folders upload -- Exports all folders from local filesystem ./bin/gdg backup folders clear -- Deletes all folders\rFolder Permissions This CRUD allows you to import / export folder permissions. Initial release will be part of v0.4.4. There are a lot of nested relationship that go with this.\nExpectations:\nUsers have to already exist. Teams (if used) need to already exist. Folders also need to already exist. The Folder Permissions will list, import and re-apply permissions. But the expectations is that all other entities are already there. Next few iteration will try to add more concurrency for this tool and more error checking when entities that don\u0026rsquo;t exist are being referenced.\nNOTE: Unlike other command, permissions does not have a clear function. Theoretically you could have a folder name with an emtpy array under folder-permissions to clear all known permissions to the folder, but otherwise clearing permissions from all folders seems too destructive to really be a useful function.\n./bin/gdg backup folders list -- Lists all current folder permissions ./bin/gdg backup folders download -- Retrieve all folders permissions from Grafana ./bin/gdg backup folders upload -- Exports all folders from local filesystem\r┌───────────┬──────────────────────────────────────┬───────────────────────────────────────────────────────────────────────────────────┬─────────────┬────────────────────────────────┬────────┬─────────────────┐ │ FOLDER ID │ FOLDERUID │ FOLDER NAME │ USERID │ TEAM NAME │ ROLE │ PERMISSION NAME │ ├───────────┼──────────────────────────────────────┼───────────────────────────────────────────────────────────────────────────────────┼─────────────┼────────────────────────────────┼────────┼─────────────────┤ │ 2272 │ dfba969d-565b-481e-a930-53aa5684992c │ sub-flow │ │ │ │ │ │ │ PERMISSION---\u0026gt; │ admin │ │ Admin │ │ 520 │ GPmSOQNnk │ EngageMap (internal beta) │ │ │ │ │ │ │ PERMISSION---\u0026gt; │ │ Admin │ Edit │ │ │ PERMISSION---\u0026gt; │ │ Editor │ Edit │ │ │ PERMISSION---\u0026gt; │ │ Viewer │ View │ │ 2031 │ n3xS8TwVk │ Team CMS - US dumb dumb │ │ │ │ │ │ │ PERMISSION---\u0026gt; │ │ authscope_team_cms │ │ Edit │ │ 1746 │ pASPyoQVk │ Team DOE-IN-PNNL - DOE-IN Pacific Northwest National Laboratory │ │ │ │ │ └──────────────────────────────────────────────────┴───────────────────────────────────────────────────────────────────────────────────┴─────────────┴────────────────────────────────┴────────┴─────────────────┘\rThe listing includes the folder name, followed by several lines with \u0026ldquo;PERMISSION\u0026mdash;\u0026gt;\u0026rdquo; which will each list a permission. It can a user being granted access or a team being granted a role etc.\nLibrary Elements Library elements are components that can be shared among multiple dashboards. Folder matching will still be applied, so any folders not monitored will be ignored unless explicitly specified. If wildcard flag is enabled, all elements will be acted on irrelevant of folder location\nAll commands can use libraryelements aliased to library and lib for laziness purposes. A more extensive tutorial is available here\n./bin/gdg backup lib list -- Lists all library components ./bin/gdg backup lib download -- Import all library components from grafana to local file system ./bin/gdg backup lib upload -- Exports all library components from local filesystem (matching folder filter) to Grafana ./bin/gdg backup lib clear -- Deletes all library components ./bin/gdg backup lib list-connections \u0026lt;Lib Element UID\u0026gt; -- Will list all of the dashboards connected to the Lib Element (Coming in v0.4.2)\rOrganizations Danger\nAuth: Requires Grafana Admin\nTokens/service account tokens are tied to a specific org and are therefore not supported. Organization Admins don\u0026rsquo;t have access to list all Orgs, therefore are also not supported. Command can use organizations or org to manage organizations.\n./bin/gdg backup org list -- Lists all organizations ./bin/gdg backup org upload -- Upload Orgs to grafana ./bin/gdg backup org download -- Download Orgs to grafana\rA tutorial on working with organizations is available.\nTeams Caution\nUsers need to be created before team export can succeed\n./bin/gdg backup team list -- Lists all known team members ./bin/gdg backup team download -- download all known team members ./bin/gdg backup team upload -- upload all known team members ./bin/gdg backup team clear -- Delete all known team except admin\rTeam Listing\r┌────┬───────────┬───────┬───────┬─────────┬─────────────┬──────────────┬───────────────────┐ │ ID │ NAME │ EMAIL │ ORGID │ CREATED │ MEMBERCOUNT │ MEMBER LOGIN │ MEMBER PERMISSION │ ├────┼───────────┼───────┼───────┼─────────┼─────────────┼──────────────┼───────────────────┤ │ 4 │ engineers │ │ 1 │ 2 │ │ │ │ │ │ │ │ │ │ admin │ Admin │ │ │ │ │ │ │ │ tux │ Member │ │ │ 5 │ musicians │ │ 1 │ 1 │ │ │ │ │ │ │ │ │ │ admin │ Admin │ │ └────┴───────────┴───────┴───────┴─────────┴─────────────┴──────────────┴───────────────────┘\rUsers Only supported with basic auth. Users is the only one where basic auth is given priority. API Auth is not supported, so will try to use basic auth if configured otherwise will warn the user and exit.\nNOTE: admin user is always ignored.\n./bin/gdg backup users list -- Lists all known users ./bin/gdg backup users download -- Lists all known users ./bin/gdg backup users upload -- Export all users (Not yet supported) ./bin/gdg backup users clear -- Delete all known users except admin\r","date":"0001-01-01","id":16,"permalink":"/gdg/docs/usage_guide/backup-guide/","summary":"Every namespace supporting CRUD operations has the functions: list, download, upload, clear operating on only the monitored folders.\nAlerting Alerting is made up of several type of entities: ContactPoints, Alert Rules, Notification Policy and finally Templates.","tags":[],"title":"Backup Guide"},{"content":"This guide focuses on the \u0026rsquo;tools\u0026rsquo; subcommand. Every command that isn\u0026rsquo;t specific to a CRUD operation falls under the tools command.\nThere are a few utility functions that have been introduced that might be useful to the user, or is geared at managing the configuration, switching contexts or Orgs for a given user and so on.\nAuthentication Management This is mainly added as a convenience mechanism. It was needed to support some testing and exposing the feature is useful as a really simple CLI to create tokens / service Keys. You probably should be using other tooling for managing all your service files and tokens. Unlike most other entities, this is not a backup feature as much as utility.\nThere are two sub commands for auth, service-accounts and tokens (will be deprecated at some point).\nToken Management No longer supported, Deprecated in v0.7.3 as it\u0026rsquo;s been removed from the official grafana API.\nPlease see below on how to add a token to a service account.\nService Accounts ./bin/gdg tools auth svc clear delete all Service Accounts ./bin/gdg tools auth svc delete delete the given service account from grafana ./bin/gdg tools auth svc list list API Keys ./bin/gdg tools auth svc new newService \u0026lt;serviceName\u0026gt; \u0026lt;role\u0026gt; [ttl in seconds]\r./bin/gdg tools auth svc new AwesomeSauceSvc admin\rNew Service\r┌────┬─────────────────┬───────┐ │ ID │ NAME │ ROLE │ ├────┼─────────────────┼───────┤ │ 4 │ AwesomeSauceSvc │ Admin │ └────┴─────────────────┴───────┘ ./bin/gdg tools auth svc newToken 4 AwesomeToken\rNew Service\r┌───────────┬──────────┬──────────────┬────────────────────────────────────────────────┐ │ SERVICEID │ TOKEN_ID │ NAME │ TOKEN │ ├───────────┼──────────┼──────────────┼────────────────────────────────────────────────┤ │ 4 │ 3 │ AwesomeToken │ glsa_a14JOaGExOkDuJHjDWScXbxjTBIXScsw_39df7bf5 │ └───────────┴──────────┴──────────────┴────────────────────────────────────────────────┘ ./bin/gdg tools auth svc list\rService Listing\r┌────┬─────────────────┬───────┬────────┬──────────┬──────────────┬───────────────┐ │ ID │ SERVICE NAME │ ROLE │ TOKENS │ TOKEN ID │ TOKEN NAME │ EXPIRATION │ ├────┼─────────────────┼───────┼────────┼──────────┼──────────────┼───────────────┤ │ 4 │ AwesomeSauceSvc │ Admin │ 1 │ │ │ │ │ │ │ │ │ 3 │ AwesomeToken │ No Expiration │ └────┴─────────────────┴───────┴────────┴──────────┴──────────────┴───────────────┘ ./bin/gdg tools auth service-accounts delete 4\r2025-01-26 16:54:00 INF Deleting Service Accounts for context context=testing serviceAccountId=4 2025-01-26 16:54:00 INF Service account has been removed serviceAccountId=4\rService Account Tokens ./bin/gdg tools auth svc tokens new \u0026lt;serviceAccountID\u0026gt; \u0026lt;name\u0026gt; [ttl in seconds] ./bin/gdg tools auth svc tokens clear \u0026lt;serviceAccountID\u0026gt;\rExamples:\n./bin/gdg tools auth svc tokens new 4 myToken 0 ./bin/gdg tools auth svc tokens clear 4\rDashboard Linter Integrated the official grafana linter into GDG. Allows you to run the linter as part of gdg.\ngdg tools dashboard lint -d bandwidth-patterns -f testing\rYou can execute this on a single dashboard, or a folder. \u0026ndash;autofix is available but should be considered a beta feature.\nDevel Some developer helper utilities\n./bin/gdg tools devel completion [bash|fish|powershell|zsh] -- Will generate autocompletion for GDG for your favorite shell ./bin/gdg tools devel srvinfo -- print grafana server info\rHelpers A few helpers utilities added to make it easier to construct CLI regex patters\ngdg tools helpers folder encode \u0026#34;ES net/LHC Data Challenge\u0026#34;\routput: INF Encoded result output=ES+net/LHC+Data+Challenge\nThe output is what you should be using for filtering your dashboards in the configuration file.\ngdg tools helpers folder decode \u0026#34;ES\\+net/LHC\\+Data\\+Challenge\u0026#34;\routput: INF Decoded result output=\u0026ldquo;ES net/LHC Data Challenge\u0026rdquo;\nthe output is what gdg will match against.\nOrganizations Command can use organizations or org to set the organizations in the configuration file.\nNOTE: this only manages top level of the orgs structure. Mainly used for a lazy man pattern.\n./bin/gdg tools org set --orgName \u0026lt;name\u0026gt; OR --orgSlugName \u0026lt;name\u0026gt; -- Sets a given Org filter. All Dashboards and Datasources etc are uploaded to the given Org only.\rAdditionally addUser, updateUserRole, deleteUser, listUsers are all used to manage a user\u0026rsquo;s membership within a given organization.\nOrganizations Preferences There are a few properties that can be set to change behavior. Keep in mind that all of these entity need to be owned by the Org, you cannot reference to a dashboard outside of a given org.\n## will set the weekstart as Tuesday and a default Org theme of dark gdg t orgs prefs set --orgName \u0026#34;Main Org.\u0026#34; --theme dark --weekstart tuesday ## Retrieve the Orgs Preferences gdg t orgs prefs get --orgName \u0026#34;Main Org.\u0026#34;\r┌──────────────────┬─────────┐ │ FIELD │ VALUE │ ├──────────────────┼─────────┤ │ HomeDashboardUID │ │ │ Theme │ dark │ │ WeekStart │ tuesday │ └──────────────────┴─────────┘\rOrganization Users CRUD gdg tools organizations users add [OrgSlug] [userID] Role[admin,editor,viewer] ## Add user to org example: gdg tools organizations users add testing 3 admin gdg tools organizations users list OrgID ## List all users for a given org example: gdg tools organizations users list 4 gdg tools organizations users updateRole [OrgSlug] [UserId] Role[admin,editor,viewer] example: gdg tools organizations users updateRole testing 2 admin gdg tools organizations users currentOrg ## displays the logged in User\u0026#39;s current associated Org gdg tools organizations users delete OrgID ## Removes a user from the given org\rUsers CRUD is under the \u0026lsquo;backup\u0026rsquo; command. The tools subcommand allows you to promote a given user to a grafana admin if you have the permission to do so.\nNOTE: admin user is always ignored.\n./bin/gdg tools users promote -u user@foobar.com -- promotes the user to a grafana admin\r","date":"0001-01-01","id":17,"permalink":"/gdg/docs/usage_guide/tools-guide/","summary":"This guide focuses on the \u0026rsquo;tools\u0026rsquo; subcommand. Every command that isn\u0026rsquo;t specific to a CRUD operation falls under the tools command.","tags":[],"title":"Tools Guide"},{"content":"The features listed below are for the enterprise edition of Grafana only. They will not work on the OSS version.\nIn order to use these features you need.\nHave a running Enterprise version of grafana, I\u0026rsquo;ll defer to the grafana community on instructions on how to set this up. For a docker setup, you need to set:\nGF_ENTERPRISE_LICENSE_TEXT='jwt token value'\nConnections Permissions Note: Available with +v0.4.6. All of these commands are a subset of the connection command. Requires grafana version: +v10.2.3\nAll commands can use permission or p to manage connection permissions.\n./bin/gdg c permission list -- Lists all current connections permissions ./bin/gdg c permission download -- Download all connections from grafana to local file system ./bin/gdg c permission upload -- Exports all dashboard from local filesystem (matching folder filter) to Grafana ./bin/gdg c permission clear -- Deletes all connections Permissions (Leaving only the default values)\rYou can additionally filter by connection slug in order to only operate on a single connection.\n./bin/gdg c permission list --connection my-elastic-connection Permission Listing\r┌────┬───────────┬───────────────┬───────────────┬─────────────────────────────────┬─────────┬──────────────────────────────────────────────────────────────┐ │ ID │ UID │ NAME │ SLUG │ TYPE │ DEFAULT │ URL │ ├────┼───────────┼───────────────┼───────────────┼─────────────────────────────────┼─────────┼──────────────────────────────────────────────────────────────┤ │ 1 │ uL86Byf4k │ Google Sheets │ google-sheets │ grafana-googlesheets-datasource │ false │ http://localhost:3000/connections/datasources/edit/uL86Byf4k │ └────┴───────────┴───────────────┴───────────────┴─────────────────────────────────┴─────────┴──────────────────────────────────────────────────────────────┘ ╔════════════════╦════════════════════╦═════════════════╦════════════════════╗ ║ CONNECTION UID ║ PERMISSION GRANTED ║ PERMISSION TYPE ║ PERMISSION GRANTEE ║ ╠════════════════╬════════════════════╬═════════════════╬════════════════════╣ ║ uL86Byf4k ║ Admin ║ User ║ user:admin ║ ║ uL86Byf4k ║ Admin ║ User ║ user:tux ║ ║ uL86Byf4k ║ Edit ║ User ║ user:bob ║ ║ uL86Byf4k ║ Query ║ Team ║ team:musicians ║ ║ uL86Byf4k ║ Query ║ BuiltinRole ║ builtInRole:Viewer ║ ║ uL86Byf4k ║ Query ║ BuiltinRole ║ builtInRole:Editor ║ ║ uL86Byf4k ║ Admin ║ BuiltinRole ║ builtInRole:Admin ║ ╚════════════════╩════════════════════╩═════════════════╩════════════════════╝ ┌────┬───────────┬─────────┬─────────┬───────────────┬─────────┬──────────────────────────────────────────────────────────────┐ │ ID │ UID │ NAME │ SLUG │ TYPE │ DEFAULT │ URL │ ├────┼───────────┼─────────┼─────────┼───────────────┼─────────┼──────────────────────────────────────────────────────────────┤ │ 3 │ rg9qPqP7z │ netsage │ netsage │ elasticsearch │ true │ http://localhost:3000/connections/datasources/edit/rg9qPqP7z │ └────┴───────────┴─────────┴─────────┴───────────────┴─────────┴──────────────────────────────────────────────────────────────┘ ╔════════════════╦════════════════════╦═════════════════╦════════════════════╗ ║ CONNECTION UID ║ PERMISSION GRANTED ║ PERMISSION TYPE ║ PERMISSION GRANTEE ║ ╠════════════════╬════════════════════╬═════════════════╬════════════════════╣ ║ rg9qPqP7z ║ Admin ║ User ║ user:admin ║ ║ rg9qPqP7z ║ Admin ║ BuiltinRole ║ builtInRole:Admin ║ ║ rg9qPqP7z ║ Query ║ BuiltinRole ║ builtInRole:Viewer ║ ║ rg9qPqP7z ║ Query ║ BuiltinRole ║ builtInRole:Editor ║ ╚════════════════╩════════════════════╩═════════════════╩════════════════════╝\rDashboard Permissions Note: Available with +v0.7.2. All of these commands are a subset of the dashboard command.\nAll commands can use permission or p to manage connection permissions.\n./bin/gdg dash permission list -- Lists all current connections permissions ./bin/gdg dash permission download -- Download all connections from grafana to local file system ./bin/gdg dash permission upload -- Exports all dashboard from local filesystem (matching folder filter) to Grafana ./bin/gdg dash permission clear -- Deletes all connections Permissions (Leaving only the default values)\rYou can additionally filter by dashboard slug in order to only operate on a single connection.\nPermission Listing\r┌────┬─────────────────────┬─────────────────────┬─────────┬───────────┬───────────────────────────────────────────────────────┐ │ ID │ NAME │ SLUG │ TYPE │ UID │ URL │ ├────┼─────────────────────┼─────────────────────┼─────────┼───────────┼───────────────────────────────────────────────────────┤ │ 1 │ Bandwidth Dashboard │ bandwidth-dashboard │ General │ 000000003 │ http://localhost:3000/d/000000003/bandwidth-dashboard │ └────┴─────────────────────┴─────────────────────┴─────────┴───────────┴───────────────────────────────────────────────────────┘ ╔═══════════════╦═════════════════════╦════════════╦═══════════╦══════════╦════════════╗ ║ DASHBOARD UID ║ DASHBOARD TITLE ║ USERLOGIN ║ TEAM ║ ROLENAME ║ PERMISSION ║ ╠═══════════════╬═════════════════════╬════════════╬═══════════╬══════════╬════════════╣ ║ 000000003 ║ Bandwidth Dashboard ║ user:admin ║ ║ ║ Admin ║ ║ 000000003 ║ Bandwidth Dashboard ║ user:bob ║ ║ ║ Edit ║ ║ 000000003 ║ Bandwidth Dashboard ║ ║ musicians ║ ║ Admin ║ ║ 000000003 ║ Bandwidth Dashboard ║ ║ ║ Editor ║ Edit ║ ║ 000000003 ║ Bandwidth Dashboard ║ ║ ║ Viewer ║ View ║ ╚═══════════════╩═════════════════════╩════════════╩═══════════╩══════════╩════════════╝ ┌────┬────────────────────┬────────────────────┬─────────┬───────────┬──────────────────────────────────────────────────────┐ │ ID │ NAME │ SLUG │ TYPE │ UID │ URL │ ├────┼────────────────────┼────────────────────┼─────────┼───────────┼──────────────────────────────────────────────────────┤ │ 2 │ Bandwidth Patterns │ bandwidth-patterns │ General │ 000000004 │ http://localhost:3000/d/000000004/bandwidth-patterns │ └────┴────────────────────┴────────────────────┴─────────┴───────────┴──────────────────────────────────────────────────────┘ ╔═══════════════╦════════════════════╦════════════╦══════╦══════════╦════════════╗ ║ DASHBOARD UID ║ DASHBOARD TITLE ║ USERLOGIN ║ TEAM ║ ROLENAME ║ PERMISSION ║ ╠═══════════════╬════════════════════╬════════════╬══════╬══════════╬════════════╣ ║ 000000004 ║ Bandwidth Patterns ║ user:admin ║ ║ ║ Admin ║ ║ 000000004 ║ Bandwidth Patterns ║ ║ ║ Editor ║ Edit ║ ║ 000000004 ║ Bandwidth Patterns ║ ║ ║ Viewer ║ View ║ ╚═══════════════╩════════════════════╩════════════╩══════╩══════════╩════════════╝\r","date":"0001-01-01","id":18,"permalink":"/gdg/docs/usage_guide/enterprise-guide/","summary":"The features listed below are for the enterprise edition of Grafana only. They will not work on the OSS version.","tags":[],"title":"Enterprise Guide"},{"content":"These are miscellaneous commands that don\u0026rsquo;t fit under any category.\nContexts Starting with version 0.1.4 contexts are now supported. Your config can contain one or multiple contexts which are essentially a grafana server configuration.\nctx is shorthand for context and basic CRUD is supported which is mainly tooling to make it easier to avoid updating the yaml file manually\n./bin/gdg tools ctx list -- Lists all known contexts ./bin/gdg tools ctx show qa -- shows the configuration for the selected context ./bin/gdg tools ctx set production -- updates the active config and sets it to the request value. ./bin/gdg tools ctx delete qa -- Deletes the QA context ./bin/gdg tools ctx cp qa staging -- copies the qa context to staging and sets it as active ./bin/gdg tools ctx clear -- Will delete all active contexts leaving only a single example entry\rVersion Print the applications release version\n./bin/gdg version\rBuild Date: 2022-05-05-13:27:08 Git Commit: 34cc84b3d80080aa93e74ed37739bddc3638997c+CHANGES Version: 0.1.11 Go Version: go1.18 OS / Arch: darwin amd64\r","date":"0001-01-01","id":19,"permalink":"/gdg/docs/usage_guide/other-commands/","summary":"These are miscellaneous commands that don\u0026rsquo;t fit under any category.\nContexts Starting with version 0.1.4 contexts are now supported. Your config can contain one or multiple contexts which are essentially a grafana server configuration.","tags":[],"title":"Other Commands"},{"content":"","date":"0001-01-01","id":20,"permalink":"/gdg/docs/templating/configuration/","summary":"","tags":[],"title":"Configuration"},{"content":"The structure of the templating config is all defined under the key entities.dashboards\nThe app expects to find a file named \u0026rsquo;templates.yml\u0026rsquo;. You can also find an example in git which is likely to be more updated.\nentites: dashboards: - template_name: template_example output: - folder: \u0026#34;General\u0026#34; organization_name: \u0026#34;Main Org.\u0026#34; dashboard_name: \u0026#34;Testing Foobar\u0026#34; template_data: Title: Bob Loves Candy enabledlight: true lightsources: - sun - moon - lightbulb - office lights - folder: \u0026#34;Testing\u0026#34; organization_name: Some Other Org dashboard_name: \u0026#34;\u0026#34; template_data: Title: Uncle McDonalds enabledlight: true lightsources: - sun - moon\rTemplate Name template_name is the name of the template which will be used to generate the given dashboards. The file is expected to live under {output_path}/templates/{template_name}.go.tmpl. The output_path would be the same the one configured for the main gdg app.\nOutput Output contains an array of one or more configuration that defines the expected behavior. The same template file can be used to write multiple dashboards to various locations under multiple orgs and so on.\nFolder folder defines the dashboard location in grafana.\nOrganization Name organization_name defines the name of the organization that owns the dashboard.\nTemplate Data template_data defines the data that will be used to generate the dashboard. This is unstructured, so any valid yaml can be specified here. The values in template data will be used in the template file. For example above template data contains a field named Title which will be used in the template file to set the dashboard title.\n","date":"0001-01-01","id":21,"permalink":"/gdg/docs/templating/configuration/structure/","summary":"The structure of the templating config is all defined under the key entities.dashboards\nThe app expects to find a file named \u0026rsquo;templates.","tags":[],"title":"Structure"},{"content":"GDG has now introduced a new supporting tool that works in conjunction with GDG. It is currently dependent on the GDG configuration since it will operate on the currently selected context. You can confirm what the current context is by running gdg tools ctx show\nFor example, my current output is as follows:\ncontext_name: storage: \u0026#34;\u0026#34; enterprise_support: true url: http://localhost:3000 token: \u0026#34;\u0026#34; user_name: admin password: admin organization_name: Main Org. watched_folders_override: [ ] watched: - General - Other connections: credential_rules: - rules: - field: name regex: misc - field: url secure_data: \u0026#34;misc.json\u0026#34; - rules: - field: url regex: .*esproxy2* secure_data: \u0026#34;proxy.json\u0026#34; - rules: - field: name regex: .* secure_data: \u0026#34;default.json\u0026#34; dashboard_settings: ignore_filters: false output_path: test/data\rMost of the config isn\u0026rsquo;t that interesting, except the output_path will be used to determine where the newly generated dashboards will be. Make sure you have a valid configuration before continuing.\nWhat does gdg-generate do? There are use cases where an almost identical dashboard is needed except we need to replace certain parts of it.\nFor example, parts of a query need to be different, a different title, brand it to specific customer with a different logo, or footer. All of these are difficult to control from grafana itself and even in the best case scenario it\u0026rsquo;s not great user experience. This allows you to configure and generate a new dashboard with any set of variables and dictionaries that you will seed to the tool.\nConfiguration The configuration that drives this application is templates.yml. You can see an example below.\nentities: dashboards: - template_name: \u0026#34;template_example\u0026#34; ##Matches the name to a file under ouput_path/templates/*.go.tmpl output: ## The section below defines one or multiple destination and the associated configuration ## that goes with it. - folder: \u0026#34;General\u0026#34; ## Name of the new folder where the template will be created organization_name: \u0026#34;Main Org.\u0026#34; dashboard_name: \u0026#34;\u0026#34; ## Optional, defaults to template_name.json template_data: ## Template Data the dictionary of datasets that can be used in the template, # it\u0026#39;s basically your \u0026#39;seed data\u0026#39;. Everything is contains is absolutely arbitrary # and can have any structure as long as it\u0026#39;s valid yaml Title: \u0026#34;Bob Loves Candy\u0026#34; ## Dashboard Titlte enabledlight: false ## Boolean check to enable/disable behavior lightsources: ## some arbitrary list we get to play with - sun - moon - lightbulb - office lights\rOne caveat. The \u0026ldquo;Keys\u0026rdquo; will all be lowercased due to how the data is being read in. Meaning, even though Title is specified, the template will see the value under \u0026ldquo;title\u0026rdquo; instead.\nAvailable Functions Additionally, there a few functions exposed and available to you that allows you to modify\n| Function Name | Example | Input | Output | |------------------|-----------------------------------------|----------------------|--------------------------| | ToSlug | {{ .title \\| ToSlug }} | Bob Candy | bob-candy | | QuotedStringJoin | {{ .lightsources \\| QuotedStringJoin }} | [sun,moon,lightbulb] | \u0026#34;sun\u0026#34;,\u0026#34;moon\u0026#34;,\u0026#34;lightbulb\u0026#34; |\rThere is also a large collection of functions that have been imported from sprig and are available for use.\nExample Templating Snippets Data Injection\n{ \u0026#34;annotations\u0026#34;: { \u0026#34;list\u0026#34;: [ { \u0026#34;$$hashKey\u0026#34;: \u0026#34;{{ .title | lower | ToSlug}}\u0026#34;, // Inserting data and piping it to two different functions. In this case, ToLower is redundant, but it serves as a chained example. \u0026#34;builtIn\u0026#34;: 1, \u0026#34;datasource\u0026#34;: \u0026#34;Grafana\u0026#34;, \u0026#34;enable\u0026#34;: true, \u0026#34;hide\u0026#34;: true, \u0026#34;iconColor\u0026#34;: \u0026#34;rgba(0, 211, 255, 1)\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Annotations Alerts\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;dashboard\u0026#34; } ] } }\rIterating and conditionals.\n{ \u0026#34;link_text\u0026#34;: [ {{ if .enabledlight }} // conditional to check if to insert or not {{ range $v: = .lightsources }} // Iterating through list {{ $v }} // Inserting value {{ end }} {{ end }} ] }\rInserting a comma delimited list\n\u0026#34;link_url\u0026#34;: [ \u0026#34;{{ .lightsources | join \u0026#34;, \u0026#34; }}\u0026#34;, \u0026#34;/grafana/d/000000003/bandwidth-dashboard\u0026#34;, \u0026#34;/grafana/d/xk26IFhmk/flow-data\u0026#34;, ]\rUsage As part of the installation you will have access to gdg-generate.\n\u0026ndash;config, \u0026ndash;template-config, and -t are optional parameters. gdg-generate will fallback on defaults if none are specified. If -t is not provided, all templates will be processed\ngdg-generate --config config/importer.yml --template-config config/template.yaml template generate -t template_example\rExample output:\n2023-11-16 09:49:03 INF gen/main.go:16 Reading GDG configuration 2023-11-16 09:49:03 INF gen/main.go:20 Configuration file is: config=importer.yml 2023-11-16 09:49:03 INF gen/main.go:29 Context is set to: context=testing 2023-11-16 09:49:03 INF templating/templating.go:83 Processing template template=template_example 2023-11-16 09:49:03 INF templating/templating.go:97 Creating a new template folder=General orgId=2 data=\u0026#34;map[enabledlight:false lightsources:[sun moon lightbulb office lights] title:Bob Loves Candy]\u0026#34; 2023-11-16 09:49:03 INF templating/templating.go:100 Writing data to destination output=test/data/org_2/dashboards 2023-11-16 09:49:03 INF templating/templating.go:131 template Path: path=test/data/templates\rA new file has been created under test/data/org_2/dashboards/General/template_example.json\n","date":"0001-01-01","id":22,"permalink":"/gdg/docs/templating/usage-guide/","summary":"GDG has now introduced a new supporting tool that works in conjunction with GDG. It is currently dependent on the GDG configuration since it will operate on the currently selected context.","tags":[],"title":"Usage Guide"},{"content":"Starting with version 0.4, library panels are going to be supported. It\u0026rsquo;s a bit special and the behavior is somewhat unique.\nRules:\nLibrary Panels are immutable. They cannot be moved to a different folder. They are linked to one or multiple dashboards. The only way I can see to move a lib element is to unlink the panel, delete the panel and re-create it in a different folder, then re-link it. In theory it\u0026rsquo;s supposed to move with the dashboards but I haven\u0026rsquo;t been able to re-create that behavior. You cannot delete a library element while a dashboard is still using it. Import components will retrieve all the components from Grafana and save to local file system.\ngdg lib download ┌─────────┬───────────────────────────────────────────────────────────────────────────────────────────────────────┐ │ TYPE │ FILENAME │ ├─────────┼───────────────────────────────────────────────────────────────────────────────────────────────────────┤ │ library │ testing_data/libraryelements/General/dashboard-makeover-extra-cleaning-duty-assignment-today.json │ │ library │ testing_data/libraryelements/General/dashboard-makeover-lighting-status.json │ │ library │ testing_data/libraryelements/General/dashboard-makeover-side-dish-prep-times-past-7-days.json │ │ library │ testing_data/libraryelements/General/dashboard-makeover-time-since-we-purchased-these-spices.json │ │ library │ testing_data/libraryelements/General/extreme-dashboard-makeover-grill.json │ │ library │ testing_data/libraryelements/General/extreme-dashboard-makeover-mac-oven.json │ │ library │ testing_data/libraryelements/General/extreme-dashboard-makeover-refrigerator-temperature-f.json │ │ library │ testing_data/libraryelements/General/extreme-dashboard-makeover-room-temperature-f.json │ │ library │ testing_data/libraryelements/General/extreme-dashboard-makeover-salmon-cooking-times-past-7-days.json │ └─────────┴───────────────────────────────────────────────────────────────────────────────────────────────────────┘\rImporting Dashboards Now that we the library components, pulled let\u0026rsquo;s pull the Dashboard.\ngdg dash download INFO[0002] Importing dashboards for context: \u0026#39;local\u0026#39; ┌───────────┬───────────────────────────────────────────────────────────────────┐ │ TYPE │ FILENAME │ ├───────────┼───────────────────────────────────────────────────────────────────┤ │ dashboard │ testing_data/dashboards/General/bandwidth-dashboard.json │ │ dashboard │ testing_data/dashboards/General/bandwidth-patterns.json │ │ dashboard │ testing_data/dashboards/Other/dashboard-makeover-challenge.json │ \u0026lt;== uses library panels │ dashboard │ testing_data/dashboards/Other/flow-analysis.json │ │ dashboard │ testing_data/dashboards/Other/flow-data-for-circuits.json │ │ dashboard │ testing_data/dashboards/Other/flow-data-for-projects.json │ │ dashboard │ testing_data/dashboards/Other/flow-data-per-country.json │ │ dashboard │ testing_data/dashboards/Other/flow-data-per-organization.json │ │ dashboard │ testing_data/dashboards/Other/flow-information.json │ │ dashboard │ testing_data/dashboards/Other/flows-by-science-discipline.json │ │ dashboard │ testing_data/dashboards/General/individual-flows.json │ │ dashboard │ testing_data/dashboards/General/individual-flows-per-country.json │ │ dashboard │ testing_data/dashboards/Ignored/latency-patterns.json │ │ dashboard │ testing_data/dashboards/General/loss-patterns.json │ │ dashboard │ testing_data/dashboards/General/other-flow-stats.json │ │ dashboard │ testing_data/dashboards/General/science-discipline-patterns.json │ │ dashboard │ testing_data/dashboards/General/top-talkers-over-time.json │ └───────────┴───────────────────────────────────────────────────────────────────┘\rThe dashboards will have a reference to the library panel linked by UID.\nHere\u0026rsquo;s the json from the dashboard JSON:\n\u0026#34;libraryPanel\u0026#34;: { \u0026#34;description\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;meta\u0026#34;: { \u0026#34;connectedDashboards\u0026#34;: 3, \u0026#34;created\u0026#34;: \u0026#34;2022-05-17T19:35:06Z\u0026#34;, \u0026#34;createdBy\u0026#34;: { \u0026#34;avatarUrl\u0026#34;: \u0026#34;/avatar/579fc54abdc9ab34fb4865322f2870a1\u0026#34;, \u0026#34;id\u0026#34;: 13, \u0026#34;name\u0026#34;: \u0026#34;mike.johnson@grafana.com\u0026#34; }, \u0026#34;folderName\u0026#34;: \u0026#34;mj\u0026#34;, \u0026#34;folderUid\u0026#34;: \u0026#34;R0bMCcW7z\u0026#34;, \u0026#34;updated\u0026#34;: \u0026#34;2022-05-17T19:37:14Z\u0026#34;, \u0026#34;updatedBy\u0026#34;: { \u0026#34;avatarUrl\u0026#34;: \u0026#34;/avatar/579fc54abdc9ab34fb4865322f2870a1\u0026#34;, \u0026#34;id\u0026#34;: 13, \u0026#34;name\u0026#34;: \u0026#34;mike.johnson@grafana.com\u0026#34; } }, \u0026#34;name\u0026#34;: \u0026#34;Extreme Dashboard Makeover - Grill\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;graph\u0026#34;, \u0026#34;uid\u0026#34;: \u0026#34;y1C0A5unz\u0026#34;, \u0026#34;version\u0026#34;: 2 },\rPlease note, this is the Grill panel.\n{ \u0026#34;name\u0026#34;: \u0026#34;Extreme Dashboard Makeover - Grill\u0026#34;, \u0026#34;orgId\u0026#34;: 1, \u0026#34;type\u0026#34;: \u0026#34;graph\u0026#34;, \u0026#34;uid\u0026#34;: \u0026#34;y1C0A5unz\u0026#34;, \u0026#34;version\u0026#34;: 1 }\rDeleting Elements If we try to delete all the Library elements, that won\u0026rsquo;t be allowed.\n./bin/gdg lib clear ERRO[0000] Failed to delete library panel titled: Dashboard Makeover - Extra Cleaning Duty Assignment Today ErrorMessage=\u0026#34;the library element has connections\u0026#34; ERRO[0000] Failed to delete library panel titled: Dashboard Makeover - Lighting Status ErrorMessage=\u0026#34;the library element has connections\u0026#34; ERRO[0000] Failed to delete library panel titled: Dashboard Makeover - Side Dish Prep Times, past 7 days ErrorMessage=\u0026#34;the library element has connections\u0026#34; ERRO[0000] Failed to delete library panel titled: Dashboard Makeover - Time since we purchased these spices ErrorMessage=\u0026#34;the library element has connections\u0026#34; ERRO[0000] Failed to delete library panel titled: Extreme Dashboard Makeover - Grill ErrorMessage=\u0026#34;the library element has connections\u0026#34; ERRO[0000] Failed to delete library panel titled: Extreme Dashboard Makeover - Mac Oven ErrorMessage=\u0026#34;the library element has connections\u0026#34; ERRO[0000] Failed to delete library panel titled: Extreme Dashboard Makeover - Refrigerator Temperature (F) ErrorMessage=\u0026#34;the library element has connections\u0026#34; ERRO[0000] Failed to delete library panel titled: Extreme Dashboard Makeover - Room Temperature (F) ErrorMessage=\u0026#34;the library element has connections\u0026#34; ERRO[0000] Failed to delete library panel titled: Extreme Dashboard Makeover - Salmon Cooking Times, past 7 days ErrorMessage=\u0026#34;the library element has connections\u0026#34; INFO[0000] No library were found. 0 librarys removed\rDeleting related dashboard (Future version will allow you to inspect which dashboard has a link to which dashboards)\n./bin/gdg dash clear -d dashboard-makeover-challenge (gke_esnet-sd-dev_us-central1-c_dev-staging-kafka-3/default) INFO[0000] 1 dashboards were deleted ┌───────────┬──────────────────────────────┐ │ TYPE │ FILENAME │ ├───────────┼──────────────────────────────┤ │ dashboard │ Dashboard Makeover Challenge │ └───────────┴──────────────────────────────┘\rPlease note the -d, we\u0026rsquo;re explicitly only deleting one dashboard. We can verify the list.\n./bin/gdg dash list ┌────┬──────────────────────────────┬──────────────────────────────┬─────────┬───────────┬────────────────────────────────────────────────────────────────┐ │ ID │ TITLE │ SLUG │ FOLDER │ UID │ URL │ ├────┼──────────────────────────────┼──────────────────────────────┼─────────┼───────────┼────────────────────────────────────────────────────────────────┤ │ 80 │ Bandwidth Dashboard │ bandwidth-dashboard │ General │ 000000003 │ http://localhost:3000/d/000000003/bandwidth-dashboard │ │ 81 │ Bandwidth Patterns │ bandwidth-patterns │ General │ 000000004 │ http://localhost:3000/d/000000004/bandwidth-patterns │ │ 90 │ Flow Analysis │ flow-analysis │ Other │ VuuXrnPWz │ http://localhost:3000/d/VuuXrnPWz/flow-analysis │ │ 91 │ Flow Data for Circuits │ flow-data-for-circuits │ Other │ xk26IFhmk │ http://localhost:3000/d/xk26IFhmk/flow-data-for-circuits │ │ 92 │ Flow Data for Projects │ flow-data-for-projects │ Other │ ie7TeomGz │ http://localhost:3000/d/ie7TeomGz/flow-data-for-projects │ │ 93 │ Flow Data per Country │ flow-data-per-country │ Other │ fgrOzz_mk │ http://localhost:3000/d/fgrOzz_mk/flow-data-per-country │ │ 94 │ Flow Data per Organization │ flow-data-per-organization │ Other │ QfzDJKhik │ http://localhost:3000/d/QfzDJKhik/flow-data-per-organization │ │ 95 │ Flow Information │ flow-information │ Other │ nzuMyBcGk │ http://localhost:3000/d/nzuMyBcGk/flow-information │ │ 96 │ Flows by Science Discipline │ flows-by-science-discipline │ Other │ WNn1qyaiz │ http://localhost:3000/d/WNn1qyaiz/flows-by-science-discipline │ │ 83 │ Individual Flows │ individual-flows │ General │ -l3_u8nWk │ http://localhost:3000/d/-l3_u8nWk/individual-flows │ │ 82 │ Individual Flows per Country │ individual-flows-per-country │ General │ 80IVUboZk │ http://localhost:3000/d/80IVUboZk/individual-flows-per-country │ │ 88 │ Latency Patterns │ latency-patterns │ Ignored │ 000000005 │ http://localhost:3000/d/000000005/latency-patterns │ │ 84 │ Loss Patterns │ loss-patterns │ General │ 000000006 │ http://localhost:3000/d/000000006/loss-patterns │ │ 85 │ Other Flow Stats │ other-flow-stats │ General │ CJC1FFhmz │ http://localhost:3000/d/CJC1FFhmz/other-flow-stats │ │ 86 │ Science Discipline Patterns │ science-discipline-patterns │ General │ ufIS9W7Zk │ http://localhost:3000/d/ufIS9W7Zk/science-discipline-patterns │ │ 87 │ Top Talkers Over Time │ top-talkers-over-time │ General │ b35BWxAZz │ http://localhost:3000/d/b35BWxAZz/top-talkers-over-time │ └────┴──────────────────────────────┴──────────────────────────────┴─────────┴───────────┴────────────────────────────────────────────────────────────────┘\rRemoving related components ./bin/gdg lib clear (gke_esnet-sd-dev_us-central1-c_dev-staging-kafka-3/default) INFO[0000] 9 library were deleted ┌─────────┬────────────────────────────────────────────────────────────────┐ │ TYPE │ FILENAME │ ├─────────┼────────────────────────────────────────────────────────────────┤ │ library │ Dashboard Makeover - Extra Cleaning Duty Assignment Today │ │ library │ Dashboard Makeover - Lighting Status │ │ library │ Dashboard Makeover - Side Dish Prep Times, past 7 days │ │ library │ Dashboard Makeover - Time since we purchased these spices │ │ library │ Extreme Dashboard Makeover - Grill │ │ library │ Extreme Dashboard Makeover - Mac Oven │ │ library │ Extreme Dashboard Makeover - Refrigerator Temperature (F) │ │ library │ Extreme Dashboard Makeover - Room Temperature (F) │ │ library │ Extreme Dashboard Makeover - Salmon Cooking Times, past 7 days │ └─────────┴────────────────────────────────────────────────────────────────┘\r","date":"0001-01-01","id":23,"permalink":"/gdg/docs/tutorials/working-with-library-panels/","summary":"Starting with version 0.4, library panels are going to be supported. It\u0026rsquo;s a bit special and the behavior is somewhat unique.","tags":[],"title":"Working with Library Panels"},{"content":"Concepts At it\u0026rsquo;s core an Organization in grafana is an entity that allows you (the user) to organize and structure entities to seperate access for both usability and security. So a Connection under org1 would never be able to be configured to use a dashboard under Org2.\nAuthentication with GDG and grafana can take a few different patterns.\nGrafana Admin - this is your typical admin/admin default user that comes with most installs. You have full access to do everything. Org Admin - this is a user that is an admin for one or multiple Orgs and can manage most entities under the given org but not high level entities. Each user can be authenticated with \u0026lsquo;BasicAuth\u0026rsquo; or APIKeys/Service Tokens.\nBasic Auth allows a user to change Orgs context if they have access to more than one. Service Token/API Keys are bound to a given org, so if the user tries to change the Org, it won\u0026rsquo;t work. It grants access, viewer, editor, admin for a given Org. If you are working with multiple Orgs, you will have a much easier time if you use basic auth. You can certainly simply rotate the tokens as you like though GDG is a bit better at dealing with basic auth and switching orgs accordingly.\nOrganization Workflow List Orgs (Grafana Admin) will retrieve all the components from Grafana and save to local file system.\ngdg backup orgs list ┌────┬───────────┐ │ ID │ ORG │ ├────┼───────────┤ │ 1 │ Main Org. │ │ 2 │ DumbDumb │ │ 3 │ Moo │ └────┴───────────┘\rLet\u0026rsquo;s take a look at our context\n---local: storage: \u0026#34;\u0026#34; enterprise_support: false url: http://localhost:3000 token: \u0026#34;SomeTokenHere\u0026#34; user_name: admin password: admin organization_name: Main Org. watched: - General - Other connections: credential_rules: - rules: - field: name regex: .* auth: user: user password: password datasources: {} dashboard_settings: ignore_filters: false output_path: test/data\rThe organization_name is set to Main Org. and is the default if unspecified.\nInspect Current Auth Org Let\u0026rsquo;s have a look at our Token.\ngdg tools org tokenOrg\r┌────┬───────────┐ │ ID │ NAME │ ├────┼───────────┤ │ 1 │ Main Org. │ └────┴───────────┘\rThis is an immutable value and may cause issues if we switch. Depending on the call the behavior is to give token preference or basic auth. So if the basic auth is succesfully namespace into a given org, the token will still point to the wrong one and cause issues. IF you wish to use Tokens, then avoid using basic auth.\nWe can also look at what our User Org is set to using:\ngdg tools org userOrg\r┌────┬───────────┐ │ ID │ NAME │ ├────┼───────────┤ │ 1 │ Main Org. │ └────┴───────────┘\rThis value though IS changeable.\nList Dashboards Now that we take a look at the dashboards under Org 1.\ngdg b dash list INFO[0002] Listing dashboards for context: \u0026#39;local\u0026#39; ┌─────┬──────────────────────────────┬──────────────────────────────┬─────────┬───────────┬──────────────┬────────────────────────────────────────────────────────────────┐ │ ID │ TITLE │ SLUG │ FOLDER │ UID │ TAGS │ URL │ ├─────┼──────────────────────────────┼──────────────────────────────┼─────────┼───────────┼──────────────┼────────────────────────────────────────────────────────────────┤ │ 166 │ Bandwidth Dashboard │ bandwidth-dashboard │ General │ 000000003 │ netsage │ http://localhost:3000/d/000000003/bandwidth-dashboard │ │ 167 │ Bandwidth Patterns │ bandwidth-patterns │ General │ 000000004 │ netsage │ http://localhost:3000/d/000000004/bandwidth-patterns │ │ 174 │ Dashboard Makeover Challenge │ dashboard-makeover-challenge │ Other │ F3eInwQ7z │ │ http://localhost:3000/d/F3eInwQ7z/dashboard-makeover-challenge │ │ 175 │ Flow Analysis │ flow-analysis │ Other │ VuuXrnPWz │ flow,netsage │ http://localhost:3000/d/VuuXrnPWz/flow-analysis │ │ 176 │ Flow Data for Circuits │ flow-data-for-circuits │ Other │ xk26IFhmk │ flow,netsage │ http://localhost:3000/d/xk26IFhmk/flow-data-for-circuits │ │ 177 │ Flow Data for Projects │ flow-data-for-projects │ Other │ ie7TeomGz │ │ http://localhost:3000/d/ie7TeomGz/flow-data-for-projects │ │ 178 │ Flow Data per Country │ flow-data-per-country │ Other │ fgrOzz_mk │ flow,netsage │ http://localhost:3000/d/fgrOzz_mk/flow-data-per-country │ │ 179 │ Flow Data per Organization │ flow-data-per-organization │ Other │ QfzDJKhik │ flow,netsage │ http://localhost:3000/d/QfzDJKhik/flow-data-per-organization │ │ 180 │ Flow Information │ flow-information │ Other │ nzuMyBcGk │ │ http://localhost:3000/d/nzuMyBcGk/flow-information │ │ 181 │ Flows by Science Discipline │ flows-by-science-discipline │ Other │ WNn1qyaiz │ flow,netsage │ http://localhost:3000/d/WNn1qyaiz/flows-by-science-discipline │ │ 169 │ Individual Flows │ individual-flows │ General │ -l3_u8nWk │ netsage │ http://localhost:3000/d/-l3_u8nWk/individual-flows │ │ 168 │ Individual Flows per Country │ individual-flows-per-country │ General │ 80IVUboZk │ netsage │ http://localhost:3000/d/80IVUboZk/individual-flows-per-country │ │ 170 │ Loss Patterns │ loss-patterns │ General │ 000000006 │ netsage │ http://localhost:3000/d/000000006/loss-patterns │ │ 171 │ Other Flow Stats │ other-flow-stats │ General │ CJC1FFhmz │ flow,netsage │ http://localhost:3000/d/CJC1FFhmz/other-flow-stats │ │ 172 │ Science Discipline Patterns │ science-discipline-patterns │ General │ ufIS9W7Zk │ flow,netsage │ http://localhost:3000/d/ufIS9W7Zk/science-discipline-patterns │ │ 173 │ Top Talkers Over Time │ top-talkers-over-time │ General │ b35BWxAZz │ │ http://localhost:3000/d/b35BWxAZz/top-talkers-over-time │ └─────┴──────────────────────────────┴──────────────────────────────┴─────────┴───────────┴──────────────┴────────────────────────────────────────────────────────────────┘\rSwitching Organizations Switching context to Org 2.\ngdg tools orgs set 2 INFO[0000] Succesfully set Org ID for context: local\rLet\u0026rsquo;s confirm that we trully changed contexts.\ngdg tools org userOrg\r┌────┬───────────┐ │ ID │ NAME │ ├────┼───────────┤ │ 2 │ DumbDumb │ └────┴───────────┘\rListing Orgs Dashboards Listing dashboards under Org 2 will result in an empty set.\ngdg b dash list INFO[0000] Listing dashboards for context: \u0026#39;local\u0026#39; INFO[0000] No dashboards found\rLet\u0026rsquo;s switch back to org 1 and donwload our dashboards.\ngdg tools orgs set 1 INFO[0000] Succesfully set Org ID for context: local\rDownload Orgs Dashboards gdg backup dash download\rINFO[0000] Importing dashboards for context: \u0026#39;local\u0026#39; ┌───────────┬──────────────────────────────────────────────────────────────────────┐ │ TYPE │ FILENAME │ ├───────────┼──────────────────────────────────────────────────────────────────────┤ │ dashboard │ test/data/org_1/dashboards/General/bandwidth-dashboard.json │ │ dashboard │ test/data/org_1/dashboards/General/bandwidth-patterns.json │ │ dashboard │ test/data/org_1/dashboards/Other/dashboard-makeover-challenge.json │ │ dashboard │ test/data/org_1/dashboards/Other/flow-analysis.json │ │ dashboard │ test/data/org_1/dashboards/Other/flow-data-for-circuits.json │ │ dashboard │ test/data/org_1/dashboards/Other/flow-data-for-projects.json │ │ dashboard │ test/data/org_1/dashboards/Other/flow-data-per-country.json │ │ dashboard │ test/data/org_1/dashboards/Other/flow-data-per-organization.json │ │ dashboard │ test/data/org_1/dashboards/Other/flow-information.json │ │ dashboard │ test/data/org_1/dashboards/Other/flows-by-science-discipline.json │ │ dashboard │ test/data/org_1/dashboards/General/individual-flows.json │ │ dashboard │ test/data/org_1/dashboards/General/individual-flows-per-country.json │ │ dashboard │ test/data/org_1/dashboards/General/loss-patterns.json │ │ dashboard │ test/data/org_1/dashboards/General/other-flow-stats.json │ │ dashboard │ test/data/org_1/dashboards/General/science-discipline-patterns.json │ │ dashboard │ test/data/org_1/dashboards/General/top-talkers-over-time.json │ └───────────┴──────────────────────────────────────────────────────────────────────┘\rPlease note the path has org_1 in the path. Starting with version 0.5 of GDG we always namespace the entities we back by the org they belong to.\n","date":"2023-09-01","id":24,"permalink":"/gdg/docs/tutorials/organization-and-authentication/","summary":"Concepts At it\u0026rsquo;s core an Organization in grafana is an entity that allows you (the user) to organize and structure entities to seperate access for both usability and security.","tags":[],"title":"Organization and Authentication"},{"content":"Starting with GDG 0.7, support for nested folders has been added. This feature requires grafana 11+. You can watch a Intro video or read the offical annoucements here.\nIt is current behind a feature toggle. You will need to set the folliwing value in your grafana.ini\n[feature_toggles] enable = nestedFolders,...\ror have the following ENV variable set\nGF_FEATURE_TOGGLES_ENABLE=nestedFolders\rAdditionaly GDG configuration needs to have the behavior enabled.\ndashboard_settings: nested_folders: true\rOnce enabled, the behavior for Dashboards and folders should reflect that.\nDashboards For example:\ngdg backup dashboard list\n┌────┬───────────────────────────────────┬─────────────────────────────┬────────────┬──────────────┬────────────────┬───────────────────────────────┬────────────────────────────────────────────────────────────────────┐ │ ID │ TITLE │ SLUG │ FOLDER │ NESTEDPATH │ UID │ TAGS │ URL │ ├────┼───────────────────────────────────┼─────────────────────────────┼────────────┼──────────────┼────────────────┼───────────────────────────────┼────────────────────────────────────────────────────────────────────┤ │ 21 │ RabbitMQ-Overview │ rabbitmq-overview │ General │ General │ Kn5xm-gZk │ [\u0026#34;rabbitmq-prometheus\u0026#34;] │ http://localhost:3000/d/Kn5xm-gZk/rabbitmq-overview │ │ 24 │ Node Exporter Full │ node-exporter-full │ dummy │ Others/dummy │ rYdddlPWk │ [\u0026#34;linux\u0026#34;] │ http://localhost:3000/d/rYdddlPWk/node-exporter-full │ │ 26 │ K8s / Storage / Volumes / Cluster │ k8s-storage-volumes-cluster │ someFolder │ Others/someFolder │ bdx48n30kejuoa │ [\u0026#34;k8s\u0026#34;,\u0026#34;openshift\u0026#34;,\u0026#34;storage\u0026#34;] │ http://localhost:3000/d/bdx48n30kejuoa/k8s-storage-volumes-cluster │ └────┴───────────────────────────────────┴─────────────────────────────┴────────────┴──────────────┴────────────────┴───────────────────────────────┴────────────────────────────────────────────────────────────────────┘\rNote the folder of Node Exporter Full is now Others/dummy, the watched_folders would also need to be updated as it does a substring match, but it might give you plenty of false positives.\nExample: filter on \u0026lsquo;dummy\u0026rsquo; folder also matches /dummy and /a/b/c/d/dummy and /a/dummy/ etc. It\u0026rsquo;s better to be explicit or have a regex Patern\nwatched: - Others/*\rOR\nwatched: - Others/dummy - Others/someFolder\rFolders gdg backup folders list ┌────────────────┬──────────────┬────────────┐ │ UID │ TITLE │ NESTEDPATH │ ├────────────────┼──────────────┼────────────┤ │ ddxll3n7dse80d │ dummy │ Others/dummy │ │ edx4a6qbjt5hcd │ dummy │ dummy │ │ fdxll3n62cbnkf │ Others │ Others │ │ fdxll3nd7jv9cc │ someFolder │ Others/someFolder │ └────────────────┴────────────┴──────────────┘\rFolder Permission Starging with GDG v0.7 file name convention are the slug of the full nested path rather than folder name.\n┌─────────────────────────────────────────────────────────────┐ │ FILENAME │ ├─────────────────────────────────────────────────────────────┤ │ test/data/org_testing/folders-permissions/others-dummy.json │ │ test/data/org_testing/folders-permissions/dummy.json │ │ test/data/org_testing/folders-permissions/others.json │ │ test/data/org_testing/folders-permissions/somefolder.json │ └─────────────────────────────────────────────────────────────┘\r","date":"0001-01-01","id":25,"permalink":"/gdg/docs/tutorials/working-with-nested-folders/","summary":"Starting with GDG 0.7, support for nested folders has been added. This feature requires grafana 11+. You can watch a Intro video or read the offical annoucements here.","tags":[],"title":"Working with Nested Folders"},{"content":"You can configure gdg in a variety of different ways but if you want so use secret the is currently the simplest pattern:\nversion: \u0026#34;3.8\u0026#34; services: app: image: ghcr.io/esnet/gdg:0.8.0 volumes: - ./importer.yml:/app/config/importer.yml:ro secrets: - staging_auth.json - default.json secrets: staging_auth.json: file: ./staging_auth.json default.json: file: ./default_connection_auth.json\rThen update your config file with the following:\nsecure_location: /run/secrets/\nFor any connection settings, you will have to additionally define all the connection settings accordingly.\nPrior to 0.8 You can create a bash script that replaces the entrypoint as can be seen below:\n#!/bin/sh GDG_CONTEXTS__DEV__PASSWORD=`cat \u0026#34;$GF_SECURITY_ADMIN_PASSWORD__FILE\u0026#34;` exec /app/gdg \u0026#34;$@\u0026#34;\rNote, bash is not in previous containers, it will be added to later versions so you\u0026rsquo;ll have to use sh instead of bash.\nThis assumes that your grafana password is in a file called gf_passwd\nservices: app: image: ghcr.io/esnet/gdg:0.7.2 entrypoint: [\u0026#34;/bin/sh\u0026#34;, \u0026#34;/app/wrapper.sh\u0026#34;] command: [\u0026#34;tools\u0026#34;, \u0026#34;contexts\u0026#34;, \u0026#34;show\u0026#34;] volumes: - ./importer.yml:/app/config/importer.yml:ro - ./wrapper.sh:/app/wrapper.sh environment: - GF_SECURITY_ADMIN_PASSWORD__FILE=/run/secrets/gf_passwd secrets: - gf_passwd secrets: gf_passwd: file: ./gf_passwd\r","date":"0001-01-01","id":26,"permalink":"/gdg/docs/cookbook/docker-compose-example/","summary":"You can configure gdg in a variety of different ways but if you want so use secret the is currently the simplest pattern:","tags":[],"title":"Docker Compose Example"},{"content":"This is a bit beyond the scope of GDG, but wanted to provide an example of how to setup GDG to run on a regular cadence and take backups of your dashboards. Example provided courtesy of arnecls\napiVersion: batch/v1 kind: CronJob metadata: labels: helm.sh/chart: grafana-operator-package-5.6.1 name: grafana-backup namespace: grafana-operator spec: concurrencyPolicy: Forbid failedJobsHistoryLimit: 1 schedule: 0 * * * * successfulJobsHistoryLimit: 1 jobTemplate: spec: backoffLimit: 0 completions: 1 template: spec: containers: - args: - -c - /etc/config/gdg.yaml - backup - dashboards - upload - --skip-confirmation image: ***/ghcr-io-mirror/esnet/gdg:0.7.1 name: grafana-backup-dashboards resources: limits: memory: 256Mi requests: cpu: 100m memory: 256Mi securityContext: allowPrivilegeEscalation: false capabilities: drop: - ALL readOnlyRootFilesystem: true runAsGroup: 65532 runAsNonRoot: true runAsUser: 65532 volumeMounts: - mountPath: /etc/config/ name: config readOnly: true - mountPath: /app/backup # \u0026lt;--- this name: scratch readOnly: false restartPolicy: Never serviceAccountName: grafana-operator-grafana-sa volumes: - configMap: defaultMode: 0444 name: grafana-backup name: config - emptyDir: {} name: scratch\r","date":"0001-01-01","id":27,"permalink":"/gdg/docs/cookbook/kubernetes-crontab-example/","summary":"This is a bit beyond the scope of GDG, but wanted to provide an example of how to setup GDG to run on a regular cadence and take backups of your dashboards.","tags":[],"title":"Kubernetes Crontab Example"},{"content":"Dependencies Development requirements.\nAs gdg is written in go, a current compiler is required. task management tool go-task. Installation Docker for running tests Install the remaining dependencies via: task install_tools\nBuilding/Running gdg Running it then should be as simple as:\n$ task build_all $ ./bin/gdg ## main binary $ ./bin/gdg-generate ## Dashboard Templating engine\rRequires task to be installed locally\nRunning Tests BasicAuth: task test Token: task test_tokens\nMaking a release You can validate that goreleaser work appropriately via\ntask release-snapshot or task release\nThe actual release will be done once a tag has been created via the CICD pipeline, artifacts will be generated and a website update will be published.\n","date":"0001-01-01","id":28,"permalink":"/gdg/docs/developer/developer-guide/","summary":"Dependencies Development requirements.\nAs gdg is written in go, a current compiler is required. task management tool go-task. Installation Docker for running tests Install the remaining dependencies via: task install_tools","tags":[],"title":"Developer Guide"},{"content":"First of all, gdg contains two binaries. gdg which manages grafana entities and provide some tooling facilities and gdg-generate a tool to help generate dashboards from templates to allow for some more flexible management. gdg-generate is fairly new, but the same quality of PRs would be nice to have.\nGDG There two types of features that get added to gdg, a tool or backup feature.\nBackup Feature A backup feature is some entity that you want to add to GDG that it will track.\nFor example, if you want to add support for managing a playlist.\nTypically, we want to be able to:\nList all entities in the current namespace (or Org) Download all entities Upload all entities In order to add a new feature you will need to:\nCreate an issue to track this work and explain the feature being added/requested. Create a new CLI subcommand for playlist. under the backup command. Extend the service to be able to list/download/upload etc the entities. Write a unit test for the given entities. If needed, add some seed data under test/data/ Update the documentation accordingly to reflect the new changes. All docs live under the website/content. All files are in markdown. If you wish you can load the website locally by running: npm install \u0026amp;\u0026amp; hugo serve Testing There are multiple types of tests.\nIntegration tests. The most common one, an instance of grafana will be available and will connect to it to create/update/delete entities. Unit tests can be created for any unit of work, and will always be executed. CLI tooling tests. use task mocks to generate mocks for your tests. The purpose of this test is to validate the CLI parsing behavior rather than the service functionality. Ensure that filtering works, stdout is redirected to the test and can validate the output matches the expectations. Tools Feature This area is more about managing grafana entities. The tools would provide way for creating service accounts, listing tokens, adding user to orgs, etc.\nTesting such features can be a bit more difficult, but we can see enough data to validate the behavior that\u0026rsquo;s always great and makes for a much more stable feature long term.\n","date":"0001-01-01","id":29,"permalink":"/gdg/docs/developer/contributing/","summary":"First of all, gdg contains two binaries. gdg which manages grafana entities and provide some tooling facilities and gdg-generate a tool to help generate dashboards from templates to allow for some more flexible management.","tags":[],"title":"Contributing"},{"content":"GDG Configuration is based on a YAML configuration. It also has the option to override configuration values via environmental variables.\nThe default config file is importer.yml which should exist in $CWD/config, $CWD or /etc/gdg. If no valid file can be found, the application will fail. An example config file can be found in github under the config folder.\nThe configuration has a few sections of note:\ncontext_name: the selected context Storage \u0026ndash; defines the storage engine if a cloud provider is used contexts: defines every context you operate on, think of it as the definition of a grafana instance and how to connect to it. It also defines behavior for what folders to inspect, authentication mechanism, etc. global: defines global behavior for all contexts. These settings are not context specific. They tend to be things like enabling debugging, retry logic, api debugging etc. Environment Overrides Caution\nComplex data type is not supported. If the value is an array it can\u0026rsquo;t be currently set, via ENV overrides.\nIf you wish to override certain value via the environment, like credentials and such you can do so.\nThe pattern for GDG\u0026rsquo;s is as follows: GDG_SECTION__SECTION__keyname\nFor example if I want to set the context name to a different value I can use:\nGDG_CONTEXT_NAME=\u0026#34;testing\u0026#34; gdg tools ctx show ## Which will override the value from the context file. GDG_CONTEXTS__TESTING__URL=\u0026#34;www.google.com\u0026#34; Will override the URL with the one provided.\r","date":"0001-01-01","id":30,"permalink":"/gdg/docs/gdg/configuration/structure/","summary":"GDG Configuration is based on a YAML configuration. It also has the option to override configuration values via environmental variables.","tags":[],"title":"Structure"},{"content":"Global flags are configuration that applies to all contexts. The following flags are all nested under globals:\nClear Output clear_output when set to true will remove all files in the destination folder prior to importing the data.\nie. if fetching all dashboards for the default org, then all files in the folder: {output_path}/org_main-org/dashboards will be removed.\nCaution\nBe careful when using this pattern. This removes all related files, if the operation fails all previous backups for that entity type will be lost.\nDebug When debug is set to true, verbose debugging is enabled. Usually only needed for debugging when issues arise.\nDebug API debug_api when set to true will echo out all the raw API calls, parameter and responses being received. This can be very helpful if you wish to debug behavior being seen or reverse engineering what GDG is actually doing.\nIgnore SSL ignore_ssl_errors when set to true will accept invalid SSL certificates.\nRetry Count retry_count when set will try N number of times before giving up on any request. Please be careful if the number is too high it can lead to very slow performance if performing several operations.\nRetry Delay retry_delay when set will wait for the specified duration before trying again. The time is parsed in the format supported by go time.ParseDuration package.\n","date":"0001-01-01","id":31,"permalink":"/gdg/docs/gdg/configuration/globals/","summary":"Global flags are configuration that applies to all contexts. The following flags are all nested under globals:\nClear Output clear_output when set to true will remove all files in the destination folder prior to importing the data.","tags":[],"title":"Globals"},{"content":"This is only needed if you intend to use a cloud provider to store your backups. If you are downloading your backups to your local file system you can skip this section.\nGDG should work with most S3 compatible providers. It leverages the go-cloud framework to provide this functionality. The standard providers should \u0026lsquo;just work\u0026rsquo; out of the box relying on the authentication mechanism that each provider supports. ie. AWS looks for ~/.aws/credentials, google will look for its respective config and so on. GDG also supports custom providers that allows for S3 compatible self hosted solutions such as Minio, Ceph, etc.\nAll configuration below fall under the storage_engine section, where a new label is introduced for each provider you would like to define. The value doesn\u0026rsquo;t matter but you\u0026rsquo;ll need to reference it in the context section.\nSimple Cloud Storage These would be S3, AWS, Azure.\nKind The flag kind is now deprecated, but if you need to set it, it should always be set to \u0026lsquo;cloud\u0026rsquo;.\nCloud Type cloud_type should be set to the provider you wish to use. Please note, that custom requires additional values to be set.\nSupported values are:\n\u0026lsquo;s3\u0026rsquo; - AWS S3 \u0026lsquo;gs\u0026rsquo; - Google Storage (GS) \u0026lsquo;azblob\u0026rsquo; - Azure Storage custom (S3 Compatible clouds) Caution\nhttps://github.com/google/go-cloud was used to support all of these providers. They should all work, but only S3 and Google have been fully tested.\nMost of these rely on the system configuration. Here are some references for each respective environment:\nGoogle Storage: https://cloud.google.com/docs/authentication#service-accounts https://cloud.google.com/docs/authentication/provide-credentials-adc#local-user-cred S3: https://docs.aws.amazon.com/sdk-for-go/api/aws/session/ Azure: https://pkg.go.dev/github.com/Azure/azure-sdk-for-go/sdk/storage/azblob Bucket Name bucket_name is the name of the bucket to use to store your data.\nPrefix If you would like to configure a prefix, you can set a value that will be appended to the final output path.\nStandard Config Example: storage_engine: any_label: kind: cloud cloud_type: [s3, gs, azblob] bucket_name: \u0026#34;\u0026#34; prefix: \u0026#34;dummy\u0026#34;\rOther Properties The rest of these properties listed below are ignore by any of the standard providers and are intended only to be used by the custom type. Note you can configure any provider as \u0026lsquo;custom\u0026rsquo; but you\u0026rsquo;ll need to set far more properties as well as store your credentials in the config. It\u0026rsquo;s likely both a better pattern and more secure to rely on the cloud provider auth mechanism.\nAccess Id access_id is the access id used to authenticate. This can be a username, or a key depending on the provider. It\u0026rsquo;s not typically seen a secret.\nSecret Key secret_key is the secret used to valid access. This is a sensitive credential and should not be shared.\nInit Bucket init_bucket will attempt to create a bucket. It will warn if it already exists and continue as is.\nEndpoint endpoint is the endpoint for the cloud provider. For S3 it\u0026rsquo;s s3.amazonaws.com, for minio it\u0026rsquo;s localhost:9000 and so on.\nRegion: region is the region for the cloud provider. If you\u0026rsquo;re defining AWS S3 as a custom data type this value is important. Otherwise the default value is us-east-1\nExample of a custom config:\nstorage_engine: some_label: custom: true ## Required, if set to true most of the \u0026#39;custom\u0026#39; configuration will be disregarded. kind: cloud cloud_type: s3 prefix: dummy bucket_name: \u0026#34;mybucket\u0026#34; access_id: \u0026#34;\u0026#34; ## this value can also be read from: AWS_ACCESS_KEY. config file is given precedence secret_key: \u0026#34;\u0026#34; ## same as above, can be read from: AWS_SECRET_KEY with config file is given precedence. init_bucket: \u0026#34;true\u0026#34; ## Only supported for custom workflows. Will attempt to create a bucket if one does not exist. endpoint: \u0026#34;http://localhost:9000\u0026#34; region: us-east-1 ssl_enabled: \u0026#34;false\u0026#34;\rContext Configuration In the context, you will need to set the storage value to the name of the label you defined in the storage section.\n","date":"0001-01-01","id":32,"permalink":"/gdg/docs/gdg/configuration/storage/","summary":"This is only needed if you intend to use a cloud provider to store your backups. If you are downloading your backups to your local file system you can skip this section.","tags":[],"title":"Storage"},{"content":"Contexts define a connection to grafana and how to interact with it, authenticate, how to map the connection credentials, how users are created etc. All contexts are defined under the contexts key.\nAPI Token The token key is used to authenticate against grafana. Please be aware that there are certain limits to the token.\nThey are scoped to a single organization. They cannot be used across multiple orgs. Some endpoints require basic auth and do not support token authentication even if it has admin rights. Connection Settings The Connection Settings define the behavior related to the connections being imported. Authorization mechanism for connections and so on. All of these settings are under connection: label.\nFilters Filters define a list of rules that are applied to the connection imports/exports. They allow a user to filter on any part of the JSON, apply a regex match on the given field and include/exclude it accordingly.\nEach filter has 3 components:\nField, example: name which inspects the connection payload extracting the connection name. regex: Any valid regex of string match. Example: \u0026ldquo;DEV-|-Dev-\u0026rdquo; will exclude any connections that start with DEV- or contains the substring -Dev-. inclusive: if set to false, the default will filter out anything that does not match. Inclusive will only return connections that match the criteria. aka. you could exclude all connections that contain Dev but only include connection for elasticsearch. Credential Rules Connection credentials are not exposed via the API so GDG cannot save those settings. As such this mechanism allows a user to map a certain connection to a set of credentials.\nThe rules are defined under credential_rules key. The credentials used will be for the first matching one. So ideally your default credentials will be the last one in the list. Otherwise, every connection will ignore any other rules and simply use the first one in the list.\nEach Credential rule has 2 components.\nA set of Rules that need to match. These are always additive, ie every single rule needs to match in order to \u0026lsquo;pass\u0026rsquo; secure_data is the location of the JSON used to map the credentials. If you use the context wizard it will create a simple one file for you. { \u0026#34;basicAuthPassword\u0026#34;: \u0026#34;password\u0026#34;, \u0026#34;user\u0026#34;: \u0026#34;user\u0026#34; }\rSome credentials use a different set of keys that it would expect, simply adjust the json to match your needs.\nThe Rules format for connections settings are the same as the filters. An example configuration can be seen below.\n- rules: - field: \u0026#34;name\u0026#34; regex: \u0026#34;misc\u0026#34; - field: \u0026#34;url\u0026#34; value: \u0026#34;.*esproxy2*\u0026#34; secure_data: \u0026#34;custom.json\u0026#34;\rIn the example above if the connection name is misc and the url matches esproxy2 then the connection credentials from custom.json will be used.\nThe default rule is defined below. This should match every possible condition and will always use default.json:\n- rules: # Default - field: \u0026#34;name\u0026#34; regex: \u0026#34;.*\u0026#34; secure_data: \u0026#34;default.json\u0026#34;\rDashboard Settings The entries under dashboard_settings define custom behavior for how dashboards are imported. They can be typically ignored unless you wish to enable a specialized behavior.\nValid values are:\nignore_filters: if you wish to download EVERY folder in grafana and disregard watched folders then set this to true. (Excluding CLI params) Monitored Folders monitored_folders is a list of folders to watch. This is an array of Folder Names and/or Inclusive Regex patterns. There is currently no pattern to exclude matching regex.\nMonitored Folders Override Monitored folders applies to all organizations. If a different behavior is desired, you can use monitored_folders_override. If configured instead of using the monitored folders, it will use the folders defined that match the given org name.\nExample Config:\nmonitored_folders_override: - organization_name: \u0026#34;Staging Org\u0026#34; folders: [\u0026#34;Folder1\u0026#34;, \u0026#34;Folder2\u0026#34;, \u0026#34;General\u0026#34;, \u0026#34;Testing\u0026#34;]\rCaution\nThis setting replaces the watched folders, it is NOT a union of watched folders with the overrides.\nOrganization Name The organization_name key is the name of your organization. The default Org is Main Org., If you are operating on a specific Org, or renamed the org this value is required.\nOutput Path The output_path key is the path relative to the current working directory where all the backups are stored. If using a cloud provider the output path will be relative to the base prefix. aka. if the prefix is \u0026lsquo;production\u0026rsquo; and output_path is \u0026lsquo;backups\u0026rsquo; the backup location will be: s3://bucketName/backups/production/dashboards/...\nPassword If using Basic auth the password field defines the password used to authenticate against grafana. Both Username and password need to be defined.\nNote\nIf you configure both, an auth Token and BasicAuth, then the Token is given priority. Watched folders under grafana is a white list of folders that are being managed by gdg. By default, only \u0026ldquo;General\u0026rdquo; is managed.\nSecure_Location If you set a value for secure_location, gdg will use the secure_location value for all sensitive data instead of its default location (output_path/secure)\nIf the path start with a / it\u0026rsquo;ll be treated as an absolute path, otherwise it\u0026rsquo;ll be assumed to exist relative to the output_path configured.\nStorage To wrap up the previous section, if you setup a cloud provider, you need to set the storage to point to the provider you wish to use.\nUsername The user_name defines the user to be used for basic auth\nUser Settings Just like connections, we cannot retrieve the credentials for a given user. The User settings are saved, but the actual passwords need to be generated. There are two patterns a user can use.\nDefault sha256 hash of username Random password If the default pattern is used the login.json will be used to generate a sha256 which is used as the password. If the user is admin, then the password will be the sha256 of \u0026ldquo;admin.json\u0026rdquo;.\necho -n admin.json | openssl sha256 \u0026gt; SHA2-256(stdin)= f172318957c89be30c2c54abcebb778a86246bbad2325d7133c4dc605319f72b\rif a random password is selected, then it will only be printed once during the import, but a random value is associated with each user.\nto enable this feature ensure random_password is set to true.\nAfter which password settings are very simple:\nmin_length: 8 ## defines the minimum length of the password max_length: 20 ## defines the maximum length of the password\rURL The url key is the URL of your Grafana instance.\n","date":"0001-01-01","id":33,"permalink":"/gdg/docs/gdg/configuration/contexts/","summary":"Contexts define a connection to grafana and how to interact with it, authenticate, how to map the connection credentials, how users are created etc.","tags":[],"title":"Contexts"},{"content":"Debugging / Trouble shooting There are two configuration flags that can be very useful to determine the issue.\n... global: debug: true api_debug: true\rThe debug flag enables very logging which may provide some insight on the core issue that you\u0026rsquo;re running into. Additionally, api_debug when enabled with print every request being made and response.\nFor example, attempting to upload all the given folders I get the follow response.\nAPI Logs\rPOST /api/folders HTTP/1.1 Host: localhost:3000 User-Agent: Go-http-client/1.1 Content-Length: 36 Accept: application/json Authorization: Basic YWRtaW46YWRtaW4= Content-Type: application/json X-Grafana-Org-Id: 1 Accept-Encoding: gzip {\u0026#34;title\u0026#34;:\u0026#34;Other\u0026#34;,\u0026#34;uid\u0026#34;:\u0026#34;CWSuYt_nk\u0026#34;} HTTP/1.1 409 Conflict Content-Length: 80 Cache-Control: no-store Content-Type: application/json Date: Wed, 11 Sep 2024 17:07:57 GMT X-Content-Type-Options: nosniff X-Frame-Options: deny X-Xss-Protection: 1; mode=block {\u0026#34;message\u0026#34;:\u0026#34;a folder with the same name already exists in the current location\u0026#34;}\rAs you can see from the logs, a POST request was made to http://localhost:3000/api/folders, the payload was\n{\u0026#34;title\u0026#34;:\u0026#34;Other\u0026#34;,\u0026#34;uid\u0026#34;:\u0026#34;CWSuYt_nk\u0026#34;}\rIt returned a 409 status since the folder already exists and the response was:\n{\u0026#34;message\u0026#34;:\u0026#34;a folder with the same name already exists in the current location\u0026#34;}\r","date":"0001-01-01","id":34,"permalink":"/gdg/docs/gdg/configuration/debugging/","summary":"Debugging / Trouble shooting There are two configuration flags that can be very useful to determine the issue.\n... global: debug: true api_debug: true\rThe debug flag enables very logging which may provide some insight on the core issue that you\u0026rsquo;re running into.","tags":[],"title":"Debugging"},{"content":"Configuration This is mostly left for reference to older documentation patterns for previous versions.\nConnection Connection Credentials Version v0.4.2-v0.5.1 Legacy Behavior\rPreview behavior did not support the use of a secure/secureData.json pattern, instead an auth: codeblock was used.\nPlease note that only basicAuth worked prior to version v0.5.2\nExample can be seen below:\ntesting: output_path: testing_data connections: credential_rules: - rules: - field: name regex: .* auth: user: user password: secret url: http://localhost:3000 user_name: admin password: admin ignore_filters: False # When set to true all Watched filtered folders will be ignored and ALL folders will be acted on watched: - General - Other\rVersion Prior to v0.4.2 Legacy Behavior\rIf the connection has BasicAuth enabled, then we\u0026rsquo;ll attempt to set the auth with the following precedence on matches:\nMatch of DS credentials based on DS name. Match URL regex for the DS if regex specified. Use Default Credentials if the above two both failed. An example of a configuration can be seen below\ntesting: output_path: testing_data connections: credentials: default: user: user password: password misc: user: admin password: secret url_regex: .*esproxy2* url: http://localhost:3000 user_name: admin password: admin ignore_filters: False # When set to true all Watched filtered folders will be ignored and ALL folders will be acted on watched: - General - Other\rConnection Filters Legacy Behavior (Prior to v0.4.2) Legacy Behavior\rThis feature allows you to exclude connection by name or include them by type. Please note that the logic switches based on the data type.\nname filter:\n... datasources: filters: name_exclusions: \u0026#34;DEV-*|-Dev-*\u0026#34;\rWill exclude any connection that matches the name regex.\nType Filter\nWill ONLY include connection that are listed.\ndatasources: filters: valid_types: - elasticsearch\rThe snippet above will ONLY import connections for elasticsearch\nGlobal Flags These are flags that apply across all contexts. They are top level configuration and are used to drive gdg\u0026rsquo;s application behavior.\nHere are the currently supported flags you may configure.\nglobal: debug: true ignore_ssl_errors: false ##when set to true will ignore invalid SSL errors retry_count: 3 ## Will retry any failed API request up to 3 times. retry_delay: 5s ## will wait for specified duration before trying again.\rdebug: when set will print a more verbose output (Development In Progress). Setting the env flag of DEBUG=1 will also generate verbose output for all HTTP calls. ignore_ssl_errors: when set will disregard any SSL errors and proceed as expected retry_count: will try N number of times before giving up retry_delay: a duration to wait before trying again. Be careful with this setting, if it\u0026rsquo;s too short, the retry won\u0026rsquo;t matter, if too long the app will be very slow. ","date":"0001-01-01","id":35,"permalink":"/gdg/docs/gdg/configuration/legacy/","summary":"Configuration This is mostly left for reference to older documentation patterns for previous versions.\nConnection Connection Credentials Version v0.4.2-v0.5.1 Legacy Behavior\rPreview behavior did not support the use of a secure/secureData.","tags":[],"title":"Legacy"},{"content":"","date":"2020-10-06","id":36,"permalink":"/gdg/docs/","summary":"","tags":[],"title":"GDG - Grafana Dash-n-Grab"},{"content":"","date":"2020-10-06","id":37,"permalink":"/gdg/","summary":"","tags":[],"title":"GDG - Grafana Dash-n-Grab"},{"content":"","date":"0001-01-01","id":38,"permalink":"/gdg/categories/","summary":"","tags":[],"title":"Categories"},{"content":"","date":"0001-01-01","id":39,"permalink":"/gdg/contributors/","summary":"","tags":[],"title":"Contributors"},{"content":"","date":"0001-01-01","id":40,"permalink":"/gdg/tags/","summary":"","tags":[],"title":"Tags"}]